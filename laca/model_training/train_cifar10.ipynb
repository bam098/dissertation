{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vkFfaHmXHKUQ"
   },
   "source": [
    "# CIFAR10 Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QlKtXlb-wULO"
   },
   "source": [
    "The training setup is the same one that has also been used by Zhang et al. For more details see their [paper](https://arxiv.org/abs/1901.09321) and their [sample code](https://github.com/hongyi-zhang/Fixup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ExlhM-ej9utH",
    "outputId": "188ca3fa-73d7-451a-ceb7-32ed57fc296e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling torch-1.7.0+cu101:\n",
      "  Successfully uninstalled torch-1.7.0+cu101\n",
      "Uninstalling torchvision-0.8.1+cu101:\n",
      "  Successfully uninstalled torchvision-0.8.1+cu101\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.7.0+cu101\n",
      "  Using cached https://download.pytorch.org/whl/cu101/torch-1.7.0%2Bcu101-cp37-cp37m-linux_x86_64.whl\n",
      "Collecting torchvision==0.8.1+cu101\n",
      "  Using cached https://download.pytorch.org/whl/cu101/torchvision-0.8.1%2Bcu101-cp37-cp37m-linux_x86_64.whl\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0+cu101) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0+cu101) (0.6)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0+cu101) (0.16.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0+cu101) (1.19.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.1+cu101) (7.0.0)\n",
      "Installing collected packages: torch, torchvision\n",
      "Successfully installed torch-1.7.0+cu101 torchvision-0.8.1+cu101\n"
     ]
    }
   ],
   "source": [
    "! pip uninstall torch torchvision -y\n",
    "! pip install torch==1.7.0+cu101 torchvision==0.8.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2PTvaJ7Q9yo8",
    "outputId": "2977a221-6e15-4427-83da-4f80a2083b69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version:      3.7.10\n",
      "torch version:       1.7.0+cu101\n",
      "torchvision version: 0.8.1+cu101\n",
      "numpy version:       1.19.5\n",
      "matplotlib version:  3.2.2\n",
      "CUDA available:      True\n",
      "cuDNN enabled:       True\n",
      "num gpus:            1\n",
      "gpu:                 Tesla T4\n",
      "\n",
      "------------------------- CUDA -------------------------\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2020 NVIDIA Corporation\n",
      "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
      "Cuda compilation tools, release 11.0, V11.0.221\n",
      "Build cuda_11.0_bu.TC445_37.28845127_0\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import platform\n",
    "\n",
    "print('python version:      {}'.format(platform.python_version()))\n",
    "print('torch version:       {}'.format(torch.__version__))\n",
    "print('torchvision version: {}'.format(torchvision.__version__))\n",
    "print('numpy version:       {}'.format(np.__version__))\n",
    "print('matplotlib version:  {}'.format(matplotlib.__version__))\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print('CUDA available:      {}'.format(use_cuda))\n",
    "print('cuDNN enabled:       {}'.format(torch.backends.cudnn.enabled))\n",
    "print('num gpus:            {}'.format(torch.cuda.device_count()))\n",
    "\n",
    "if use_cuda:\n",
    "    print('gpu:                 {}'.format(torch.cuda.get_device_name(0)))\n",
    "\n",
    "    print()\n",
    "    print('------------------------- CUDA -------------------------')\n",
    "    ! nvcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yb63e9GR-Aii"
   },
   "source": [
    "Put CUDNN to deterministic and set seed values for [reproducibility reasons](https://pytorch.org/docs/stable/notes/randomness.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yMH4t0VK9-Cp"
   },
   "outputs": [],
   "source": [
    "random_seed = 0\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.set_deterministic(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELNzocTU-DwE"
   },
   "source": [
    "Let's set some parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7dBVyKcX4qNw"
   },
   "outputs": [],
   "source": [
    "num_epochs = 200                                         # number of training epochs\n",
    "batch_size_train = 128                                   # batch size for training\n",
    "batch_size_test = 1000                                   # batch size for testing\n",
    "alpha = 1.                                               # alpha\n",
    "base_lr = 0.1                                            # learning rate for training\n",
    "base_learning_rate = base_lr * batch_size_train / 128.   # base learning rate\n",
    "mom = 0.9                                                # momentum\n",
    "decay = 1e-4                                             # weight decay\n",
    "use_sgdr = True                                          # use sgdr\n",
    "calibset_size = 750                                      # size of the calibration set (should be used for calculating a confidence score later)\n",
    "\n",
    "log_interval = 10                                        # printing training statistics after 10 iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wik1VDmc-GfA"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U7c2zcL7yVUC"
   },
   "source": [
    "### Specify Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eoGsnIwryaom"
   },
   "source": [
    "Define data transform functions for training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VmUEEiqvyRj4"
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQKJcyi_yfkV"
   },
   "source": [
    "Define training, test and calibration set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TeakmI6Xyf8-",
    "outputId": "09684e56-83a0-450c-91bc-6c81965fcfb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Training set\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train\n",
    ")\n",
    "\n",
    "# Test set and calibration set\n",
    "orig_testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test\n",
    ")\n",
    "orig_testset_size = len(orig_testset)\n",
    "\n",
    "testset_size = orig_testset_size - calibset_size\n",
    "testset, calibset = torch.utils.data.random_split(orig_testset, [testset_size, calibset_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzgtNQAwymuT"
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZlSfVhWEyxG7"
   },
   "source": [
    "Create train, test and calibration data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0fi0GzKryxw4"
   },
   "outputs": [],
   "source": [
    "# Create training data loader\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size_train, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "# Create test data loader\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_size_test, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "# Create calib data loader\n",
    "calibloader = torch.utils.data.DataLoader(\n",
    "    calibset, batch_size=calibset_size, shuffle=False, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ha-pQCWXb0Iv"
   },
   "source": [
    "Print out the sizes of the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F5XTyUe0b31Q",
    "outputId": "68414037-4b3b-4d62-e38c-f51168e3d2ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset size: 50000\n",
      "testset size:  9250\n",
      "calibset size: 750\n"
     ]
    }
   ],
   "source": [
    "print('trainset size: {}'.format(len(trainloader.dataset)))\n",
    "print('testset size:  {}'.format(len(testloader.dataset)))\n",
    "print('calibset size: {}'.format(len(calibloader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SvhyHSj_y2Ra"
   },
   "source": [
    "### Display Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NQBLPagqy2_J"
   },
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def show_samples(data, targets):\n",
    "    data = data.numpy()\n",
    "    print(\"tensor shape: \" + str(data.shape))\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    for i in range(9):\n",
    "        plt.subplot(3,3,i+1)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        img = data[i]\n",
    "        img[0] = img[0] * 0.2023 + 0.4914\n",
    "        img[1] = img[1] * 0.1994 + 0.4822\n",
    "        img[2] = img[2] * 0.2010 + 0.4465\n",
    "        img = np.clip(img, 0, 1)\n",
    "        img = np.moveaxis(img, 0, -1)\n",
    "        \n",
    "        plt.imshow(img)\n",
    "        plt.title(\"Ground Truth: {}\".format(classes[targets[i]]))\n",
    "        \n",
    "        plt.xticks([])\n",
    "        plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kXdGSzry8Ce"
   },
   "source": [
    "Load a few test images and display them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "woBy6gE-y8YR",
    "outputId": "d7d3b711-5dfc-4566-e607-03e7fcbdc231"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor shape: (1000, 3, 32, 32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = enumerate(testloader)\n",
    "_, (sample_data, sample_targets) = next(dataiter)\n",
    "\n",
    "show_samples(sample_data, sample_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8nrEJtUA4vwY"
   },
   "source": [
    "## Define Training and Test Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the functions for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PgBe_-yy4w-B"
   },
   "outputs": [],
   "source": [
    "def train(num_epochs, model, optim, sgdr, cel, crit, train_loader, test_loader):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    test_accs = []\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model, train_losses = train_one_epoch(epoch, model, optim, crit, train_loader, train_losses)\n",
    "\n",
    "        lr = 0.\n",
    "        if use_sgdr:\n",
    "            sgdr.step()\n",
    "            for param_group in optim.param_groups:\n",
    "                lr = param_group['lr']\n",
    "                break\n",
    "        else:\n",
    "            lr = adjust_learning_rate(optim, epoch)\n",
    "\n",
    "        test_losses, test_accs = test(model, cel, test_loader, test_losses, test_accs)\n",
    "        \n",
    "    print('Finished Training')\n",
    "    return train_losses, test_losses, test_accs\n",
    "\n",
    "\n",
    "def train_one_epoch(epoch_num, model, optim, crit, data_loader, losses):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch_idx, data in enumerate(data_loader):\n",
    "        # Get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, targets = data\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "        inputs, targets_a, targets_b, lam = mixup_data(inputs, targets, alpha, use_cuda)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        # Forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss_func = mixup_criterion(targets_a, targets_b, lam)\n",
    "        loss = loss_func(crit, outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            dataset_size = len(data_loader.dataset)\n",
    "            used_samples = batch_idx * len(inputs)\n",
    "            train_progress = 100. * batch_idx / len(data_loader)\n",
    "            avg_batch_loss = running_loss / log_interval\n",
    "            \n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch_num, used_samples, dataset_size, train_progress, avg_batch_loss\n",
    "            ))\n",
    "            \n",
    "            losses.append(avg_batch_loss)\n",
    "            running_loss = 0.0\n",
    "                \n",
    "    return model, losses\n",
    "\n",
    "    \n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"decrease the learning rate at 100 and 150 epoch\"\"\"\n",
    "    lr = base_learning_rate\n",
    "    if epoch <= 9 and lr > 0.1:\n",
    "        # warm-up training for large minibatch\n",
    "        lr = 0.1 + (base_learning_rate - 0.1) * epoch / 10.\n",
    "    if epoch >= 100:\n",
    "        lr /= 10\n",
    "    if epoch >= 150:\n",
    "        lr /= 10\n",
    "    for param_group in optimizer.param_groups:\n",
    "        if param_group['initial_lr'] == base_learning_rate:\n",
    "            param_group['lr'] = lr\n",
    "        else:\n",
    "            if epoch <= 9:\n",
    "                param_group['lr'] = param_group['initial_lr'] * lr / base_learning_rate\n",
    "            elif epoch < 100:\n",
    "                param_group['lr'] = param_group['initial_lr']\n",
    "            elif epoch < 150:\n",
    "                param_group['lr'] = param_group['initial_lr'] / 10.\n",
    "            else:\n",
    "                param_group['lr'] = param_group['initial_lr'] / 100.\n",
    "    return lr\n",
    "     \n",
    "    \n",
    "def test(model, crit, data_loader, test_losses, test_accs):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    test_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            # Get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, targets = data\n",
    "\n",
    "            if use_cuda:\n",
    "              inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            \n",
    "            # Forward + loss + correct\n",
    "            outputs = model(inputs)\n",
    "            test_loss += crit(outputs, targets).item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "          \n",
    "    dataset_size = len(data_loader.dataset)\n",
    "    test_loss /= dataset_size\n",
    "    acc = 100. * correct / dataset_size\n",
    "    \n",
    "    test_losses.append(test_loss)\n",
    "    test_accs.append(acc)\n",
    "    \n",
    "    print('\\nTest set: Avg. loss: {:.6f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, dataset_size, acc\n",
    "    ))\n",
    "    \n",
    "    return test_losses, test_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_YFZQkAi450A"
   },
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52b1IG-ra3eH"
   },
   "source": [
    "Let's define the Fixup-ResNet20 architecture for CIFAR10 that was used by Zhang et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P7Pt-A4Z47aj"
   },
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=1.0, use_cuda=True, per_sample=False):\n",
    "\n",
    "    '''Compute the mixup data. Return mixed inputs, pairs of targets, and lambda'''\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    if alpha > 0. and not per_sample:\n",
    "        lam = torch.zeros(y.size()).fill_(np.random.beta(alpha, alpha)).cuda()\n",
    "        mixed_x = lam.view(-1, 1, 1, 1) * x + (1 - lam.view(-1, 1, 1, 1)) * x[index,:]\n",
    "    elif alpha > 0.:\n",
    "        lam = torch.Tensor(np.random.beta(alpha, alpha, size=y.size())).cuda()\n",
    "        mixed_x = lam.view(-1, 1, 1, 1) * x + (1 - lam.view(-1, 1, 1, 1)) * x[index,:]\n",
    "    else:\n",
    "        lam = torch.ones(y.size()).cuda()\n",
    "        mixed_x = x\n",
    "\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "def mixup_lam_idx(batch_size, alpha, use_cuda=True):\n",
    "    '''Compute the mixup data. Return mixed inputs, pairs of targets, and lambda'''\n",
    "    if alpha > 0.:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1.\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    return lam, index    \n",
    "\n",
    "\n",
    "def mixup_criterion(y_a, y_b, lam):\n",
    "    return lambda criterion, pred: criterion(pred, y_a, lam) + criterion(pred, y_b, 1 - lam)\n",
    "\n",
    "\n",
    "def get_mean_and_std(dataset):\n",
    "    '''Compute the mean and std value of dataset.'''\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n",
    "    mean = torch.zeros(3)\n",
    "    std = torch.zeros(3)\n",
    "    print('==> Computing mean and std..')\n",
    "    for inputs, targets in dataloader:\n",
    "        for i in range(3):\n",
    "            mean[i] += inputs[:,i,:,:].mean()\n",
    "            std[i] += inputs[:,i,:,:].std()\n",
    "    mean.div_(len(dataset))\n",
    "    std.div_(len(dataset))\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "def init_params(net):\n",
    "    '''Init layer parameters.'''\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            init.kaiming_normal(m.weight, mode='fan_out')\n",
    "            if m.bias:\n",
    "                init.constant(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            init.constant(m.weight, 1)\n",
    "            init.constant(m.bias, 0)\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            init.normal(m.weight, std=1e-3)\n",
    "            if m.bias:\n",
    "                init.constant(m.bias, 0)\n",
    "\n",
    "                \n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class FixupBasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(FixupBasicBlock, self).__init__()\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.bias1a = nn.Parameter(torch.zeros(1))\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bias1b = nn.Parameter(torch.zeros(1))\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.bias2a = nn.Parameter(torch.zeros(1))\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.scale = nn.Parameter(torch.ones(1))\n",
    "        self.bias2b = nn.Parameter(torch.zeros(1))\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x + self.bias1a)\n",
    "        out = self.relu(out + self.bias1b)\n",
    "\n",
    "        out = self.conv2(out + self.bias2a)\n",
    "        out = out * self.scale + self.bias2b\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x + self.bias1a)\n",
    "            identity = torch.cat((identity, torch.zeros_like(identity)), 1)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class FixupResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        super(FixupResNet, self).__init__()\n",
    "        self.num_layers = sum(layers)\n",
    "        self.inplanes = 16\n",
    "        self.conv1 = conv3x3(3, 16)\n",
    "        self.bias1 = nn.Parameter(torch.zeros(1))\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(block, 16, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 32, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.bias2 = nn.Parameter(torch.zeros(1))\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, FixupBasicBlock):\n",
    "                nn.init.normal_(m.conv1.weight, mean=0, std=np.sqrt(2 / (m.conv1.weight.shape[0] * np.prod(m.conv1.weight.shape[2:]))) * self.num_layers ** (-0.5))\n",
    "                nn.init.constant_(m.conv2.weight, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.constant_(m.weight, 0)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1:\n",
    "            downsample = nn.AvgPool2d(1, stride=stride)\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(planes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x + self.bias1)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x + self.bias2)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def fixup_resnet20(**kwargs):\n",
    "    \"\"\"Constructs a Fixup-ResNet-20 model.\n",
    "    \"\"\"\n",
    "    model = FixupResNet(FixupBasicBlock, [3, 3, 3], **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "szo94UrQH0qc"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXs2dnBFISBR"
   },
   "source": [
    "Let's train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rP4BTofQITUI",
    "outputId": "500c939d-438a-4be8-8e83-ceaec384381c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mDie letzten 5000Zeilen der Streamingausgabe wurden abgeschnitten.\u001b[0m\n",
      "Train Epoch: 84 [39680/50000 (79%)]\tLoss: 1.319357\n",
      "Train Epoch: 84 [40960/50000 (82%)]\tLoss: 1.131843\n",
      "Train Epoch: 84 [42240/50000 (84%)]\tLoss: 1.190307\n",
      "Train Epoch: 84 [43520/50000 (87%)]\tLoss: 1.164256\n",
      "Train Epoch: 84 [44800/50000 (90%)]\tLoss: 1.041701\n",
      "Train Epoch: 84 [46080/50000 (92%)]\tLoss: 1.205570\n",
      "Train Epoch: 84 [47360/50000 (95%)]\tLoss: 1.253714\n",
      "Train Epoch: 84 [48640/50000 (97%)]\tLoss: 1.118697\n",
      "Train Epoch: 84 [31200/50000 (100%)]\tLoss: 1.089067\n",
      "\n",
      "Test set: Avg. loss: 0.000431, Accuracy: 8241/9250 (89.09%)\n",
      "\n",
      "Train Epoch: 85 [0/50000 (0%)]\tLoss: 0.141120\n",
      "Train Epoch: 85 [1280/50000 (3%)]\tLoss: 1.113729\n",
      "Train Epoch: 85 [2560/50000 (5%)]\tLoss: 1.059148\n",
      "Train Epoch: 85 [3840/50000 (8%)]\tLoss: 1.251486\n",
      "Train Epoch: 85 [5120/50000 (10%)]\tLoss: 0.855420\n",
      "Train Epoch: 85 [6400/50000 (13%)]\tLoss: 0.963817\n",
      "Train Epoch: 85 [7680/50000 (15%)]\tLoss: 1.104524\n",
      "Train Epoch: 85 [8960/50000 (18%)]\tLoss: 1.038729\n",
      "Train Epoch: 85 [10240/50000 (20%)]\tLoss: 1.119538\n",
      "Train Epoch: 85 [11520/50000 (23%)]\tLoss: 1.241493\n",
      "Train Epoch: 85 [12800/50000 (26%)]\tLoss: 1.024732\n",
      "Train Epoch: 85 [14080/50000 (28%)]\tLoss: 1.007565\n",
      "Train Epoch: 85 [15360/50000 (31%)]\tLoss: 0.908699\n",
      "Train Epoch: 85 [16640/50000 (33%)]\tLoss: 0.934713\n",
      "Train Epoch: 85 [17920/50000 (36%)]\tLoss: 1.105763\n",
      "Train Epoch: 85 [19200/50000 (38%)]\tLoss: 1.081283\n",
      "Train Epoch: 85 [20480/50000 (41%)]\tLoss: 1.218705\n",
      "Train Epoch: 85 [21760/50000 (43%)]\tLoss: 1.110088\n",
      "Train Epoch: 85 [23040/50000 (46%)]\tLoss: 0.942732\n",
      "Train Epoch: 85 [24320/50000 (49%)]\tLoss: 1.110313\n",
      "Train Epoch: 85 [25600/50000 (51%)]\tLoss: 1.098073\n",
      "Train Epoch: 85 [26880/50000 (54%)]\tLoss: 1.105349\n",
      "Train Epoch: 85 [28160/50000 (56%)]\tLoss: 1.128844\n",
      "Train Epoch: 85 [29440/50000 (59%)]\tLoss: 0.914842\n",
      "Train Epoch: 85 [30720/50000 (61%)]\tLoss: 1.196419\n",
      "Train Epoch: 85 [32000/50000 (64%)]\tLoss: 1.099727\n",
      "Train Epoch: 85 [33280/50000 (66%)]\tLoss: 1.106454\n",
      "Train Epoch: 85 [34560/50000 (69%)]\tLoss: 0.944251\n",
      "Train Epoch: 85 [35840/50000 (72%)]\tLoss: 1.110373\n",
      "Train Epoch: 85 [37120/50000 (74%)]\tLoss: 0.985543\n",
      "Train Epoch: 85 [38400/50000 (77%)]\tLoss: 1.154431\n",
      "Train Epoch: 85 [39680/50000 (79%)]\tLoss: 1.108283\n",
      "Train Epoch: 85 [40960/50000 (82%)]\tLoss: 1.114149\n",
      "Train Epoch: 85 [42240/50000 (84%)]\tLoss: 1.160693\n",
      "Train Epoch: 85 [43520/50000 (87%)]\tLoss: 0.773230\n",
      "Train Epoch: 85 [44800/50000 (90%)]\tLoss: 1.139598\n",
      "Train Epoch: 85 [46080/50000 (92%)]\tLoss: 1.020354\n",
      "Train Epoch: 85 [47360/50000 (95%)]\tLoss: 1.292861\n",
      "Train Epoch: 85 [48640/50000 (97%)]\tLoss: 1.125264\n",
      "Train Epoch: 85 [31200/50000 (100%)]\tLoss: 1.085047\n",
      "\n",
      "Test set: Avg. loss: 0.000437, Accuracy: 8160/9250 (88.22%)\n",
      "\n",
      "Train Epoch: 86 [0/50000 (0%)]\tLoss: 0.126505\n",
      "Train Epoch: 86 [1280/50000 (3%)]\tLoss: 0.985615\n",
      "Train Epoch: 86 [2560/50000 (5%)]\tLoss: 1.128857\n",
      "Train Epoch: 86 [3840/50000 (8%)]\tLoss: 1.025745\n",
      "Train Epoch: 86 [5120/50000 (10%)]\tLoss: 1.051156\n",
      "Train Epoch: 86 [6400/50000 (13%)]\tLoss: 1.003728\n",
      "Train Epoch: 86 [7680/50000 (15%)]\tLoss: 1.292500\n",
      "Train Epoch: 86 [8960/50000 (18%)]\tLoss: 1.065325\n",
      "Train Epoch: 86 [10240/50000 (20%)]\tLoss: 1.107381\n",
      "Train Epoch: 86 [11520/50000 (23%)]\tLoss: 0.957013\n",
      "Train Epoch: 86 [12800/50000 (26%)]\tLoss: 1.168709\n",
      "Train Epoch: 86 [14080/50000 (28%)]\tLoss: 0.775211\n",
      "Train Epoch: 86 [15360/50000 (31%)]\tLoss: 1.061025\n",
      "Train Epoch: 86 [16640/50000 (33%)]\tLoss: 1.120969\n",
      "Train Epoch: 86 [17920/50000 (36%)]\tLoss: 1.104928\n",
      "Train Epoch: 86 [19200/50000 (38%)]\tLoss: 1.069738\n",
      "Train Epoch: 86 [20480/50000 (41%)]\tLoss: 1.297472\n",
      "Train Epoch: 86 [21760/50000 (43%)]\tLoss: 1.056187\n",
      "Train Epoch: 86 [23040/50000 (46%)]\tLoss: 1.122618\n",
      "Train Epoch: 86 [24320/50000 (49%)]\tLoss: 1.074241\n",
      "Train Epoch: 86 [25600/50000 (51%)]\tLoss: 1.019498\n",
      "Train Epoch: 86 [26880/50000 (54%)]\tLoss: 1.083426\n",
      "Train Epoch: 86 [28160/50000 (56%)]\tLoss: 1.089978\n",
      "Train Epoch: 86 [29440/50000 (59%)]\tLoss: 1.302228\n",
      "Train Epoch: 86 [30720/50000 (61%)]\tLoss: 1.126212\n",
      "Train Epoch: 86 [32000/50000 (64%)]\tLoss: 1.100643\n",
      "Train Epoch: 86 [33280/50000 (66%)]\tLoss: 1.008973\n",
      "Train Epoch: 86 [34560/50000 (69%)]\tLoss: 0.902353\n",
      "Train Epoch: 86 [35840/50000 (72%)]\tLoss: 1.059662\n",
      "Train Epoch: 86 [37120/50000 (74%)]\tLoss: 0.966107\n",
      "Train Epoch: 86 [38400/50000 (77%)]\tLoss: 1.183739\n",
      "Train Epoch: 86 [39680/50000 (79%)]\tLoss: 1.093343\n",
      "Train Epoch: 86 [40960/50000 (82%)]\tLoss: 1.156817\n",
      "Train Epoch: 86 [42240/50000 (84%)]\tLoss: 1.111857\n",
      "Train Epoch: 86 [43520/50000 (87%)]\tLoss: 1.108111\n",
      "Train Epoch: 86 [44800/50000 (90%)]\tLoss: 1.315722\n",
      "Train Epoch: 86 [46080/50000 (92%)]\tLoss: 0.955857\n",
      "Train Epoch: 86 [47360/50000 (95%)]\tLoss: 1.219326\n",
      "Train Epoch: 86 [48640/50000 (97%)]\tLoss: 1.294912\n",
      "Train Epoch: 86 [31200/50000 (100%)]\tLoss: 1.225220\n",
      "\n",
      "Test set: Avg. loss: 0.000453, Accuracy: 8210/9250 (88.76%)\n",
      "\n",
      "Train Epoch: 87 [0/50000 (0%)]\tLoss: 0.146933\n",
      "Train Epoch: 87 [1280/50000 (3%)]\tLoss: 1.206913\n",
      "Train Epoch: 87 [2560/50000 (5%)]\tLoss: 0.932524\n",
      "Train Epoch: 87 [3840/50000 (8%)]\tLoss: 1.246875\n",
      "Train Epoch: 87 [5120/50000 (10%)]\tLoss: 1.128654\n",
      "Train Epoch: 87 [6400/50000 (13%)]\tLoss: 1.087218\n",
      "Train Epoch: 87 [7680/50000 (15%)]\tLoss: 0.897191\n",
      "Train Epoch: 87 [8960/50000 (18%)]\tLoss: 1.222844\n",
      "Train Epoch: 87 [10240/50000 (20%)]\tLoss: 1.314981\n",
      "Train Epoch: 87 [11520/50000 (23%)]\tLoss: 1.018856\n",
      "Train Epoch: 87 [12800/50000 (26%)]\tLoss: 1.236817\n",
      "Train Epoch: 87 [14080/50000 (28%)]\tLoss: 1.008111\n",
      "Train Epoch: 87 [15360/50000 (31%)]\tLoss: 1.136060\n",
      "Train Epoch: 87 [16640/50000 (33%)]\tLoss: 1.170568\n",
      "Train Epoch: 87 [17920/50000 (36%)]\tLoss: 1.126179\n",
      "Train Epoch: 87 [19200/50000 (38%)]\tLoss: 1.068049\n",
      "Train Epoch: 87 [20480/50000 (41%)]\tLoss: 1.020548\n",
      "Train Epoch: 87 [21760/50000 (43%)]\tLoss: 1.142525\n",
      "Train Epoch: 87 [23040/50000 (46%)]\tLoss: 1.216713\n",
      "Train Epoch: 87 [24320/50000 (49%)]\tLoss: 0.815414\n",
      "Train Epoch: 87 [25600/50000 (51%)]\tLoss: 1.036153\n",
      "Train Epoch: 87 [26880/50000 (54%)]\tLoss: 1.176911\n",
      "Train Epoch: 87 [28160/50000 (56%)]\tLoss: 1.276551\n",
      "Train Epoch: 87 [29440/50000 (59%)]\tLoss: 1.122913\n",
      "Train Epoch: 87 [30720/50000 (61%)]\tLoss: 1.176106\n",
      "Train Epoch: 87 [32000/50000 (64%)]\tLoss: 1.261439\n",
      "Train Epoch: 87 [33280/50000 (66%)]\tLoss: 1.075339\n",
      "Train Epoch: 87 [34560/50000 (69%)]\tLoss: 1.046482\n",
      "Train Epoch: 87 [35840/50000 (72%)]\tLoss: 0.858909\n",
      "Train Epoch: 87 [37120/50000 (74%)]\tLoss: 1.034344\n",
      "Train Epoch: 87 [38400/50000 (77%)]\tLoss: 1.085278\n",
      "Train Epoch: 87 [39680/50000 (79%)]\tLoss: 1.034244\n",
      "Train Epoch: 87 [40960/50000 (82%)]\tLoss: 1.165224\n",
      "Train Epoch: 87 [42240/50000 (84%)]\tLoss: 1.379054\n",
      "Train Epoch: 87 [43520/50000 (87%)]\tLoss: 1.192770\n",
      "Train Epoch: 87 [44800/50000 (90%)]\tLoss: 1.142501\n",
      "Train Epoch: 87 [46080/50000 (92%)]\tLoss: 1.246452\n",
      "Train Epoch: 87 [47360/50000 (95%)]\tLoss: 1.233175\n",
      "Train Epoch: 87 [48640/50000 (97%)]\tLoss: 0.985962\n",
      "Train Epoch: 87 [31200/50000 (100%)]\tLoss: 1.007605\n",
      "\n",
      "Test set: Avg. loss: 0.000422, Accuracy: 8265/9250 (89.35%)\n",
      "\n",
      "Train Epoch: 88 [0/50000 (0%)]\tLoss: 0.054942\n",
      "Train Epoch: 88 [1280/50000 (3%)]\tLoss: 1.225199\n",
      "Train Epoch: 88 [2560/50000 (5%)]\tLoss: 1.172397\n",
      "Train Epoch: 88 [3840/50000 (8%)]\tLoss: 1.160517\n",
      "Train Epoch: 88 [5120/50000 (10%)]\tLoss: 1.013163\n",
      "Train Epoch: 88 [6400/50000 (13%)]\tLoss: 1.163269\n",
      "Train Epoch: 88 [7680/50000 (15%)]\tLoss: 1.214651\n",
      "Train Epoch: 88 [8960/50000 (18%)]\tLoss: 0.926135\n",
      "Train Epoch: 88 [10240/50000 (20%)]\tLoss: 1.164706\n",
      "Train Epoch: 88 [11520/50000 (23%)]\tLoss: 1.023309\n",
      "Train Epoch: 88 [12800/50000 (26%)]\tLoss: 0.986034\n",
      "Train Epoch: 88 [14080/50000 (28%)]\tLoss: 1.010243\n",
      "Train Epoch: 88 [15360/50000 (31%)]\tLoss: 0.975320\n",
      "Train Epoch: 88 [16640/50000 (33%)]\tLoss: 1.082969\n",
      "Train Epoch: 88 [17920/50000 (36%)]\tLoss: 1.116212\n",
      "Train Epoch: 88 [19200/50000 (38%)]\tLoss: 1.163040\n",
      "Train Epoch: 88 [20480/50000 (41%)]\tLoss: 1.099591\n",
      "Train Epoch: 88 [21760/50000 (43%)]\tLoss: 1.131856\n",
      "Train Epoch: 88 [23040/50000 (46%)]\tLoss: 1.152996\n",
      "Train Epoch: 88 [24320/50000 (49%)]\tLoss: 1.078831\n",
      "Train Epoch: 88 [25600/50000 (51%)]\tLoss: 1.076543\n",
      "Train Epoch: 88 [26880/50000 (54%)]\tLoss: 1.171813\n",
      "Train Epoch: 88 [28160/50000 (56%)]\tLoss: 0.969730\n",
      "Train Epoch: 88 [29440/50000 (59%)]\tLoss: 1.216049\n",
      "Train Epoch: 88 [30720/50000 (61%)]\tLoss: 1.080858\n",
      "Train Epoch: 88 [32000/50000 (64%)]\tLoss: 1.082576\n",
      "Train Epoch: 88 [33280/50000 (66%)]\tLoss: 0.857650\n",
      "Train Epoch: 88 [34560/50000 (69%)]\tLoss: 0.919543\n",
      "Train Epoch: 88 [35840/50000 (72%)]\tLoss: 1.122392\n",
      "Train Epoch: 88 [37120/50000 (74%)]\tLoss: 1.353929\n",
      "Train Epoch: 88 [38400/50000 (77%)]\tLoss: 1.078622\n",
      "Train Epoch: 88 [39680/50000 (79%)]\tLoss: 1.087140\n",
      "Train Epoch: 88 [40960/50000 (82%)]\tLoss: 1.061853\n",
      "Train Epoch: 88 [42240/50000 (84%)]\tLoss: 1.073137\n",
      "Train Epoch: 88 [43520/50000 (87%)]\tLoss: 1.239591\n",
      "Train Epoch: 88 [44800/50000 (90%)]\tLoss: 1.060950\n",
      "Train Epoch: 88 [46080/50000 (92%)]\tLoss: 1.090530\n",
      "Train Epoch: 88 [47360/50000 (95%)]\tLoss: 1.245526\n",
      "Train Epoch: 88 [48640/50000 (97%)]\tLoss: 1.115992\n",
      "Train Epoch: 88 [31200/50000 (100%)]\tLoss: 0.990149\n",
      "\n",
      "Test set: Avg. loss: 0.000428, Accuracy: 8229/9250 (88.96%)\n",
      "\n",
      "Train Epoch: 89 [0/50000 (0%)]\tLoss: 0.077534\n",
      "Train Epoch: 89 [1280/50000 (3%)]\tLoss: 1.041925\n",
      "Train Epoch: 89 [2560/50000 (5%)]\tLoss: 1.147699\n",
      "Train Epoch: 89 [3840/50000 (8%)]\tLoss: 1.314147\n",
      "Train Epoch: 89 [5120/50000 (10%)]\tLoss: 0.886157\n",
      "Train Epoch: 89 [6400/50000 (13%)]\tLoss: 1.113474\n",
      "Train Epoch: 89 [7680/50000 (15%)]\tLoss: 1.212739\n",
      "Train Epoch: 89 [8960/50000 (18%)]\tLoss: 1.064878\n",
      "Train Epoch: 89 [10240/50000 (20%)]\tLoss: 1.191489\n",
      "Train Epoch: 89 [11520/50000 (23%)]\tLoss: 1.293155\n",
      "Train Epoch: 89 [12800/50000 (26%)]\tLoss: 1.109853\n",
      "Train Epoch: 89 [14080/50000 (28%)]\tLoss: 1.205036\n",
      "Train Epoch: 89 [15360/50000 (31%)]\tLoss: 1.187072\n",
      "Train Epoch: 89 [16640/50000 (33%)]\tLoss: 1.176959\n",
      "Train Epoch: 89 [17920/50000 (36%)]\tLoss: 0.886798\n",
      "Train Epoch: 89 [19200/50000 (38%)]\tLoss: 1.211010\n",
      "Train Epoch: 89 [20480/50000 (41%)]\tLoss: 1.089335\n",
      "Train Epoch: 89 [21760/50000 (43%)]\tLoss: 1.088199\n",
      "Train Epoch: 89 [23040/50000 (46%)]\tLoss: 1.226960\n",
      "Train Epoch: 89 [24320/50000 (49%)]\tLoss: 1.340797\n",
      "Train Epoch: 89 [25600/50000 (51%)]\tLoss: 1.195359\n",
      "Train Epoch: 89 [26880/50000 (54%)]\tLoss: 1.301207\n",
      "Train Epoch: 89 [28160/50000 (56%)]\tLoss: 1.171915\n",
      "Train Epoch: 89 [29440/50000 (59%)]\tLoss: 1.076135\n",
      "Train Epoch: 89 [30720/50000 (61%)]\tLoss: 0.961134\n",
      "Train Epoch: 89 [32000/50000 (64%)]\tLoss: 1.293506\n",
      "Train Epoch: 89 [33280/50000 (66%)]\tLoss: 1.229612\n",
      "Train Epoch: 89 [34560/50000 (69%)]\tLoss: 1.222792\n",
      "Train Epoch: 89 [35840/50000 (72%)]\tLoss: 1.246846\n",
      "Train Epoch: 89 [37120/50000 (74%)]\tLoss: 1.033887\n",
      "Train Epoch: 89 [38400/50000 (77%)]\tLoss: 1.051874\n",
      "Train Epoch: 89 [39680/50000 (79%)]\tLoss: 1.128459\n",
      "Train Epoch: 89 [40960/50000 (82%)]\tLoss: 1.101369\n",
      "Train Epoch: 89 [42240/50000 (84%)]\tLoss: 1.308725\n",
      "Train Epoch: 89 [43520/50000 (87%)]\tLoss: 1.090588\n",
      "Train Epoch: 89 [44800/50000 (90%)]\tLoss: 1.094291\n",
      "Train Epoch: 89 [46080/50000 (92%)]\tLoss: 1.145904\n",
      "Train Epoch: 89 [47360/50000 (95%)]\tLoss: 1.138925\n",
      "Train Epoch: 89 [48640/50000 (97%)]\tLoss: 1.036730\n",
      "Train Epoch: 89 [31200/50000 (100%)]\tLoss: 1.136361\n",
      "\n",
      "Test set: Avg. loss: 0.000463, Accuracy: 8232/9250 (88.99%)\n",
      "\n",
      "Train Epoch: 90 [0/50000 (0%)]\tLoss: 0.112236\n",
      "Train Epoch: 90 [1280/50000 (3%)]\tLoss: 1.179398\n",
      "Train Epoch: 90 [2560/50000 (5%)]\tLoss: 1.050015\n",
      "Train Epoch: 90 [3840/50000 (8%)]\tLoss: 1.145964\n",
      "Train Epoch: 90 [5120/50000 (10%)]\tLoss: 0.936399\n",
      "Train Epoch: 90 [6400/50000 (13%)]\tLoss: 1.254286\n",
      "Train Epoch: 90 [7680/50000 (15%)]\tLoss: 1.065525\n",
      "Train Epoch: 90 [8960/50000 (18%)]\tLoss: 0.905558\n",
      "Train Epoch: 90 [10240/50000 (20%)]\tLoss: 1.051345\n",
      "Train Epoch: 90 [11520/50000 (23%)]\tLoss: 1.043047\n",
      "Train Epoch: 90 [12800/50000 (26%)]\tLoss: 1.204764\n",
      "Train Epoch: 90 [14080/50000 (28%)]\tLoss: 1.122853\n",
      "Train Epoch: 90 [15360/50000 (31%)]\tLoss: 1.019156\n",
      "Train Epoch: 90 [16640/50000 (33%)]\tLoss: 1.318771\n",
      "Train Epoch: 90 [17920/50000 (36%)]\tLoss: 1.309150\n",
      "Train Epoch: 90 [19200/50000 (38%)]\tLoss: 1.091739\n",
      "Train Epoch: 90 [20480/50000 (41%)]\tLoss: 0.978511\n",
      "Train Epoch: 90 [21760/50000 (43%)]\tLoss: 0.894128\n",
      "Train Epoch: 90 [23040/50000 (46%)]\tLoss: 1.123587\n",
      "Train Epoch: 90 [24320/50000 (49%)]\tLoss: 1.120080\n",
      "Train Epoch: 90 [25600/50000 (51%)]\tLoss: 1.183024\n",
      "Train Epoch: 90 [26880/50000 (54%)]\tLoss: 1.095576\n",
      "Train Epoch: 90 [28160/50000 (56%)]\tLoss: 1.196133\n",
      "Train Epoch: 90 [29440/50000 (59%)]\tLoss: 1.338100\n",
      "Train Epoch: 90 [30720/50000 (61%)]\tLoss: 1.277818\n",
      "Train Epoch: 90 [32000/50000 (64%)]\tLoss: 1.164805\n",
      "Train Epoch: 90 [33280/50000 (66%)]\tLoss: 1.032272\n",
      "Train Epoch: 90 [34560/50000 (69%)]\tLoss: 1.153416\n",
      "Train Epoch: 90 [35840/50000 (72%)]\tLoss: 1.004942\n",
      "Train Epoch: 90 [37120/50000 (74%)]\tLoss: 0.990138\n",
      "Train Epoch: 90 [38400/50000 (77%)]\tLoss: 0.976807\n",
      "Train Epoch: 90 [39680/50000 (79%)]\tLoss: 1.077079\n",
      "Train Epoch: 90 [40960/50000 (82%)]\tLoss: 1.035705\n",
      "Train Epoch: 90 [42240/50000 (84%)]\tLoss: 1.149063\n",
      "Train Epoch: 90 [43520/50000 (87%)]\tLoss: 0.923930\n",
      "Train Epoch: 90 [44800/50000 (90%)]\tLoss: 1.178569\n",
      "Train Epoch: 90 [46080/50000 (92%)]\tLoss: 1.229874\n",
      "Train Epoch: 90 [47360/50000 (95%)]\tLoss: 1.128959\n",
      "Train Epoch: 90 [48640/50000 (97%)]\tLoss: 1.284410\n",
      "Train Epoch: 90 [31200/50000 (100%)]\tLoss: 1.160641\n",
      "\n",
      "Test set: Avg. loss: 0.000473, Accuracy: 8193/9250 (88.57%)\n",
      "\n",
      "Train Epoch: 91 [0/50000 (0%)]\tLoss: 0.047879\n",
      "Train Epoch: 91 [1280/50000 (3%)]\tLoss: 1.182263\n",
      "Train Epoch: 91 [2560/50000 (5%)]\tLoss: 1.156964\n",
      "Train Epoch: 91 [3840/50000 (8%)]\tLoss: 1.072010\n",
      "Train Epoch: 91 [5120/50000 (10%)]\tLoss: 1.127723\n",
      "Train Epoch: 91 [6400/50000 (13%)]\tLoss: 1.063797\n",
      "Train Epoch: 91 [7680/50000 (15%)]\tLoss: 0.983816\n",
      "Train Epoch: 91 [8960/50000 (18%)]\tLoss: 1.123276\n",
      "Train Epoch: 91 [10240/50000 (20%)]\tLoss: 1.115259\n",
      "Train Epoch: 91 [11520/50000 (23%)]\tLoss: 1.156423\n",
      "Train Epoch: 91 [12800/50000 (26%)]\tLoss: 1.166088\n",
      "Train Epoch: 91 [14080/50000 (28%)]\tLoss: 1.217384\n",
      "Train Epoch: 91 [15360/50000 (31%)]\tLoss: 1.313772\n",
      "Train Epoch: 91 [16640/50000 (33%)]\tLoss: 1.017303\n",
      "Train Epoch: 91 [17920/50000 (36%)]\tLoss: 1.249024\n",
      "Train Epoch: 91 [19200/50000 (38%)]\tLoss: 1.117611\n",
      "Train Epoch: 91 [20480/50000 (41%)]\tLoss: 1.082932\n",
      "Train Epoch: 91 [21760/50000 (43%)]\tLoss: 0.904669\n",
      "Train Epoch: 91 [23040/50000 (46%)]\tLoss: 1.202687\n",
      "Train Epoch: 91 [24320/50000 (49%)]\tLoss: 1.213140\n",
      "Train Epoch: 91 [25600/50000 (51%)]\tLoss: 1.064331\n",
      "Train Epoch: 91 [26880/50000 (54%)]\tLoss: 1.092676\n",
      "Train Epoch: 91 [28160/50000 (56%)]\tLoss: 1.110065\n",
      "Train Epoch: 91 [29440/50000 (59%)]\tLoss: 1.242476\n",
      "Train Epoch: 91 [30720/50000 (61%)]\tLoss: 1.137669\n",
      "Train Epoch: 91 [32000/50000 (64%)]\tLoss: 1.064883\n",
      "Train Epoch: 91 [33280/50000 (66%)]\tLoss: 0.936874\n",
      "Train Epoch: 91 [34560/50000 (69%)]\tLoss: 1.097312\n",
      "Train Epoch: 91 [35840/50000 (72%)]\tLoss: 1.159529\n",
      "Train Epoch: 91 [37120/50000 (74%)]\tLoss: 1.192536\n",
      "Train Epoch: 91 [38400/50000 (77%)]\tLoss: 0.998894\n",
      "Train Epoch: 91 [39680/50000 (79%)]\tLoss: 0.992077\n",
      "Train Epoch: 91 [40960/50000 (82%)]\tLoss: 1.293657\n",
      "Train Epoch: 91 [42240/50000 (84%)]\tLoss: 1.044239\n",
      "Train Epoch: 91 [43520/50000 (87%)]\tLoss: 1.081782\n",
      "Train Epoch: 91 [44800/50000 (90%)]\tLoss: 1.058664\n",
      "Train Epoch: 91 [46080/50000 (92%)]\tLoss: 1.140733\n",
      "Train Epoch: 91 [47360/50000 (95%)]\tLoss: 1.289804\n",
      "Train Epoch: 91 [48640/50000 (97%)]\tLoss: 1.230181\n",
      "Train Epoch: 91 [31200/50000 (100%)]\tLoss: 0.940569\n",
      "\n",
      "Test set: Avg. loss: 0.000394, Accuracy: 8259/9250 (89.29%)\n",
      "\n",
      "Train Epoch: 92 [0/50000 (0%)]\tLoss: 0.143244\n",
      "Train Epoch: 92 [1280/50000 (3%)]\tLoss: 0.848487\n",
      "Train Epoch: 92 [2560/50000 (5%)]\tLoss: 1.180768\n",
      "Train Epoch: 92 [3840/50000 (8%)]\tLoss: 1.050059\n",
      "Train Epoch: 92 [5120/50000 (10%)]\tLoss: 0.953254\n",
      "Train Epoch: 92 [6400/50000 (13%)]\tLoss: 0.975039\n",
      "Train Epoch: 92 [7680/50000 (15%)]\tLoss: 1.259720\n",
      "Train Epoch: 92 [8960/50000 (18%)]\tLoss: 1.232608\n",
      "Train Epoch: 92 [10240/50000 (20%)]\tLoss: 1.144523\n",
      "Train Epoch: 92 [11520/50000 (23%)]\tLoss: 1.232262\n",
      "Train Epoch: 92 [12800/50000 (26%)]\tLoss: 1.037330\n",
      "Train Epoch: 92 [14080/50000 (28%)]\tLoss: 1.187994\n",
      "Train Epoch: 92 [15360/50000 (31%)]\tLoss: 0.896925\n",
      "Train Epoch: 92 [16640/50000 (33%)]\tLoss: 1.083285\n",
      "Train Epoch: 92 [17920/50000 (36%)]\tLoss: 1.089985\n",
      "Train Epoch: 92 [19200/50000 (38%)]\tLoss: 1.258563\n",
      "Train Epoch: 92 [20480/50000 (41%)]\tLoss: 1.108171\n",
      "Train Epoch: 92 [21760/50000 (43%)]\tLoss: 1.090811\n",
      "Train Epoch: 92 [23040/50000 (46%)]\tLoss: 1.168499\n",
      "Train Epoch: 92 [24320/50000 (49%)]\tLoss: 1.124340\n",
      "Train Epoch: 92 [25600/50000 (51%)]\tLoss: 0.942299\n",
      "Train Epoch: 92 [26880/50000 (54%)]\tLoss: 1.215797\n",
      "Train Epoch: 92 [28160/50000 (56%)]\tLoss: 1.101919\n",
      "Train Epoch: 92 [29440/50000 (59%)]\tLoss: 1.129601\n",
      "Train Epoch: 92 [30720/50000 (61%)]\tLoss: 0.959542\n",
      "Train Epoch: 92 [32000/50000 (64%)]\tLoss: 1.180841\n",
      "Train Epoch: 92 [33280/50000 (66%)]\tLoss: 1.089987\n",
      "Train Epoch: 92 [34560/50000 (69%)]\tLoss: 1.121874\n",
      "Train Epoch: 92 [35840/50000 (72%)]\tLoss: 1.289483\n",
      "Train Epoch: 92 [37120/50000 (74%)]\tLoss: 1.110577\n",
      "Train Epoch: 92 [38400/50000 (77%)]\tLoss: 1.216658\n",
      "Train Epoch: 92 [39680/50000 (79%)]\tLoss: 1.058702\n",
      "Train Epoch: 92 [40960/50000 (82%)]\tLoss: 1.269639\n",
      "Train Epoch: 92 [42240/50000 (84%)]\tLoss: 1.257201\n",
      "Train Epoch: 92 [43520/50000 (87%)]\tLoss: 1.166967\n",
      "Train Epoch: 92 [44800/50000 (90%)]\tLoss: 1.059657\n",
      "Train Epoch: 92 [46080/50000 (92%)]\tLoss: 0.716695\n",
      "Train Epoch: 92 [47360/50000 (95%)]\tLoss: 1.158491\n",
      "Train Epoch: 92 [48640/50000 (97%)]\tLoss: 1.173037\n",
      "Train Epoch: 92 [31200/50000 (100%)]\tLoss: 0.993543\n",
      "\n",
      "Test set: Avg. loss: 0.000444, Accuracy: 8194/9250 (88.58%)\n",
      "\n",
      "Train Epoch: 93 [0/50000 (0%)]\tLoss: 0.056037\n",
      "Train Epoch: 93 [1280/50000 (3%)]\tLoss: 1.084244\n",
      "Train Epoch: 93 [2560/50000 (5%)]\tLoss: 1.136493\n",
      "Train Epoch: 93 [3840/50000 (8%)]\tLoss: 1.040645\n",
      "Train Epoch: 93 [5120/50000 (10%)]\tLoss: 0.939283\n",
      "Train Epoch: 93 [6400/50000 (13%)]\tLoss: 1.146932\n",
      "Train Epoch: 93 [7680/50000 (15%)]\tLoss: 1.253900\n",
      "Train Epoch: 93 [8960/50000 (18%)]\tLoss: 1.064647\n",
      "Train Epoch: 93 [10240/50000 (20%)]\tLoss: 1.018733\n",
      "Train Epoch: 93 [11520/50000 (23%)]\tLoss: 0.989755\n",
      "Train Epoch: 93 [12800/50000 (26%)]\tLoss: 0.923456\n",
      "Train Epoch: 93 [14080/50000 (28%)]\tLoss: 1.122962\n",
      "Train Epoch: 93 [15360/50000 (31%)]\tLoss: 0.829645\n",
      "Train Epoch: 93 [16640/50000 (33%)]\tLoss: 1.168415\n",
      "Train Epoch: 93 [17920/50000 (36%)]\tLoss: 1.072931\n",
      "Train Epoch: 93 [19200/50000 (38%)]\tLoss: 0.986670\n",
      "Train Epoch: 93 [20480/50000 (41%)]\tLoss: 0.918654\n",
      "Train Epoch: 93 [21760/50000 (43%)]\tLoss: 1.171531\n",
      "Train Epoch: 93 [23040/50000 (46%)]\tLoss: 1.052859\n",
      "Train Epoch: 93 [24320/50000 (49%)]\tLoss: 0.991582\n",
      "Train Epoch: 93 [25600/50000 (51%)]\tLoss: 0.995127\n",
      "Train Epoch: 93 [26880/50000 (54%)]\tLoss: 1.083842\n",
      "Train Epoch: 93 [28160/50000 (56%)]\tLoss: 1.131181\n",
      "Train Epoch: 93 [29440/50000 (59%)]\tLoss: 1.017378\n",
      "Train Epoch: 93 [30720/50000 (61%)]\tLoss: 0.950152\n",
      "Train Epoch: 93 [32000/50000 (64%)]\tLoss: 1.047840\n",
      "Train Epoch: 93 [33280/50000 (66%)]\tLoss: 1.229612\n",
      "Train Epoch: 93 [34560/50000 (69%)]\tLoss: 0.995548\n",
      "Train Epoch: 93 [35840/50000 (72%)]\tLoss: 1.154346\n",
      "Train Epoch: 93 [37120/50000 (74%)]\tLoss: 1.171291\n",
      "Train Epoch: 93 [38400/50000 (77%)]\tLoss: 1.122618\n",
      "Train Epoch: 93 [39680/50000 (79%)]\tLoss: 1.008687\n",
      "Train Epoch: 93 [40960/50000 (82%)]\tLoss: 1.233249\n",
      "Train Epoch: 93 [42240/50000 (84%)]\tLoss: 1.029178\n",
      "Train Epoch: 93 [43520/50000 (87%)]\tLoss: 0.724785\n",
      "Train Epoch: 93 [44800/50000 (90%)]\tLoss: 1.220971\n",
      "Train Epoch: 93 [46080/50000 (92%)]\tLoss: 1.037215\n",
      "Train Epoch: 93 [47360/50000 (95%)]\tLoss: 1.170730\n",
      "Train Epoch: 93 [48640/50000 (97%)]\tLoss: 0.800316\n",
      "Train Epoch: 93 [31200/50000 (100%)]\tLoss: 0.941684\n",
      "\n",
      "Test set: Avg. loss: 0.000425, Accuracy: 8247/9250 (89.16%)\n",
      "\n",
      "Train Epoch: 94 [0/50000 (0%)]\tLoss: 0.134330\n",
      "Train Epoch: 94 [1280/50000 (3%)]\tLoss: 0.958422\n",
      "Train Epoch: 94 [2560/50000 (5%)]\tLoss: 1.247714\n",
      "Train Epoch: 94 [3840/50000 (8%)]\tLoss: 1.097099\n",
      "Train Epoch: 94 [5120/50000 (10%)]\tLoss: 1.082645\n",
      "Train Epoch: 94 [6400/50000 (13%)]\tLoss: 0.997208\n",
      "Train Epoch: 94 [7680/50000 (15%)]\tLoss: 1.135109\n",
      "Train Epoch: 94 [8960/50000 (18%)]\tLoss: 1.030091\n",
      "Train Epoch: 94 [10240/50000 (20%)]\tLoss: 1.100382\n",
      "Train Epoch: 94 [11520/50000 (23%)]\tLoss: 1.100715\n",
      "Train Epoch: 94 [12800/50000 (26%)]\tLoss: 1.033029\n",
      "Train Epoch: 94 [14080/50000 (28%)]\tLoss: 1.076471\n",
      "Train Epoch: 94 [15360/50000 (31%)]\tLoss: 1.056817\n",
      "Train Epoch: 94 [16640/50000 (33%)]\tLoss: 1.172818\n",
      "Train Epoch: 94 [17920/50000 (36%)]\tLoss: 0.832733\n",
      "Train Epoch: 94 [19200/50000 (38%)]\tLoss: 1.102080\n",
      "Train Epoch: 94 [20480/50000 (41%)]\tLoss: 1.135955\n",
      "Train Epoch: 94 [21760/50000 (43%)]\tLoss: 1.089774\n",
      "Train Epoch: 94 [23040/50000 (46%)]\tLoss: 1.084750\n",
      "Train Epoch: 94 [24320/50000 (49%)]\tLoss: 1.218369\n",
      "Train Epoch: 94 [25600/50000 (51%)]\tLoss: 1.032325\n",
      "Train Epoch: 94 [26880/50000 (54%)]\tLoss: 1.240527\n",
      "Train Epoch: 94 [28160/50000 (56%)]\tLoss: 1.003228\n",
      "Train Epoch: 94 [29440/50000 (59%)]\tLoss: 0.967715\n",
      "Train Epoch: 94 [30720/50000 (61%)]\tLoss: 1.003239\n",
      "Train Epoch: 94 [32000/50000 (64%)]\tLoss: 1.245594\n",
      "Train Epoch: 94 [33280/50000 (66%)]\tLoss: 1.124799\n",
      "Train Epoch: 94 [34560/50000 (69%)]\tLoss: 1.131472\n",
      "Train Epoch: 94 [35840/50000 (72%)]\tLoss: 0.991938\n",
      "Train Epoch: 94 [37120/50000 (74%)]\tLoss: 1.055746\n",
      "Train Epoch: 94 [38400/50000 (77%)]\tLoss: 1.200006\n",
      "Train Epoch: 94 [39680/50000 (79%)]\tLoss: 0.881762\n",
      "Train Epoch: 94 [40960/50000 (82%)]\tLoss: 1.237024\n",
      "Train Epoch: 94 [42240/50000 (84%)]\tLoss: 1.051040\n",
      "Train Epoch: 94 [43520/50000 (87%)]\tLoss: 1.016428\n",
      "Train Epoch: 94 [44800/50000 (90%)]\tLoss: 1.018862\n",
      "Train Epoch: 94 [46080/50000 (92%)]\tLoss: 1.175796\n",
      "Train Epoch: 94 [47360/50000 (95%)]\tLoss: 0.932747\n",
      "Train Epoch: 94 [48640/50000 (97%)]\tLoss: 1.076066\n",
      "Train Epoch: 94 [31200/50000 (100%)]\tLoss: 1.016952\n",
      "\n",
      "Test set: Avg. loss: 0.000419, Accuracy: 8234/9250 (89.02%)\n",
      "\n",
      "Train Epoch: 95 [0/50000 (0%)]\tLoss: 0.146437\n",
      "Train Epoch: 95 [1280/50000 (3%)]\tLoss: 0.784141\n",
      "Train Epoch: 95 [2560/50000 (5%)]\tLoss: 1.250422\n",
      "Train Epoch: 95 [3840/50000 (8%)]\tLoss: 1.030763\n",
      "Train Epoch: 95 [5120/50000 (10%)]\tLoss: 1.119544\n",
      "Train Epoch: 95 [6400/50000 (13%)]\tLoss: 1.239626\n",
      "Train Epoch: 95 [7680/50000 (15%)]\tLoss: 0.895624\n",
      "Train Epoch: 95 [8960/50000 (18%)]\tLoss: 0.795856\n",
      "Train Epoch: 95 [10240/50000 (20%)]\tLoss: 1.134752\n",
      "Train Epoch: 95 [11520/50000 (23%)]\tLoss: 0.942866\n",
      "Train Epoch: 95 [12800/50000 (26%)]\tLoss: 1.199562\n",
      "Train Epoch: 95 [14080/50000 (28%)]\tLoss: 0.818364\n",
      "Train Epoch: 95 [15360/50000 (31%)]\tLoss: 1.257056\n",
      "Train Epoch: 95 [16640/50000 (33%)]\tLoss: 1.007801\n",
      "Train Epoch: 95 [17920/50000 (36%)]\tLoss: 0.977139\n",
      "Train Epoch: 95 [19200/50000 (38%)]\tLoss: 1.253626\n",
      "Train Epoch: 95 [20480/50000 (41%)]\tLoss: 1.146506\n",
      "Train Epoch: 95 [21760/50000 (43%)]\tLoss: 1.225752\n",
      "Train Epoch: 95 [23040/50000 (46%)]\tLoss: 1.094315\n",
      "Train Epoch: 95 [24320/50000 (49%)]\tLoss: 1.022133\n",
      "Train Epoch: 95 [25600/50000 (51%)]\tLoss: 1.081681\n",
      "Train Epoch: 95 [26880/50000 (54%)]\tLoss: 0.994247\n",
      "Train Epoch: 95 [28160/50000 (56%)]\tLoss: 0.895580\n",
      "Train Epoch: 95 [29440/50000 (59%)]\tLoss: 1.011430\n",
      "Train Epoch: 95 [30720/50000 (61%)]\tLoss: 0.900799\n",
      "Train Epoch: 95 [32000/50000 (64%)]\tLoss: 1.157528\n",
      "Train Epoch: 95 [33280/50000 (66%)]\tLoss: 1.239858\n",
      "Train Epoch: 95 [34560/50000 (69%)]\tLoss: 1.253045\n",
      "Train Epoch: 95 [35840/50000 (72%)]\tLoss: 1.048362\n",
      "Train Epoch: 95 [37120/50000 (74%)]\tLoss: 1.168018\n",
      "Train Epoch: 95 [38400/50000 (77%)]\tLoss: 1.082961\n",
      "Train Epoch: 95 [39680/50000 (79%)]\tLoss: 0.870920\n",
      "Train Epoch: 95 [40960/50000 (82%)]\tLoss: 1.011936\n",
      "Train Epoch: 95 [42240/50000 (84%)]\tLoss: 1.134365\n",
      "Train Epoch: 95 [43520/50000 (87%)]\tLoss: 1.249897\n",
      "Train Epoch: 95 [44800/50000 (90%)]\tLoss: 1.089579\n",
      "Train Epoch: 95 [46080/50000 (92%)]\tLoss: 1.003030\n",
      "Train Epoch: 95 [47360/50000 (95%)]\tLoss: 1.229137\n",
      "Train Epoch: 95 [48640/50000 (97%)]\tLoss: 1.160751\n",
      "Train Epoch: 95 [31200/50000 (100%)]\tLoss: 1.063641\n",
      "\n",
      "Test set: Avg. loss: 0.000448, Accuracy: 8229/9250 (88.96%)\n",
      "\n",
      "Train Epoch: 96 [0/50000 (0%)]\tLoss: 0.137971\n",
      "Train Epoch: 96 [1280/50000 (3%)]\tLoss: 0.990161\n",
      "Train Epoch: 96 [2560/50000 (5%)]\tLoss: 1.215399\n",
      "Train Epoch: 96 [3840/50000 (8%)]\tLoss: 0.986639\n",
      "Train Epoch: 96 [5120/50000 (10%)]\tLoss: 1.176769\n",
      "Train Epoch: 96 [6400/50000 (13%)]\tLoss: 0.871362\n",
      "Train Epoch: 96 [7680/50000 (15%)]\tLoss: 0.926390\n",
      "Train Epoch: 96 [8960/50000 (18%)]\tLoss: 1.153653\n",
      "Train Epoch: 96 [10240/50000 (20%)]\tLoss: 1.244995\n",
      "Train Epoch: 96 [11520/50000 (23%)]\tLoss: 1.160431\n",
      "Train Epoch: 96 [12800/50000 (26%)]\tLoss: 0.923690\n",
      "Train Epoch: 96 [14080/50000 (28%)]\tLoss: 1.078013\n",
      "Train Epoch: 96 [15360/50000 (31%)]\tLoss: 1.192303\n",
      "Train Epoch: 96 [16640/50000 (33%)]\tLoss: 1.143188\n",
      "Train Epoch: 96 [17920/50000 (36%)]\tLoss: 1.052566\n",
      "Train Epoch: 96 [19200/50000 (38%)]\tLoss: 0.940262\n",
      "Train Epoch: 96 [20480/50000 (41%)]\tLoss: 1.132858\n",
      "Train Epoch: 96 [21760/50000 (43%)]\tLoss: 1.193098\n",
      "Train Epoch: 96 [23040/50000 (46%)]\tLoss: 1.122077\n",
      "Train Epoch: 96 [24320/50000 (49%)]\tLoss: 1.169937\n",
      "Train Epoch: 96 [25600/50000 (51%)]\tLoss: 0.994233\n",
      "Train Epoch: 96 [26880/50000 (54%)]\tLoss: 1.183286\n",
      "Train Epoch: 96 [28160/50000 (56%)]\tLoss: 1.054118\n",
      "Train Epoch: 96 [29440/50000 (59%)]\tLoss: 1.360534\n",
      "Train Epoch: 96 [30720/50000 (61%)]\tLoss: 0.925211\n",
      "Train Epoch: 96 [32000/50000 (64%)]\tLoss: 1.028371\n",
      "Train Epoch: 96 [33280/50000 (66%)]\tLoss: 1.191053\n",
      "Train Epoch: 96 [34560/50000 (69%)]\tLoss: 1.002349\n",
      "Train Epoch: 96 [35840/50000 (72%)]\tLoss: 1.069977\n",
      "Train Epoch: 96 [37120/50000 (74%)]\tLoss: 1.006209\n",
      "Train Epoch: 96 [38400/50000 (77%)]\tLoss: 1.022936\n",
      "Train Epoch: 96 [39680/50000 (79%)]\tLoss: 1.207153\n",
      "Train Epoch: 96 [40960/50000 (82%)]\tLoss: 1.206933\n",
      "Train Epoch: 96 [42240/50000 (84%)]\tLoss: 1.080826\n",
      "Train Epoch: 96 [43520/50000 (87%)]\tLoss: 1.032397\n",
      "Train Epoch: 96 [44800/50000 (90%)]\tLoss: 0.937044\n",
      "Train Epoch: 96 [46080/50000 (92%)]\tLoss: 1.179153\n",
      "Train Epoch: 96 [47360/50000 (95%)]\tLoss: 0.982921\n",
      "Train Epoch: 96 [48640/50000 (97%)]\tLoss: 0.939144\n",
      "Train Epoch: 96 [31200/50000 (100%)]\tLoss: 1.066557\n",
      "\n",
      "Test set: Avg. loss: 0.000435, Accuracy: 8215/9250 (88.81%)\n",
      "\n",
      "Train Epoch: 97 [0/50000 (0%)]\tLoss: 0.048674\n",
      "Train Epoch: 97 [1280/50000 (3%)]\tLoss: 1.164964\n",
      "Train Epoch: 97 [2560/50000 (5%)]\tLoss: 1.048933\n",
      "Train Epoch: 97 [3840/50000 (8%)]\tLoss: 1.085886\n",
      "Train Epoch: 97 [5120/50000 (10%)]\tLoss: 1.100030\n",
      "Train Epoch: 97 [6400/50000 (13%)]\tLoss: 1.282046\n",
      "Train Epoch: 97 [7680/50000 (15%)]\tLoss: 1.144114\n",
      "Train Epoch: 97 [8960/50000 (18%)]\tLoss: 1.031320\n",
      "Train Epoch: 97 [10240/50000 (20%)]\tLoss: 1.048254\n",
      "Train Epoch: 97 [11520/50000 (23%)]\tLoss: 1.032757\n",
      "Train Epoch: 97 [12800/50000 (26%)]\tLoss: 0.933576\n",
      "Train Epoch: 97 [14080/50000 (28%)]\tLoss: 1.050297\n",
      "Train Epoch: 97 [15360/50000 (31%)]\tLoss: 1.256924\n",
      "Train Epoch: 97 [16640/50000 (33%)]\tLoss: 1.320044\n",
      "Train Epoch: 97 [17920/50000 (36%)]\tLoss: 1.044620\n",
      "Train Epoch: 97 [19200/50000 (38%)]\tLoss: 1.311863\n",
      "Train Epoch: 97 [20480/50000 (41%)]\tLoss: 1.075365\n",
      "Train Epoch: 97 [21760/50000 (43%)]\tLoss: 1.099277\n",
      "Train Epoch: 97 [23040/50000 (46%)]\tLoss: 0.775163\n",
      "Train Epoch: 97 [24320/50000 (49%)]\tLoss: 0.774005\n",
      "Train Epoch: 97 [25600/50000 (51%)]\tLoss: 0.943249\n",
      "Train Epoch: 97 [26880/50000 (54%)]\tLoss: 1.282476\n",
      "Train Epoch: 97 [28160/50000 (56%)]\tLoss: 1.270016\n",
      "Train Epoch: 97 [29440/50000 (59%)]\tLoss: 0.986861\n",
      "Train Epoch: 97 [30720/50000 (61%)]\tLoss: 1.194045\n",
      "Train Epoch: 97 [32000/50000 (64%)]\tLoss: 0.947266\n",
      "Train Epoch: 97 [33280/50000 (66%)]\tLoss: 1.245985\n",
      "Train Epoch: 97 [34560/50000 (69%)]\tLoss: 1.296016\n",
      "Train Epoch: 97 [35840/50000 (72%)]\tLoss: 1.161866\n",
      "Train Epoch: 97 [37120/50000 (74%)]\tLoss: 1.094010\n",
      "Train Epoch: 97 [38400/50000 (77%)]\tLoss: 1.000038\n",
      "Train Epoch: 97 [39680/50000 (79%)]\tLoss: 1.158093\n",
      "Train Epoch: 97 [40960/50000 (82%)]\tLoss: 1.189366\n",
      "Train Epoch: 97 [42240/50000 (84%)]\tLoss: 1.080259\n",
      "Train Epoch: 97 [43520/50000 (87%)]\tLoss: 1.079812\n",
      "Train Epoch: 97 [44800/50000 (90%)]\tLoss: 0.907273\n",
      "Train Epoch: 97 [46080/50000 (92%)]\tLoss: 1.019280\n",
      "Train Epoch: 97 [47360/50000 (95%)]\tLoss: 1.064260\n",
      "Train Epoch: 97 [48640/50000 (97%)]\tLoss: 1.119596\n",
      "Train Epoch: 97 [31200/50000 (100%)]\tLoss: 0.959396\n",
      "\n",
      "Test set: Avg. loss: 0.000414, Accuracy: 8257/9250 (89.26%)\n",
      "\n",
      "Train Epoch: 98 [0/50000 (0%)]\tLoss: 0.068436\n",
      "Train Epoch: 98 [1280/50000 (3%)]\tLoss: 1.124530\n",
      "Train Epoch: 98 [2560/50000 (5%)]\tLoss: 1.121313\n",
      "Train Epoch: 98 [3840/50000 (8%)]\tLoss: 1.152317\n",
      "Train Epoch: 98 [5120/50000 (10%)]\tLoss: 1.087469\n",
      "Train Epoch: 98 [6400/50000 (13%)]\tLoss: 1.064768\n",
      "Train Epoch: 98 [7680/50000 (15%)]\tLoss: 1.269116\n",
      "Train Epoch: 98 [8960/50000 (18%)]\tLoss: 1.187060\n",
      "Train Epoch: 98 [10240/50000 (20%)]\tLoss: 1.198376\n",
      "Train Epoch: 98 [11520/50000 (23%)]\tLoss: 0.994954\n",
      "Train Epoch: 98 [12800/50000 (26%)]\tLoss: 1.174370\n",
      "Train Epoch: 98 [14080/50000 (28%)]\tLoss: 1.026282\n",
      "Train Epoch: 98 [15360/50000 (31%)]\tLoss: 1.135422\n",
      "Train Epoch: 98 [16640/50000 (33%)]\tLoss: 1.243100\n",
      "Train Epoch: 98 [17920/50000 (36%)]\tLoss: 1.151157\n",
      "Train Epoch: 98 [19200/50000 (38%)]\tLoss: 1.126084\n",
      "Train Epoch: 98 [20480/50000 (41%)]\tLoss: 1.121823\n",
      "Train Epoch: 98 [21760/50000 (43%)]\tLoss: 1.072335\n",
      "Train Epoch: 98 [23040/50000 (46%)]\tLoss: 1.036365\n",
      "Train Epoch: 98 [24320/50000 (49%)]\tLoss: 1.213388\n",
      "Train Epoch: 98 [25600/50000 (51%)]\tLoss: 0.955435\n",
      "Train Epoch: 98 [26880/50000 (54%)]\tLoss: 0.985826\n",
      "Train Epoch: 98 [28160/50000 (56%)]\tLoss: 1.096686\n",
      "Train Epoch: 98 [29440/50000 (59%)]\tLoss: 1.038776\n",
      "Train Epoch: 98 [30720/50000 (61%)]\tLoss: 1.039929\n",
      "Train Epoch: 98 [32000/50000 (64%)]\tLoss: 1.054503\n",
      "Train Epoch: 98 [33280/50000 (66%)]\tLoss: 1.245421\n",
      "Train Epoch: 98 [34560/50000 (69%)]\tLoss: 1.140529\n",
      "Train Epoch: 98 [35840/50000 (72%)]\tLoss: 1.080581\n",
      "Train Epoch: 98 [37120/50000 (74%)]\tLoss: 1.057470\n",
      "Train Epoch: 98 [38400/50000 (77%)]\tLoss: 0.919144\n",
      "Train Epoch: 98 [39680/50000 (79%)]\tLoss: 1.180389\n",
      "Train Epoch: 98 [40960/50000 (82%)]\tLoss: 1.277354\n",
      "Train Epoch: 98 [42240/50000 (84%)]\tLoss: 1.071454\n",
      "Train Epoch: 98 [43520/50000 (87%)]\tLoss: 1.271323\n",
      "Train Epoch: 98 [44800/50000 (90%)]\tLoss: 1.153023\n",
      "Train Epoch: 98 [46080/50000 (92%)]\tLoss: 1.106677\n",
      "Train Epoch: 98 [47360/50000 (95%)]\tLoss: 1.124182\n",
      "Train Epoch: 98 [48640/50000 (97%)]\tLoss: 0.968323\n",
      "Train Epoch: 98 [31200/50000 (100%)]\tLoss: 1.119539\n",
      "\n",
      "Test set: Avg. loss: 0.000422, Accuracy: 8285/9250 (89.57%)\n",
      "\n",
      "Train Epoch: 99 [0/50000 (0%)]\tLoss: 0.138770\n",
      "Train Epoch: 99 [1280/50000 (3%)]\tLoss: 1.092171\n",
      "Train Epoch: 99 [2560/50000 (5%)]\tLoss: 1.154332\n",
      "Train Epoch: 99 [3840/50000 (8%)]\tLoss: 1.301179\n",
      "Train Epoch: 99 [5120/50000 (10%)]\tLoss: 1.039428\n",
      "Train Epoch: 99 [6400/50000 (13%)]\tLoss: 1.067634\n",
      "Train Epoch: 99 [7680/50000 (15%)]\tLoss: 0.950797\n",
      "Train Epoch: 99 [8960/50000 (18%)]\tLoss: 0.888937\n",
      "Train Epoch: 99 [10240/50000 (20%)]\tLoss: 1.110574\n",
      "Train Epoch: 99 [11520/50000 (23%)]\tLoss: 1.191939\n",
      "Train Epoch: 99 [12800/50000 (26%)]\tLoss: 1.256635\n",
      "Train Epoch: 99 [14080/50000 (28%)]\tLoss: 1.206721\n",
      "Train Epoch: 99 [15360/50000 (31%)]\tLoss: 1.194684\n",
      "Train Epoch: 99 [16640/50000 (33%)]\tLoss: 0.950786\n",
      "Train Epoch: 99 [17920/50000 (36%)]\tLoss: 1.069664\n",
      "Train Epoch: 99 [19200/50000 (38%)]\tLoss: 1.176601\n",
      "Train Epoch: 99 [20480/50000 (41%)]\tLoss: 1.213790\n",
      "Train Epoch: 99 [21760/50000 (43%)]\tLoss: 1.185924\n",
      "Train Epoch: 99 [23040/50000 (46%)]\tLoss: 1.125765\n",
      "Train Epoch: 99 [24320/50000 (49%)]\tLoss: 1.100566\n",
      "Train Epoch: 99 [25600/50000 (51%)]\tLoss: 1.314695\n",
      "Train Epoch: 99 [26880/50000 (54%)]\tLoss: 1.167208\n",
      "Train Epoch: 99 [28160/50000 (56%)]\tLoss: 1.074048\n",
      "Train Epoch: 99 [29440/50000 (59%)]\tLoss: 1.198566\n",
      "Train Epoch: 99 [30720/50000 (61%)]\tLoss: 1.039239\n",
      "Train Epoch: 99 [32000/50000 (64%)]\tLoss: 1.200896\n",
      "Train Epoch: 99 [33280/50000 (66%)]\tLoss: 0.870407\n",
      "Train Epoch: 99 [34560/50000 (69%)]\tLoss: 0.995652\n",
      "Train Epoch: 99 [35840/50000 (72%)]\tLoss: 1.063965\n",
      "Train Epoch: 99 [37120/50000 (74%)]\tLoss: 1.221862\n",
      "Train Epoch: 99 [38400/50000 (77%)]\tLoss: 1.284857\n",
      "Train Epoch: 99 [39680/50000 (79%)]\tLoss: 1.068474\n",
      "Train Epoch: 99 [40960/50000 (82%)]\tLoss: 1.129168\n",
      "Train Epoch: 99 [42240/50000 (84%)]\tLoss: 0.984355\n",
      "Train Epoch: 99 [43520/50000 (87%)]\tLoss: 1.185024\n",
      "Train Epoch: 99 [44800/50000 (90%)]\tLoss: 1.212936\n",
      "Train Epoch: 99 [46080/50000 (92%)]\tLoss: 0.971185\n",
      "Train Epoch: 99 [47360/50000 (95%)]\tLoss: 1.232855\n",
      "Train Epoch: 99 [48640/50000 (97%)]\tLoss: 0.982502\n",
      "Train Epoch: 99 [31200/50000 (100%)]\tLoss: 1.201060\n",
      "\n",
      "Test set: Avg. loss: 0.000442, Accuracy: 8278/9250 (89.49%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLoss: 0.116972\n",
      "Train Epoch: 100 [1280/50000 (3%)]\tLoss: 0.867294\n",
      "Train Epoch: 100 [2560/50000 (5%)]\tLoss: 1.207337\n",
      "Train Epoch: 100 [3840/50000 (8%)]\tLoss: 1.053441\n",
      "Train Epoch: 100 [5120/50000 (10%)]\tLoss: 1.269016\n",
      "Train Epoch: 100 [6400/50000 (13%)]\tLoss: 1.108974\n",
      "Train Epoch: 100 [7680/50000 (15%)]\tLoss: 1.204496\n",
      "Train Epoch: 100 [8960/50000 (18%)]\tLoss: 1.033810\n",
      "Train Epoch: 100 [10240/50000 (20%)]\tLoss: 1.267035\n",
      "Train Epoch: 100 [11520/50000 (23%)]\tLoss: 1.196742\n",
      "Train Epoch: 100 [12800/50000 (26%)]\tLoss: 1.239187\n",
      "Train Epoch: 100 [14080/50000 (28%)]\tLoss: 1.067794\n",
      "Train Epoch: 100 [15360/50000 (31%)]\tLoss: 1.032632\n",
      "Train Epoch: 100 [16640/50000 (33%)]\tLoss: 1.036699\n",
      "Train Epoch: 100 [17920/50000 (36%)]\tLoss: 1.209477\n",
      "Train Epoch: 100 [19200/50000 (38%)]\tLoss: 1.151779\n",
      "Train Epoch: 100 [20480/50000 (41%)]\tLoss: 1.143312\n",
      "Train Epoch: 100 [21760/50000 (43%)]\tLoss: 1.146095\n",
      "Train Epoch: 100 [23040/50000 (46%)]\tLoss: 1.182908\n",
      "Train Epoch: 100 [24320/50000 (49%)]\tLoss: 1.164454\n",
      "Train Epoch: 100 [25600/50000 (51%)]\tLoss: 1.098226\n",
      "Train Epoch: 100 [26880/50000 (54%)]\tLoss: 0.983253\n",
      "Train Epoch: 100 [28160/50000 (56%)]\tLoss: 1.055230\n",
      "Train Epoch: 100 [29440/50000 (59%)]\tLoss: 1.051789\n",
      "Train Epoch: 100 [30720/50000 (61%)]\tLoss: 0.941193\n",
      "Train Epoch: 100 [32000/50000 (64%)]\tLoss: 1.030718\n",
      "Train Epoch: 100 [33280/50000 (66%)]\tLoss: 1.003346\n",
      "Train Epoch: 100 [34560/50000 (69%)]\tLoss: 1.109776\n",
      "Train Epoch: 100 [35840/50000 (72%)]\tLoss: 1.022939\n",
      "Train Epoch: 100 [37120/50000 (74%)]\tLoss: 1.250546\n",
      "Train Epoch: 100 [38400/50000 (77%)]\tLoss: 0.991062\n",
      "Train Epoch: 100 [39680/50000 (79%)]\tLoss: 1.219263\n",
      "Train Epoch: 100 [40960/50000 (82%)]\tLoss: 1.003061\n",
      "Train Epoch: 100 [42240/50000 (84%)]\tLoss: 1.002175\n",
      "Train Epoch: 100 [43520/50000 (87%)]\tLoss: 0.931788\n",
      "Train Epoch: 100 [44800/50000 (90%)]\tLoss: 1.051886\n",
      "Train Epoch: 100 [46080/50000 (92%)]\tLoss: 1.050045\n",
      "Train Epoch: 100 [47360/50000 (95%)]\tLoss: 1.090579\n",
      "Train Epoch: 100 [48640/50000 (97%)]\tLoss: 1.006861\n",
      "Train Epoch: 100 [31200/50000 (100%)]\tLoss: 1.254235\n",
      "\n",
      "Test set: Avg. loss: 0.000483, Accuracy: 8263/9250 (89.33%)\n",
      "\n",
      "Train Epoch: 101 [0/50000 (0%)]\tLoss: 0.080795\n",
      "Train Epoch: 101 [1280/50000 (3%)]\tLoss: 1.125415\n",
      "Train Epoch: 101 [2560/50000 (5%)]\tLoss: 1.199297\n",
      "Train Epoch: 101 [3840/50000 (8%)]\tLoss: 1.139645\n",
      "Train Epoch: 101 [5120/50000 (10%)]\tLoss: 0.935614\n",
      "Train Epoch: 101 [6400/50000 (13%)]\tLoss: 1.051108\n",
      "Train Epoch: 101 [7680/50000 (15%)]\tLoss: 1.030752\n",
      "Train Epoch: 101 [8960/50000 (18%)]\tLoss: 0.990842\n",
      "Train Epoch: 101 [10240/50000 (20%)]\tLoss: 1.160616\n",
      "Train Epoch: 101 [11520/50000 (23%)]\tLoss: 1.021383\n",
      "Train Epoch: 101 [12800/50000 (26%)]\tLoss: 1.194445\n",
      "Train Epoch: 101 [14080/50000 (28%)]\tLoss: 1.076450\n",
      "Train Epoch: 101 [15360/50000 (31%)]\tLoss: 0.941879\n",
      "Train Epoch: 101 [16640/50000 (33%)]\tLoss: 1.145242\n",
      "Train Epoch: 101 [17920/50000 (36%)]\tLoss: 1.082123\n",
      "Train Epoch: 101 [19200/50000 (38%)]\tLoss: 1.112762\n",
      "Train Epoch: 101 [20480/50000 (41%)]\tLoss: 1.199357\n",
      "Train Epoch: 101 [21760/50000 (43%)]\tLoss: 1.096116\n",
      "Train Epoch: 101 [23040/50000 (46%)]\tLoss: 0.952231\n",
      "Train Epoch: 101 [24320/50000 (49%)]\tLoss: 1.223550\n",
      "Train Epoch: 101 [25600/50000 (51%)]\tLoss: 0.910364\n",
      "Train Epoch: 101 [26880/50000 (54%)]\tLoss: 1.058163\n",
      "Train Epoch: 101 [28160/50000 (56%)]\tLoss: 1.010763\n",
      "Train Epoch: 101 [29440/50000 (59%)]\tLoss: 0.915828\n",
      "Train Epoch: 101 [30720/50000 (61%)]\tLoss: 1.081830\n",
      "Train Epoch: 101 [32000/50000 (64%)]\tLoss: 1.268690\n",
      "Train Epoch: 101 [33280/50000 (66%)]\tLoss: 0.986737\n",
      "Train Epoch: 101 [34560/50000 (69%)]\tLoss: 1.033286\n",
      "Train Epoch: 101 [35840/50000 (72%)]\tLoss: 1.228294\n",
      "Train Epoch: 101 [37120/50000 (74%)]\tLoss: 1.048967\n",
      "Train Epoch: 101 [38400/50000 (77%)]\tLoss: 1.239320\n",
      "Train Epoch: 101 [39680/50000 (79%)]\tLoss: 1.031734\n",
      "Train Epoch: 101 [40960/50000 (82%)]\tLoss: 0.989924\n",
      "Train Epoch: 101 [42240/50000 (84%)]\tLoss: 0.952944\n",
      "Train Epoch: 101 [43520/50000 (87%)]\tLoss: 1.160316\n",
      "Train Epoch: 101 [44800/50000 (90%)]\tLoss: 1.001834\n",
      "Train Epoch: 101 [46080/50000 (92%)]\tLoss: 0.875207\n",
      "Train Epoch: 101 [47360/50000 (95%)]\tLoss: 1.069250\n",
      "Train Epoch: 101 [48640/50000 (97%)]\tLoss: 1.044132\n",
      "Train Epoch: 101 [31200/50000 (100%)]\tLoss: 1.065352\n",
      "\n",
      "Test set: Avg. loss: 0.000422, Accuracy: 8190/9250 (88.54%)\n",
      "\n",
      "Train Epoch: 102 [0/50000 (0%)]\tLoss: 0.131555\n",
      "Train Epoch: 102 [1280/50000 (3%)]\tLoss: 0.983560\n",
      "Train Epoch: 102 [2560/50000 (5%)]\tLoss: 1.159868\n",
      "Train Epoch: 102 [3840/50000 (8%)]\tLoss: 1.000547\n",
      "Train Epoch: 102 [5120/50000 (10%)]\tLoss: 0.870647\n",
      "Train Epoch: 102 [6400/50000 (13%)]\tLoss: 1.028989\n",
      "Train Epoch: 102 [7680/50000 (15%)]\tLoss: 1.075984\n",
      "Train Epoch: 102 [8960/50000 (18%)]\tLoss: 1.121196\n",
      "Train Epoch: 102 [10240/50000 (20%)]\tLoss: 0.847214\n",
      "Train Epoch: 102 [11520/50000 (23%)]\tLoss: 0.983046\n",
      "Train Epoch: 102 [12800/50000 (26%)]\tLoss: 0.847144\n",
      "Train Epoch: 102 [14080/50000 (28%)]\tLoss: 1.074440\n",
      "Train Epoch: 102 [15360/50000 (31%)]\tLoss: 0.928464\n",
      "Train Epoch: 102 [16640/50000 (33%)]\tLoss: 0.950297\n",
      "Train Epoch: 102 [17920/50000 (36%)]\tLoss: 1.170548\n",
      "Train Epoch: 102 [19200/50000 (38%)]\tLoss: 1.067472\n",
      "Train Epoch: 102 [20480/50000 (41%)]\tLoss: 1.012896\n",
      "Train Epoch: 102 [21760/50000 (43%)]\tLoss: 0.987271\n",
      "Train Epoch: 102 [23040/50000 (46%)]\tLoss: 0.945311\n",
      "Train Epoch: 102 [24320/50000 (49%)]\tLoss: 1.006018\n",
      "Train Epoch: 102 [25600/50000 (51%)]\tLoss: 1.161475\n",
      "Train Epoch: 102 [26880/50000 (54%)]\tLoss: 0.835509\n",
      "Train Epoch: 102 [28160/50000 (56%)]\tLoss: 1.176973\n",
      "Train Epoch: 102 [29440/50000 (59%)]\tLoss: 1.102577\n",
      "Train Epoch: 102 [30720/50000 (61%)]\tLoss: 1.167005\n",
      "Train Epoch: 102 [32000/50000 (64%)]\tLoss: 1.103250\n",
      "Train Epoch: 102 [33280/50000 (66%)]\tLoss: 1.211710\n",
      "Train Epoch: 102 [34560/50000 (69%)]\tLoss: 0.918586\n",
      "Train Epoch: 102 [35840/50000 (72%)]\tLoss: 1.075389\n",
      "Train Epoch: 102 [37120/50000 (74%)]\tLoss: 1.103663\n",
      "Train Epoch: 102 [38400/50000 (77%)]\tLoss: 1.059181\n",
      "Train Epoch: 102 [39680/50000 (79%)]\tLoss: 1.188428\n",
      "Train Epoch: 102 [40960/50000 (82%)]\tLoss: 1.181318\n",
      "Train Epoch: 102 [42240/50000 (84%)]\tLoss: 1.262388\n",
      "Train Epoch: 102 [43520/50000 (87%)]\tLoss: 0.753606\n",
      "Train Epoch: 102 [44800/50000 (90%)]\tLoss: 1.129235\n",
      "Train Epoch: 102 [46080/50000 (92%)]\tLoss: 0.994823\n",
      "Train Epoch: 102 [47360/50000 (95%)]\tLoss: 1.110966\n",
      "Train Epoch: 102 [48640/50000 (97%)]\tLoss: 1.041366\n",
      "Train Epoch: 102 [31200/50000 (100%)]\tLoss: 1.071100\n",
      "\n",
      "Test set: Avg. loss: 0.000435, Accuracy: 8267/9250 (89.37%)\n",
      "\n",
      "Train Epoch: 103 [0/50000 (0%)]\tLoss: 0.102364\n",
      "Train Epoch: 103 [1280/50000 (3%)]\tLoss: 1.146440\n",
      "Train Epoch: 103 [2560/50000 (5%)]\tLoss: 1.078285\n",
      "Train Epoch: 103 [3840/50000 (8%)]\tLoss: 1.133937\n",
      "Train Epoch: 103 [5120/50000 (10%)]\tLoss: 0.964927\n",
      "Train Epoch: 103 [6400/50000 (13%)]\tLoss: 0.903651\n",
      "Train Epoch: 103 [7680/50000 (15%)]\tLoss: 0.963621\n",
      "Train Epoch: 103 [8960/50000 (18%)]\tLoss: 0.951258\n",
      "Train Epoch: 103 [10240/50000 (20%)]\tLoss: 0.991033\n",
      "Train Epoch: 103 [11520/50000 (23%)]\tLoss: 1.002640\n",
      "Train Epoch: 103 [12800/50000 (26%)]\tLoss: 0.953850\n",
      "Train Epoch: 103 [14080/50000 (28%)]\tLoss: 1.000201\n",
      "Train Epoch: 103 [15360/50000 (31%)]\tLoss: 0.966972\n",
      "Train Epoch: 103 [16640/50000 (33%)]\tLoss: 0.988296\n",
      "Train Epoch: 103 [17920/50000 (36%)]\tLoss: 1.020883\n",
      "Train Epoch: 103 [19200/50000 (38%)]\tLoss: 1.052164\n",
      "Train Epoch: 103 [20480/50000 (41%)]\tLoss: 1.135583\n",
      "Train Epoch: 103 [21760/50000 (43%)]\tLoss: 0.971884\n",
      "Train Epoch: 103 [23040/50000 (46%)]\tLoss: 0.953983\n",
      "Train Epoch: 103 [24320/50000 (49%)]\tLoss: 1.078325\n",
      "Train Epoch: 103 [25600/50000 (51%)]\tLoss: 1.014833\n",
      "Train Epoch: 103 [26880/50000 (54%)]\tLoss: 1.157940\n",
      "Train Epoch: 103 [28160/50000 (56%)]\tLoss: 1.174589\n",
      "Train Epoch: 103 [29440/50000 (59%)]\tLoss: 1.242886\n",
      "Train Epoch: 103 [30720/50000 (61%)]\tLoss: 1.055850\n",
      "Train Epoch: 103 [32000/50000 (64%)]\tLoss: 1.171167\n",
      "Train Epoch: 103 [33280/50000 (66%)]\tLoss: 1.114777\n",
      "Train Epoch: 103 [34560/50000 (69%)]\tLoss: 0.996786\n",
      "Train Epoch: 103 [35840/50000 (72%)]\tLoss: 1.127754\n",
      "Train Epoch: 103 [37120/50000 (74%)]\tLoss: 1.170543\n",
      "Train Epoch: 103 [38400/50000 (77%)]\tLoss: 1.115309\n",
      "Train Epoch: 103 [39680/50000 (79%)]\tLoss: 1.345662\n",
      "Train Epoch: 103 [40960/50000 (82%)]\tLoss: 0.930830\n",
      "Train Epoch: 103 [42240/50000 (84%)]\tLoss: 1.123096\n",
      "Train Epoch: 103 [43520/50000 (87%)]\tLoss: 0.877229\n",
      "Train Epoch: 103 [44800/50000 (90%)]\tLoss: 1.100648\n",
      "Train Epoch: 103 [46080/50000 (92%)]\tLoss: 1.006907\n",
      "Train Epoch: 103 [47360/50000 (95%)]\tLoss: 1.092894\n",
      "Train Epoch: 103 [48640/50000 (97%)]\tLoss: 1.121608\n",
      "Train Epoch: 103 [31200/50000 (100%)]\tLoss: 1.013792\n",
      "\n",
      "Test set: Avg. loss: 0.000398, Accuracy: 8276/9250 (89.47%)\n",
      "\n",
      "Train Epoch: 104 [0/50000 (0%)]\tLoss: 0.025095\n",
      "Train Epoch: 104 [1280/50000 (3%)]\tLoss: 1.053045\n",
      "Train Epoch: 104 [2560/50000 (5%)]\tLoss: 1.086740\n",
      "Train Epoch: 104 [3840/50000 (8%)]\tLoss: 1.074510\n",
      "Train Epoch: 104 [5120/50000 (10%)]\tLoss: 1.189760\n",
      "Train Epoch: 104 [6400/50000 (13%)]\tLoss: 1.152007\n",
      "Train Epoch: 104 [7680/50000 (15%)]\tLoss: 0.946510\n",
      "Train Epoch: 104 [8960/50000 (18%)]\tLoss: 0.997284\n",
      "Train Epoch: 104 [10240/50000 (20%)]\tLoss: 1.147730\n",
      "Train Epoch: 104 [11520/50000 (23%)]\tLoss: 1.101645\n",
      "Train Epoch: 104 [12800/50000 (26%)]\tLoss: 1.043159\n",
      "Train Epoch: 104 [14080/50000 (28%)]\tLoss: 1.190347\n",
      "Train Epoch: 104 [15360/50000 (31%)]\tLoss: 1.154089\n",
      "Train Epoch: 104 [16640/50000 (33%)]\tLoss: 0.930910\n",
      "Train Epoch: 104 [17920/50000 (36%)]\tLoss: 1.131527\n",
      "Train Epoch: 104 [19200/50000 (38%)]\tLoss: 1.186818\n",
      "Train Epoch: 104 [20480/50000 (41%)]\tLoss: 1.158118\n",
      "Train Epoch: 104 [21760/50000 (43%)]\tLoss: 1.029420\n",
      "Train Epoch: 104 [23040/50000 (46%)]\tLoss: 1.110909\n",
      "Train Epoch: 104 [24320/50000 (49%)]\tLoss: 0.955513\n",
      "Train Epoch: 104 [25600/50000 (51%)]\tLoss: 1.077020\n",
      "Train Epoch: 104 [26880/50000 (54%)]\tLoss: 1.186756\n",
      "Train Epoch: 104 [28160/50000 (56%)]\tLoss: 1.181532\n",
      "Train Epoch: 104 [29440/50000 (59%)]\tLoss: 1.130362\n",
      "Train Epoch: 104 [30720/50000 (61%)]\tLoss: 1.133499\n",
      "Train Epoch: 104 [32000/50000 (64%)]\tLoss: 1.209552\n",
      "Train Epoch: 104 [33280/50000 (66%)]\tLoss: 0.941569\n",
      "Train Epoch: 104 [34560/50000 (69%)]\tLoss: 1.222331\n",
      "Train Epoch: 104 [35840/50000 (72%)]\tLoss: 1.261605\n",
      "Train Epoch: 104 [37120/50000 (74%)]\tLoss: 0.965662\n",
      "Train Epoch: 104 [38400/50000 (77%)]\tLoss: 0.993113\n",
      "Train Epoch: 104 [39680/50000 (79%)]\tLoss: 1.170840\n",
      "Train Epoch: 104 [40960/50000 (82%)]\tLoss: 0.905907\n",
      "Train Epoch: 104 [42240/50000 (84%)]\tLoss: 1.112783\n",
      "Train Epoch: 104 [43520/50000 (87%)]\tLoss: 0.858211\n",
      "Train Epoch: 104 [44800/50000 (90%)]\tLoss: 1.236479\n",
      "Train Epoch: 104 [46080/50000 (92%)]\tLoss: 1.006518\n",
      "Train Epoch: 104 [47360/50000 (95%)]\tLoss: 1.041277\n",
      "Train Epoch: 104 [48640/50000 (97%)]\tLoss: 1.187911\n",
      "Train Epoch: 104 [31200/50000 (100%)]\tLoss: 0.958491\n",
      "\n",
      "Test set: Avg. loss: 0.000398, Accuracy: 8287/9250 (89.59%)\n",
      "\n",
      "Train Epoch: 105 [0/50000 (0%)]\tLoss: 0.076066\n",
      "Train Epoch: 105 [1280/50000 (3%)]\tLoss: 1.010586\n",
      "Train Epoch: 105 [2560/50000 (5%)]\tLoss: 1.119914\n",
      "Train Epoch: 105 [3840/50000 (8%)]\tLoss: 1.161210\n",
      "Train Epoch: 105 [5120/50000 (10%)]\tLoss: 1.157188\n",
      "Train Epoch: 105 [6400/50000 (13%)]\tLoss: 1.023890\n",
      "Train Epoch: 105 [7680/50000 (15%)]\tLoss: 0.936658\n",
      "Train Epoch: 105 [8960/50000 (18%)]\tLoss: 1.052205\n",
      "Train Epoch: 105 [10240/50000 (20%)]\tLoss: 0.823209\n",
      "Train Epoch: 105 [11520/50000 (23%)]\tLoss: 1.042456\n",
      "Train Epoch: 105 [12800/50000 (26%)]\tLoss: 1.141888\n",
      "Train Epoch: 105 [14080/50000 (28%)]\tLoss: 1.053274\n",
      "Train Epoch: 105 [15360/50000 (31%)]\tLoss: 1.051429\n",
      "Train Epoch: 105 [16640/50000 (33%)]\tLoss: 1.209388\n",
      "Train Epoch: 105 [17920/50000 (36%)]\tLoss: 1.072537\n",
      "Train Epoch: 105 [19200/50000 (38%)]\tLoss: 1.191749\n",
      "Train Epoch: 105 [20480/50000 (41%)]\tLoss: 1.225194\n",
      "Train Epoch: 105 [21760/50000 (43%)]\tLoss: 1.240984\n",
      "Train Epoch: 105 [23040/50000 (46%)]\tLoss: 1.164661\n",
      "Train Epoch: 105 [24320/50000 (49%)]\tLoss: 1.188525\n",
      "Train Epoch: 105 [25600/50000 (51%)]\tLoss: 1.161881\n",
      "Train Epoch: 105 [26880/50000 (54%)]\tLoss: 1.150583\n",
      "Train Epoch: 105 [28160/50000 (56%)]\tLoss: 1.031139\n",
      "Train Epoch: 105 [29440/50000 (59%)]\tLoss: 1.013988\n",
      "Train Epoch: 105 [30720/50000 (61%)]\tLoss: 1.148338\n",
      "Train Epoch: 105 [32000/50000 (64%)]\tLoss: 1.147843\n",
      "Train Epoch: 105 [33280/50000 (66%)]\tLoss: 1.232875\n",
      "Train Epoch: 105 [34560/50000 (69%)]\tLoss: 1.183920\n",
      "Train Epoch: 105 [35840/50000 (72%)]\tLoss: 0.954931\n",
      "Train Epoch: 105 [37120/50000 (74%)]\tLoss: 0.997105\n",
      "Train Epoch: 105 [38400/50000 (77%)]\tLoss: 1.155557\n",
      "Train Epoch: 105 [39680/50000 (79%)]\tLoss: 0.886511\n",
      "Train Epoch: 105 [40960/50000 (82%)]\tLoss: 1.042760\n",
      "Train Epoch: 105 [42240/50000 (84%)]\tLoss: 0.989429\n",
      "Train Epoch: 105 [43520/50000 (87%)]\tLoss: 1.042851\n",
      "Train Epoch: 105 [44800/50000 (90%)]\tLoss: 1.355078\n",
      "Train Epoch: 105 [46080/50000 (92%)]\tLoss: 1.065105\n",
      "Train Epoch: 105 [47360/50000 (95%)]\tLoss: 1.206018\n",
      "Train Epoch: 105 [48640/50000 (97%)]\tLoss: 1.066269\n",
      "Train Epoch: 105 [31200/50000 (100%)]\tLoss: 0.928526\n",
      "\n",
      "Test set: Avg. loss: 0.000412, Accuracy: 8276/9250 (89.47%)\n",
      "\n",
      "Train Epoch: 106 [0/50000 (0%)]\tLoss: 0.108823\n",
      "Train Epoch: 106 [1280/50000 (3%)]\tLoss: 0.943094\n",
      "Train Epoch: 106 [2560/50000 (5%)]\tLoss: 1.159110\n",
      "Train Epoch: 106 [3840/50000 (8%)]\tLoss: 1.054730\n",
      "Train Epoch: 106 [5120/50000 (10%)]\tLoss: 1.201301\n",
      "Train Epoch: 106 [6400/50000 (13%)]\tLoss: 1.081662\n",
      "Train Epoch: 106 [7680/50000 (15%)]\tLoss: 1.065528\n",
      "Train Epoch: 106 [8960/50000 (18%)]\tLoss: 0.929380\n",
      "Train Epoch: 106 [10240/50000 (20%)]\tLoss: 1.084283\n",
      "Train Epoch: 106 [11520/50000 (23%)]\tLoss: 1.115074\n",
      "Train Epoch: 106 [12800/50000 (26%)]\tLoss: 1.190783\n",
      "Train Epoch: 106 [14080/50000 (28%)]\tLoss: 1.046954\n",
      "Train Epoch: 106 [15360/50000 (31%)]\tLoss: 1.161279\n",
      "Train Epoch: 106 [16640/50000 (33%)]\tLoss: 0.970382\n",
      "Train Epoch: 106 [17920/50000 (36%)]\tLoss: 1.005550\n",
      "Train Epoch: 106 [19200/50000 (38%)]\tLoss: 1.001754\n",
      "Train Epoch: 106 [20480/50000 (41%)]\tLoss: 1.121721\n",
      "Train Epoch: 106 [21760/50000 (43%)]\tLoss: 1.116140\n",
      "Train Epoch: 106 [23040/50000 (46%)]\tLoss: 1.244276\n",
      "Train Epoch: 106 [24320/50000 (49%)]\tLoss: 1.174468\n",
      "Train Epoch: 106 [25600/50000 (51%)]\tLoss: 1.115919\n",
      "Train Epoch: 106 [26880/50000 (54%)]\tLoss: 1.049623\n",
      "Train Epoch: 106 [28160/50000 (56%)]\tLoss: 0.949331\n",
      "Train Epoch: 106 [29440/50000 (59%)]\tLoss: 1.096466\n",
      "Train Epoch: 106 [30720/50000 (61%)]\tLoss: 0.861799\n",
      "Train Epoch: 106 [32000/50000 (64%)]\tLoss: 1.295853\n",
      "Train Epoch: 106 [33280/50000 (66%)]\tLoss: 1.089998\n",
      "Train Epoch: 106 [34560/50000 (69%)]\tLoss: 1.078770\n",
      "Train Epoch: 106 [35840/50000 (72%)]\tLoss: 1.123366\n",
      "Train Epoch: 106 [37120/50000 (74%)]\tLoss: 1.150542\n",
      "Train Epoch: 106 [38400/50000 (77%)]\tLoss: 1.088468\n",
      "Train Epoch: 106 [39680/50000 (79%)]\tLoss: 1.155085\n",
      "Train Epoch: 106 [40960/50000 (82%)]\tLoss: 1.119478\n",
      "Train Epoch: 106 [42240/50000 (84%)]\tLoss: 1.050635\n",
      "Train Epoch: 106 [43520/50000 (87%)]\tLoss: 0.973859\n",
      "Train Epoch: 106 [44800/50000 (90%)]\tLoss: 1.194122\n",
      "Train Epoch: 106 [46080/50000 (92%)]\tLoss: 1.141215\n",
      "Train Epoch: 106 [47360/50000 (95%)]\tLoss: 1.130709\n",
      "Train Epoch: 106 [48640/50000 (97%)]\tLoss: 1.143237\n",
      "Train Epoch: 106 [31200/50000 (100%)]\tLoss: 0.792979\n",
      "\n",
      "Test set: Avg. loss: 0.000366, Accuracy: 8280/9250 (89.51%)\n",
      "\n",
      "Train Epoch: 107 [0/50000 (0%)]\tLoss: 0.131992\n",
      "Train Epoch: 107 [1280/50000 (3%)]\tLoss: 1.258907\n",
      "Train Epoch: 107 [2560/50000 (5%)]\tLoss: 1.020424\n",
      "Train Epoch: 107 [3840/50000 (8%)]\tLoss: 1.127656\n",
      "Train Epoch: 107 [5120/50000 (10%)]\tLoss: 1.078551\n",
      "Train Epoch: 107 [6400/50000 (13%)]\tLoss: 0.980720\n",
      "Train Epoch: 107 [7680/50000 (15%)]\tLoss: 0.924969\n",
      "Train Epoch: 107 [8960/50000 (18%)]\tLoss: 1.040232\n",
      "Train Epoch: 107 [10240/50000 (20%)]\tLoss: 1.155855\n",
      "Train Epoch: 107 [11520/50000 (23%)]\tLoss: 1.112204\n",
      "Train Epoch: 107 [12800/50000 (26%)]\tLoss: 1.077626\n",
      "Train Epoch: 107 [14080/50000 (28%)]\tLoss: 0.939348\n",
      "Train Epoch: 107 [15360/50000 (31%)]\tLoss: 0.876582\n",
      "Train Epoch: 107 [16640/50000 (33%)]\tLoss: 1.140760\n",
      "Train Epoch: 107 [17920/50000 (36%)]\tLoss: 1.037406\n",
      "Train Epoch: 107 [19200/50000 (38%)]\tLoss: 0.870231\n",
      "Train Epoch: 107 [20480/50000 (41%)]\tLoss: 1.193193\n",
      "Train Epoch: 107 [21760/50000 (43%)]\tLoss: 0.812758\n",
      "Train Epoch: 107 [23040/50000 (46%)]\tLoss: 1.058093\n",
      "Train Epoch: 107 [24320/50000 (49%)]\tLoss: 1.122995\n",
      "Train Epoch: 107 [25600/50000 (51%)]\tLoss: 1.050712\n",
      "Train Epoch: 107 [26880/50000 (54%)]\tLoss: 1.026909\n",
      "Train Epoch: 107 [28160/50000 (56%)]\tLoss: 1.141384\n",
      "Train Epoch: 107 [29440/50000 (59%)]\tLoss: 1.153859\n",
      "Train Epoch: 107 [30720/50000 (61%)]\tLoss: 0.985678\n",
      "Train Epoch: 107 [32000/50000 (64%)]\tLoss: 0.908918\n",
      "Train Epoch: 107 [33280/50000 (66%)]\tLoss: 1.167811\n",
      "Train Epoch: 107 [34560/50000 (69%)]\tLoss: 0.938113\n",
      "Train Epoch: 107 [35840/50000 (72%)]\tLoss: 1.024459\n",
      "Train Epoch: 107 [37120/50000 (74%)]\tLoss: 1.039363\n",
      "Train Epoch: 107 [38400/50000 (77%)]\tLoss: 1.163039\n",
      "Train Epoch: 107 [39680/50000 (79%)]\tLoss: 1.085382\n",
      "Train Epoch: 107 [40960/50000 (82%)]\tLoss: 1.230358\n",
      "Train Epoch: 107 [42240/50000 (84%)]\tLoss: 1.046900\n",
      "Train Epoch: 107 [43520/50000 (87%)]\tLoss: 0.988076\n",
      "Train Epoch: 107 [44800/50000 (90%)]\tLoss: 1.149803\n",
      "Train Epoch: 107 [46080/50000 (92%)]\tLoss: 0.889068\n",
      "Train Epoch: 107 [47360/50000 (95%)]\tLoss: 1.323124\n",
      "Train Epoch: 107 [48640/50000 (97%)]\tLoss: 1.110081\n",
      "Train Epoch: 107 [31200/50000 (100%)]\tLoss: 0.951961\n",
      "\n",
      "Test set: Avg. loss: 0.000389, Accuracy: 8292/9250 (89.64%)\n",
      "\n",
      "Train Epoch: 108 [0/50000 (0%)]\tLoss: 0.102249\n",
      "Train Epoch: 108 [1280/50000 (3%)]\tLoss: 0.874902\n",
      "Train Epoch: 108 [2560/50000 (5%)]\tLoss: 0.975102\n",
      "Train Epoch: 108 [3840/50000 (8%)]\tLoss: 1.026676\n",
      "Train Epoch: 108 [5120/50000 (10%)]\tLoss: 1.001898\n",
      "Train Epoch: 108 [6400/50000 (13%)]\tLoss: 1.210934\n",
      "Train Epoch: 108 [7680/50000 (15%)]\tLoss: 1.216788\n",
      "Train Epoch: 108 [8960/50000 (18%)]\tLoss: 1.024301\n",
      "Train Epoch: 108 [10240/50000 (20%)]\tLoss: 0.900124\n",
      "Train Epoch: 108 [11520/50000 (23%)]\tLoss: 1.213697\n",
      "Train Epoch: 108 [12800/50000 (26%)]\tLoss: 1.097052\n",
      "Train Epoch: 108 [14080/50000 (28%)]\tLoss: 0.963950\n",
      "Train Epoch: 108 [15360/50000 (31%)]\tLoss: 0.989163\n",
      "Train Epoch: 108 [16640/50000 (33%)]\tLoss: 0.892860\n",
      "Train Epoch: 108 [17920/50000 (36%)]\tLoss: 0.925780\n",
      "Train Epoch: 108 [19200/50000 (38%)]\tLoss: 1.046287\n",
      "Train Epoch: 108 [20480/50000 (41%)]\tLoss: 1.165979\n",
      "Train Epoch: 108 [21760/50000 (43%)]\tLoss: 1.037511\n",
      "Train Epoch: 108 [23040/50000 (46%)]\tLoss: 1.312421\n",
      "Train Epoch: 108 [24320/50000 (49%)]\tLoss: 1.100167\n",
      "Train Epoch: 108 [25600/50000 (51%)]\tLoss: 1.127858\n",
      "Train Epoch: 108 [26880/50000 (54%)]\tLoss: 1.009785\n",
      "Train Epoch: 108 [28160/50000 (56%)]\tLoss: 0.972176\n",
      "Train Epoch: 108 [29440/50000 (59%)]\tLoss: 0.880638\n",
      "Train Epoch: 108 [30720/50000 (61%)]\tLoss: 0.890767\n",
      "Train Epoch: 108 [32000/50000 (64%)]\tLoss: 1.060040\n",
      "Train Epoch: 108 [33280/50000 (66%)]\tLoss: 1.018203\n",
      "Train Epoch: 108 [34560/50000 (69%)]\tLoss: 1.254595\n",
      "Train Epoch: 108 [35840/50000 (72%)]\tLoss: 1.026899\n",
      "Train Epoch: 108 [37120/50000 (74%)]\tLoss: 1.113602\n",
      "Train Epoch: 108 [38400/50000 (77%)]\tLoss: 0.957667\n",
      "Train Epoch: 108 [39680/50000 (79%)]\tLoss: 0.854327\n",
      "Train Epoch: 108 [40960/50000 (82%)]\tLoss: 0.877848\n",
      "Train Epoch: 108 [42240/50000 (84%)]\tLoss: 0.941514\n",
      "Train Epoch: 108 [43520/50000 (87%)]\tLoss: 1.022656\n",
      "Train Epoch: 108 [44800/50000 (90%)]\tLoss: 1.114891\n",
      "Train Epoch: 108 [46080/50000 (92%)]\tLoss: 0.871881\n",
      "Train Epoch: 108 [47360/50000 (95%)]\tLoss: 0.911217\n",
      "Train Epoch: 108 [48640/50000 (97%)]\tLoss: 0.948869\n",
      "Train Epoch: 108 [31200/50000 (100%)]\tLoss: 1.017201\n",
      "\n",
      "Test set: Avg. loss: 0.000430, Accuracy: 8269/9250 (89.39%)\n",
      "\n",
      "Train Epoch: 109 [0/50000 (0%)]\tLoss: 0.142503\n",
      "Train Epoch: 109 [1280/50000 (3%)]\tLoss: 0.988848\n",
      "Train Epoch: 109 [2560/50000 (5%)]\tLoss: 1.052101\n",
      "Train Epoch: 109 [3840/50000 (8%)]\tLoss: 0.986844\n",
      "Train Epoch: 109 [5120/50000 (10%)]\tLoss: 0.921373\n",
      "Train Epoch: 109 [6400/50000 (13%)]\tLoss: 1.071351\n",
      "Train Epoch: 109 [7680/50000 (15%)]\tLoss: 1.003232\n",
      "Train Epoch: 109 [8960/50000 (18%)]\tLoss: 1.052748\n",
      "Train Epoch: 109 [10240/50000 (20%)]\tLoss: 1.132763\n",
      "Train Epoch: 109 [11520/50000 (23%)]\tLoss: 1.115571\n",
      "Train Epoch: 109 [12800/50000 (26%)]\tLoss: 1.144925\n",
      "Train Epoch: 109 [14080/50000 (28%)]\tLoss: 1.188420\n",
      "Train Epoch: 109 [15360/50000 (31%)]\tLoss: 0.883173\n",
      "Train Epoch: 109 [16640/50000 (33%)]\tLoss: 1.133917\n",
      "Train Epoch: 109 [17920/50000 (36%)]\tLoss: 1.170704\n",
      "Train Epoch: 109 [19200/50000 (38%)]\tLoss: 1.062302\n",
      "Train Epoch: 109 [20480/50000 (41%)]\tLoss: 1.101687\n",
      "Train Epoch: 109 [21760/50000 (43%)]\tLoss: 0.947085\n",
      "Train Epoch: 109 [23040/50000 (46%)]\tLoss: 1.109326\n",
      "Train Epoch: 109 [24320/50000 (49%)]\tLoss: 1.027288\n",
      "Train Epoch: 109 [25600/50000 (51%)]\tLoss: 1.079267\n",
      "Train Epoch: 109 [26880/50000 (54%)]\tLoss: 0.989598\n",
      "Train Epoch: 109 [28160/50000 (56%)]\tLoss: 1.110451\n",
      "Train Epoch: 109 [29440/50000 (59%)]\tLoss: 0.891304\n",
      "Train Epoch: 109 [30720/50000 (61%)]\tLoss: 0.962027\n",
      "Train Epoch: 109 [32000/50000 (64%)]\tLoss: 0.879076\n",
      "Train Epoch: 109 [33280/50000 (66%)]\tLoss: 0.992413\n",
      "Train Epoch: 109 [34560/50000 (69%)]\tLoss: 1.225715\n",
      "Train Epoch: 109 [35840/50000 (72%)]\tLoss: 1.122489\n",
      "Train Epoch: 109 [37120/50000 (74%)]\tLoss: 1.124009\n",
      "Train Epoch: 109 [38400/50000 (77%)]\tLoss: 1.129132\n",
      "Train Epoch: 109 [39680/50000 (79%)]\tLoss: 0.901290\n",
      "Train Epoch: 109 [40960/50000 (82%)]\tLoss: 1.088419\n",
      "Train Epoch: 109 [42240/50000 (84%)]\tLoss: 1.029832\n",
      "Train Epoch: 109 [43520/50000 (87%)]\tLoss: 0.976536\n",
      "Train Epoch: 109 [44800/50000 (90%)]\tLoss: 1.125061\n",
      "Train Epoch: 109 [46080/50000 (92%)]\tLoss: 0.999667\n",
      "Train Epoch: 109 [47360/50000 (95%)]\tLoss: 1.084279\n",
      "Train Epoch: 109 [48640/50000 (97%)]\tLoss: 0.940255\n",
      "Train Epoch: 109 [31200/50000 (100%)]\tLoss: 0.917241\n",
      "\n",
      "Test set: Avg. loss: 0.000396, Accuracy: 8296/9250 (89.69%)\n",
      "\n",
      "Train Epoch: 110 [0/50000 (0%)]\tLoss: 0.133553\n",
      "Train Epoch: 110 [1280/50000 (3%)]\tLoss: 0.860753\n",
      "Train Epoch: 110 [2560/50000 (5%)]\tLoss: 1.029507\n",
      "Train Epoch: 110 [3840/50000 (8%)]\tLoss: 1.010195\n",
      "Train Epoch: 110 [5120/50000 (10%)]\tLoss: 1.118640\n",
      "Train Epoch: 110 [6400/50000 (13%)]\tLoss: 0.853748\n",
      "Train Epoch: 110 [7680/50000 (15%)]\tLoss: 1.055352\n",
      "Train Epoch: 110 [8960/50000 (18%)]\tLoss: 1.200740\n",
      "Train Epoch: 110 [10240/50000 (20%)]\tLoss: 1.023940\n",
      "Train Epoch: 110 [11520/50000 (23%)]\tLoss: 0.683708\n",
      "Train Epoch: 110 [12800/50000 (26%)]\tLoss: 1.100939\n",
      "Train Epoch: 110 [14080/50000 (28%)]\tLoss: 1.253766\n",
      "Train Epoch: 110 [15360/50000 (31%)]\tLoss: 1.123333\n",
      "Train Epoch: 110 [16640/50000 (33%)]\tLoss: 1.072292\n",
      "Train Epoch: 110 [17920/50000 (36%)]\tLoss: 0.892933\n",
      "Train Epoch: 110 [19200/50000 (38%)]\tLoss: 1.166840\n",
      "Train Epoch: 110 [20480/50000 (41%)]\tLoss: 1.116223\n",
      "Train Epoch: 110 [21760/50000 (43%)]\tLoss: 1.116603\n",
      "Train Epoch: 110 [23040/50000 (46%)]\tLoss: 1.187748\n",
      "Train Epoch: 110 [24320/50000 (49%)]\tLoss: 1.207395\n",
      "Train Epoch: 110 [25600/50000 (51%)]\tLoss: 0.919973\n",
      "Train Epoch: 110 [26880/50000 (54%)]\tLoss: 1.176826\n",
      "Train Epoch: 110 [28160/50000 (56%)]\tLoss: 0.950089\n",
      "Train Epoch: 110 [29440/50000 (59%)]\tLoss: 1.192051\n",
      "Train Epoch: 110 [30720/50000 (61%)]\tLoss: 1.031624\n",
      "Train Epoch: 110 [32000/50000 (64%)]\tLoss: 0.803789\n",
      "Train Epoch: 110 [33280/50000 (66%)]\tLoss: 1.085942\n",
      "Train Epoch: 110 [34560/50000 (69%)]\tLoss: 1.289883\n",
      "Train Epoch: 110 [35840/50000 (72%)]\tLoss: 1.202304\n",
      "Train Epoch: 110 [37120/50000 (74%)]\tLoss: 1.100626\n",
      "Train Epoch: 110 [38400/50000 (77%)]\tLoss: 1.173666\n",
      "Train Epoch: 110 [39680/50000 (79%)]\tLoss: 1.070952\n",
      "Train Epoch: 110 [40960/50000 (82%)]\tLoss: 1.095287\n",
      "Train Epoch: 110 [42240/50000 (84%)]\tLoss: 1.142309\n",
      "Train Epoch: 110 [43520/50000 (87%)]\tLoss: 1.152703\n",
      "Train Epoch: 110 [44800/50000 (90%)]\tLoss: 1.035586\n",
      "Train Epoch: 110 [46080/50000 (92%)]\tLoss: 0.793085\n",
      "Train Epoch: 110 [47360/50000 (95%)]\tLoss: 1.153247\n",
      "Train Epoch: 110 [48640/50000 (97%)]\tLoss: 1.138341\n",
      "Train Epoch: 110 [31200/50000 (100%)]\tLoss: 1.107305\n",
      "\n",
      "Test set: Avg. loss: 0.000412, Accuracy: 8276/9250 (89.47%)\n",
      "\n",
      "Train Epoch: 111 [0/50000 (0%)]\tLoss: 0.102253\n",
      "Train Epoch: 111 [1280/50000 (3%)]\tLoss: 0.855450\n",
      "Train Epoch: 111 [2560/50000 (5%)]\tLoss: 0.994029\n",
      "Train Epoch: 111 [3840/50000 (8%)]\tLoss: 0.930455\n",
      "Train Epoch: 111 [5120/50000 (10%)]\tLoss: 1.108593\n",
      "Train Epoch: 111 [6400/50000 (13%)]\tLoss: 1.121223\n",
      "Train Epoch: 111 [7680/50000 (15%)]\tLoss: 1.081234\n",
      "Train Epoch: 111 [8960/50000 (18%)]\tLoss: 1.057655\n",
      "Train Epoch: 111 [10240/50000 (20%)]\tLoss: 1.101248\n",
      "Train Epoch: 111 [11520/50000 (23%)]\tLoss: 1.249917\n",
      "Train Epoch: 111 [12800/50000 (26%)]\tLoss: 1.135960\n",
      "Train Epoch: 111 [14080/50000 (28%)]\tLoss: 1.076230\n",
      "Train Epoch: 111 [15360/50000 (31%)]\tLoss: 1.006415\n",
      "Train Epoch: 111 [16640/50000 (33%)]\tLoss: 1.154685\n",
      "Train Epoch: 111 [17920/50000 (36%)]\tLoss: 1.367399\n",
      "Train Epoch: 111 [19200/50000 (38%)]\tLoss: 1.114172\n",
      "Train Epoch: 111 [20480/50000 (41%)]\tLoss: 1.096416\n",
      "Train Epoch: 111 [21760/50000 (43%)]\tLoss: 1.234740\n",
      "Train Epoch: 111 [23040/50000 (46%)]\tLoss: 1.145796\n",
      "Train Epoch: 111 [24320/50000 (49%)]\tLoss: 1.190639\n",
      "Train Epoch: 111 [25600/50000 (51%)]\tLoss: 1.183739\n",
      "Train Epoch: 111 [26880/50000 (54%)]\tLoss: 1.045841\n",
      "Train Epoch: 111 [28160/50000 (56%)]\tLoss: 1.242804\n",
      "Train Epoch: 111 [29440/50000 (59%)]\tLoss: 1.148988\n",
      "Train Epoch: 111 [30720/50000 (61%)]\tLoss: 1.153036\n",
      "Train Epoch: 111 [32000/50000 (64%)]\tLoss: 1.008418\n",
      "Train Epoch: 111 [33280/50000 (66%)]\tLoss: 1.201871\n",
      "Train Epoch: 111 [34560/50000 (69%)]\tLoss: 0.966553\n",
      "Train Epoch: 111 [35840/50000 (72%)]\tLoss: 1.067882\n",
      "Train Epoch: 111 [37120/50000 (74%)]\tLoss: 1.051052\n",
      "Train Epoch: 111 [38400/50000 (77%)]\tLoss: 1.014577\n",
      "Train Epoch: 111 [39680/50000 (79%)]\tLoss: 1.070691\n",
      "Train Epoch: 111 [40960/50000 (82%)]\tLoss: 1.096205\n",
      "Train Epoch: 111 [42240/50000 (84%)]\tLoss: 1.031211\n",
      "Train Epoch: 111 [43520/50000 (87%)]\tLoss: 1.012576\n",
      "Train Epoch: 111 [44800/50000 (90%)]\tLoss: 0.825517\n",
      "Train Epoch: 111 [46080/50000 (92%)]\tLoss: 1.166692\n",
      "Train Epoch: 111 [47360/50000 (95%)]\tLoss: 0.831184\n",
      "Train Epoch: 111 [48640/50000 (97%)]\tLoss: 1.104843\n",
      "Train Epoch: 111 [31200/50000 (100%)]\tLoss: 1.113033\n",
      "\n",
      "Test set: Avg. loss: 0.000407, Accuracy: 8273/9250 (89.44%)\n",
      "\n",
      "Train Epoch: 112 [0/50000 (0%)]\tLoss: 0.095941\n",
      "Train Epoch: 112 [1280/50000 (3%)]\tLoss: 1.096860\n",
      "Train Epoch: 112 [2560/50000 (5%)]\tLoss: 1.120086\n",
      "Train Epoch: 112 [3840/50000 (8%)]\tLoss: 1.041287\n",
      "Train Epoch: 112 [5120/50000 (10%)]\tLoss: 1.226455\n",
      "Train Epoch: 112 [6400/50000 (13%)]\tLoss: 1.045361\n",
      "Train Epoch: 112 [7680/50000 (15%)]\tLoss: 1.110567\n",
      "Train Epoch: 112 [8960/50000 (18%)]\tLoss: 0.900493\n",
      "Train Epoch: 112 [10240/50000 (20%)]\tLoss: 1.216778\n",
      "Train Epoch: 112 [11520/50000 (23%)]\tLoss: 1.277646\n",
      "Train Epoch: 112 [12800/50000 (26%)]\tLoss: 0.949663\n",
      "Train Epoch: 112 [14080/50000 (28%)]\tLoss: 1.225883\n",
      "Train Epoch: 112 [15360/50000 (31%)]\tLoss: 1.179912\n",
      "Train Epoch: 112 [16640/50000 (33%)]\tLoss: 1.075483\n",
      "Train Epoch: 112 [17920/50000 (36%)]\tLoss: 1.159714\n",
      "Train Epoch: 112 [19200/50000 (38%)]\tLoss: 1.311425\n",
      "Train Epoch: 112 [20480/50000 (41%)]\tLoss: 1.184801\n",
      "Train Epoch: 112 [21760/50000 (43%)]\tLoss: 1.195543\n",
      "Train Epoch: 112 [23040/50000 (46%)]\tLoss: 1.101386\n",
      "Train Epoch: 112 [24320/50000 (49%)]\tLoss: 1.035925\n",
      "Train Epoch: 112 [25600/50000 (51%)]\tLoss: 1.061351\n",
      "Train Epoch: 112 [26880/50000 (54%)]\tLoss: 0.802323\n",
      "Train Epoch: 112 [28160/50000 (56%)]\tLoss: 1.218155\n",
      "Train Epoch: 112 [29440/50000 (59%)]\tLoss: 1.162940\n",
      "Train Epoch: 112 [30720/50000 (61%)]\tLoss: 0.998402\n",
      "Train Epoch: 112 [32000/50000 (64%)]\tLoss: 1.111876\n",
      "Train Epoch: 112 [33280/50000 (66%)]\tLoss: 1.231838\n",
      "Train Epoch: 112 [34560/50000 (69%)]\tLoss: 1.148025\n",
      "Train Epoch: 112 [35840/50000 (72%)]\tLoss: 1.019092\n",
      "Train Epoch: 112 [37120/50000 (74%)]\tLoss: 0.920835\n",
      "Train Epoch: 112 [38400/50000 (77%)]\tLoss: 1.234791\n",
      "Train Epoch: 112 [39680/50000 (79%)]\tLoss: 1.000241\n",
      "Train Epoch: 112 [40960/50000 (82%)]\tLoss: 1.083346\n",
      "Train Epoch: 112 [42240/50000 (84%)]\tLoss: 0.974882\n",
      "Train Epoch: 112 [43520/50000 (87%)]\tLoss: 1.026938\n",
      "Train Epoch: 112 [44800/50000 (90%)]\tLoss: 1.070741\n",
      "Train Epoch: 112 [46080/50000 (92%)]\tLoss: 1.044947\n",
      "Train Epoch: 112 [47360/50000 (95%)]\tLoss: 0.871489\n",
      "Train Epoch: 112 [48640/50000 (97%)]\tLoss: 1.033173\n",
      "Train Epoch: 112 [31200/50000 (100%)]\tLoss: 1.050840\n",
      "\n",
      "Test set: Avg. loss: 0.000397, Accuracy: 8334/9250 (90.10%)\n",
      "\n",
      "Train Epoch: 113 [0/50000 (0%)]\tLoss: 0.143699\n",
      "Train Epoch: 113 [1280/50000 (3%)]\tLoss: 1.092808\n",
      "Train Epoch: 113 [2560/50000 (5%)]\tLoss: 0.891696\n",
      "Train Epoch: 113 [3840/50000 (8%)]\tLoss: 1.074010\n",
      "Train Epoch: 113 [5120/50000 (10%)]\tLoss: 1.210316\n",
      "Train Epoch: 113 [6400/50000 (13%)]\tLoss: 0.992099\n",
      "Train Epoch: 113 [7680/50000 (15%)]\tLoss: 0.899745\n",
      "Train Epoch: 113 [8960/50000 (18%)]\tLoss: 0.895232\n",
      "Train Epoch: 113 [10240/50000 (20%)]\tLoss: 1.084190\n",
      "Train Epoch: 113 [11520/50000 (23%)]\tLoss: 1.166650\n",
      "Train Epoch: 113 [12800/50000 (26%)]\tLoss: 1.016080\n",
      "Train Epoch: 113 [14080/50000 (28%)]\tLoss: 1.027053\n",
      "Train Epoch: 113 [15360/50000 (31%)]\tLoss: 1.123376\n",
      "Train Epoch: 113 [16640/50000 (33%)]\tLoss: 1.115626\n",
      "Train Epoch: 113 [17920/50000 (36%)]\tLoss: 1.056384\n",
      "Train Epoch: 113 [19200/50000 (38%)]\tLoss: 1.107984\n",
      "Train Epoch: 113 [20480/50000 (41%)]\tLoss: 1.106669\n",
      "Train Epoch: 113 [21760/50000 (43%)]\tLoss: 1.226499\n",
      "Train Epoch: 113 [23040/50000 (46%)]\tLoss: 1.045668\n",
      "Train Epoch: 113 [24320/50000 (49%)]\tLoss: 1.031000\n",
      "Train Epoch: 113 [25600/50000 (51%)]\tLoss: 1.074737\n",
      "Train Epoch: 113 [26880/50000 (54%)]\tLoss: 1.125517\n",
      "Train Epoch: 113 [28160/50000 (56%)]\tLoss: 1.116454\n",
      "Train Epoch: 113 [29440/50000 (59%)]\tLoss: 1.117683\n",
      "Train Epoch: 113 [30720/50000 (61%)]\tLoss: 0.948591\n",
      "Train Epoch: 113 [32000/50000 (64%)]\tLoss: 1.139456\n",
      "Train Epoch: 113 [33280/50000 (66%)]\tLoss: 1.271049\n",
      "Train Epoch: 113 [34560/50000 (69%)]\tLoss: 1.202901\n",
      "Train Epoch: 113 [35840/50000 (72%)]\tLoss: 0.931348\n",
      "Train Epoch: 113 [37120/50000 (74%)]\tLoss: 1.009130\n",
      "Train Epoch: 113 [38400/50000 (77%)]\tLoss: 1.121380\n",
      "Train Epoch: 113 [39680/50000 (79%)]\tLoss: 1.067431\n",
      "Train Epoch: 113 [40960/50000 (82%)]\tLoss: 1.230725\n",
      "Train Epoch: 113 [42240/50000 (84%)]\tLoss: 0.963327\n",
      "Train Epoch: 113 [43520/50000 (87%)]\tLoss: 0.920528\n",
      "Train Epoch: 113 [44800/50000 (90%)]\tLoss: 0.998843\n",
      "Train Epoch: 113 [46080/50000 (92%)]\tLoss: 1.058587\n",
      "Train Epoch: 113 [47360/50000 (95%)]\tLoss: 1.176295\n",
      "Train Epoch: 113 [48640/50000 (97%)]\tLoss: 1.021814\n",
      "Train Epoch: 113 [31200/50000 (100%)]\tLoss: 0.976718\n",
      "\n",
      "Test set: Avg. loss: 0.000396, Accuracy: 8357/9250 (90.35%)\n",
      "\n",
      "Train Epoch: 114 [0/50000 (0%)]\tLoss: 0.096963\n",
      "Train Epoch: 114 [1280/50000 (3%)]\tLoss: 1.130551\n",
      "Train Epoch: 114 [2560/50000 (5%)]\tLoss: 1.236314\n",
      "Train Epoch: 114 [3840/50000 (8%)]\tLoss: 1.000388\n",
      "Train Epoch: 114 [5120/50000 (10%)]\tLoss: 0.793235\n",
      "Train Epoch: 114 [6400/50000 (13%)]\tLoss: 1.017763\n",
      "Train Epoch: 114 [7680/50000 (15%)]\tLoss: 1.051246\n",
      "Train Epoch: 114 [8960/50000 (18%)]\tLoss: 1.149983\n",
      "Train Epoch: 114 [10240/50000 (20%)]\tLoss: 1.153952\n",
      "Train Epoch: 114 [11520/50000 (23%)]\tLoss: 1.042731\n",
      "Train Epoch: 114 [12800/50000 (26%)]\tLoss: 0.895198\n",
      "Train Epoch: 114 [14080/50000 (28%)]\tLoss: 1.143942\n",
      "Train Epoch: 114 [15360/50000 (31%)]\tLoss: 1.132506\n",
      "Train Epoch: 114 [16640/50000 (33%)]\tLoss: 1.008588\n",
      "Train Epoch: 114 [17920/50000 (36%)]\tLoss: 1.042482\n",
      "Train Epoch: 114 [19200/50000 (38%)]\tLoss: 1.055148\n",
      "Train Epoch: 114 [20480/50000 (41%)]\tLoss: 1.128939\n",
      "Train Epoch: 114 [21760/50000 (43%)]\tLoss: 0.923824\n",
      "Train Epoch: 114 [23040/50000 (46%)]\tLoss: 1.267274\n",
      "Train Epoch: 114 [24320/50000 (49%)]\tLoss: 0.918717\n",
      "Train Epoch: 114 [25600/50000 (51%)]\tLoss: 1.131841\n",
      "Train Epoch: 114 [26880/50000 (54%)]\tLoss: 1.216807\n",
      "Train Epoch: 114 [28160/50000 (56%)]\tLoss: 1.092797\n",
      "Train Epoch: 114 [29440/50000 (59%)]\tLoss: 1.085758\n",
      "Train Epoch: 114 [30720/50000 (61%)]\tLoss: 1.081462\n",
      "Train Epoch: 114 [32000/50000 (64%)]\tLoss: 1.126461\n",
      "Train Epoch: 114 [33280/50000 (66%)]\tLoss: 0.980746\n",
      "Train Epoch: 114 [34560/50000 (69%)]\tLoss: 1.098311\n",
      "Train Epoch: 114 [35840/50000 (72%)]\tLoss: 1.258396\n",
      "Train Epoch: 114 [37120/50000 (74%)]\tLoss: 1.091670\n",
      "Train Epoch: 114 [38400/50000 (77%)]\tLoss: 1.033466\n",
      "Train Epoch: 114 [39680/50000 (79%)]\tLoss: 0.870426\n",
      "Train Epoch: 114 [40960/50000 (82%)]\tLoss: 0.968025\n",
      "Train Epoch: 114 [42240/50000 (84%)]\tLoss: 1.088098\n",
      "Train Epoch: 114 [43520/50000 (87%)]\tLoss: 0.818040\n",
      "Train Epoch: 114 [44800/50000 (90%)]\tLoss: 1.253547\n",
      "Train Epoch: 114 [46080/50000 (92%)]\tLoss: 1.145127\n",
      "Train Epoch: 114 [47360/50000 (95%)]\tLoss: 0.890048\n",
      "Train Epoch: 114 [48640/50000 (97%)]\tLoss: 1.018776\n",
      "Train Epoch: 114 [31200/50000 (100%)]\tLoss: 1.082454\n",
      "\n",
      "Test set: Avg. loss: 0.000419, Accuracy: 8279/9250 (89.50%)\n",
      "\n",
      "Train Epoch: 115 [0/50000 (0%)]\tLoss: 0.134771\n",
      "Train Epoch: 115 [1280/50000 (3%)]\tLoss: 0.992926\n",
      "Train Epoch: 115 [2560/50000 (5%)]\tLoss: 1.059513\n",
      "Train Epoch: 115 [3840/50000 (8%)]\tLoss: 1.010391\n",
      "Train Epoch: 115 [5120/50000 (10%)]\tLoss: 1.155110\n",
      "Train Epoch: 115 [6400/50000 (13%)]\tLoss: 1.242500\n",
      "Train Epoch: 115 [7680/50000 (15%)]\tLoss: 0.974414\n",
      "Train Epoch: 115 [8960/50000 (18%)]\tLoss: 1.205107\n",
      "Train Epoch: 115 [10240/50000 (20%)]\tLoss: 1.164852\n",
      "Train Epoch: 115 [11520/50000 (23%)]\tLoss: 0.964795\n",
      "Train Epoch: 115 [12800/50000 (26%)]\tLoss: 0.971164\n",
      "Train Epoch: 115 [14080/50000 (28%)]\tLoss: 1.129051\n",
      "Train Epoch: 115 [15360/50000 (31%)]\tLoss: 1.085273\n",
      "Train Epoch: 115 [16640/50000 (33%)]\tLoss: 0.954192\n",
      "Train Epoch: 115 [17920/50000 (36%)]\tLoss: 1.332049\n",
      "Train Epoch: 115 [19200/50000 (38%)]\tLoss: 1.138399\n",
      "Train Epoch: 115 [20480/50000 (41%)]\tLoss: 1.018318\n",
      "Train Epoch: 115 [21760/50000 (43%)]\tLoss: 1.091554\n",
      "Train Epoch: 115 [23040/50000 (46%)]\tLoss: 1.018099\n",
      "Train Epoch: 115 [24320/50000 (49%)]\tLoss: 0.956346\n",
      "Train Epoch: 115 [25600/50000 (51%)]\tLoss: 1.146280\n",
      "Train Epoch: 115 [26880/50000 (54%)]\tLoss: 0.904737\n",
      "Train Epoch: 115 [28160/50000 (56%)]\tLoss: 1.013159\n",
      "Train Epoch: 115 [29440/50000 (59%)]\tLoss: 0.954112\n",
      "Train Epoch: 115 [30720/50000 (61%)]\tLoss: 1.059326\n",
      "Train Epoch: 115 [32000/50000 (64%)]\tLoss: 0.866012\n",
      "Train Epoch: 115 [33280/50000 (66%)]\tLoss: 0.925017\n",
      "Train Epoch: 115 [34560/50000 (69%)]\tLoss: 1.224010\n",
      "Train Epoch: 115 [35840/50000 (72%)]\tLoss: 0.920882\n",
      "Train Epoch: 115 [37120/50000 (74%)]\tLoss: 0.864001\n",
      "Train Epoch: 115 [38400/50000 (77%)]\tLoss: 1.013188\n",
      "Train Epoch: 115 [39680/50000 (79%)]\tLoss: 1.066740\n",
      "Train Epoch: 115 [40960/50000 (82%)]\tLoss: 0.912443\n",
      "Train Epoch: 115 [42240/50000 (84%)]\tLoss: 1.135904\n",
      "Train Epoch: 115 [43520/50000 (87%)]\tLoss: 1.102144\n",
      "Train Epoch: 115 [44800/50000 (90%)]\tLoss: 0.935508\n",
      "Train Epoch: 115 [46080/50000 (92%)]\tLoss: 0.908645\n",
      "Train Epoch: 115 [47360/50000 (95%)]\tLoss: 0.837069\n",
      "Train Epoch: 115 [48640/50000 (97%)]\tLoss: 0.979769\n",
      "Train Epoch: 115 [31200/50000 (100%)]\tLoss: 0.889950\n",
      "\n",
      "Test set: Avg. loss: 0.000371, Accuracy: 8318/9250 (89.92%)\n",
      "\n",
      "Train Epoch: 116 [0/50000 (0%)]\tLoss: 0.107125\n",
      "Train Epoch: 116 [1280/50000 (3%)]\tLoss: 1.130888\n",
      "Train Epoch: 116 [2560/50000 (5%)]\tLoss: 0.858466\n",
      "Train Epoch: 116 [3840/50000 (8%)]\tLoss: 0.937451\n",
      "Train Epoch: 116 [5120/50000 (10%)]\tLoss: 1.117062\n",
      "Train Epoch: 116 [6400/50000 (13%)]\tLoss: 1.007569\n",
      "Train Epoch: 116 [7680/50000 (15%)]\tLoss: 1.117948\n",
      "Train Epoch: 116 [8960/50000 (18%)]\tLoss: 0.948253\n",
      "Train Epoch: 116 [10240/50000 (20%)]\tLoss: 0.743225\n",
      "Train Epoch: 116 [11520/50000 (23%)]\tLoss: 1.199966\n",
      "Train Epoch: 116 [12800/50000 (26%)]\tLoss: 1.150917\n",
      "Train Epoch: 116 [14080/50000 (28%)]\tLoss: 0.910704\n",
      "Train Epoch: 116 [15360/50000 (31%)]\tLoss: 1.011336\n",
      "Train Epoch: 116 [16640/50000 (33%)]\tLoss: 1.114385\n",
      "Train Epoch: 116 [17920/50000 (36%)]\tLoss: 1.021962\n",
      "Train Epoch: 116 [19200/50000 (38%)]\tLoss: 1.056160\n",
      "Train Epoch: 116 [20480/50000 (41%)]\tLoss: 1.172411\n",
      "Train Epoch: 116 [21760/50000 (43%)]\tLoss: 1.177043\n",
      "Train Epoch: 116 [23040/50000 (46%)]\tLoss: 0.958301\n",
      "Train Epoch: 116 [24320/50000 (49%)]\tLoss: 1.106626\n",
      "Train Epoch: 116 [25600/50000 (51%)]\tLoss: 0.976641\n",
      "Train Epoch: 116 [26880/50000 (54%)]\tLoss: 1.194591\n",
      "Train Epoch: 116 [28160/50000 (56%)]\tLoss: 0.762580\n",
      "Train Epoch: 116 [29440/50000 (59%)]\tLoss: 1.063266\n",
      "Train Epoch: 116 [30720/50000 (61%)]\tLoss: 0.888242\n",
      "Train Epoch: 116 [32000/50000 (64%)]\tLoss: 0.889194\n",
      "Train Epoch: 116 [33280/50000 (66%)]\tLoss: 1.025965\n",
      "Train Epoch: 116 [34560/50000 (69%)]\tLoss: 1.233287\n",
      "Train Epoch: 116 [35840/50000 (72%)]\tLoss: 1.060728\n",
      "Train Epoch: 116 [37120/50000 (74%)]\tLoss: 0.937592\n",
      "Train Epoch: 116 [38400/50000 (77%)]\tLoss: 0.950590\n",
      "Train Epoch: 116 [39680/50000 (79%)]\tLoss: 0.828596\n",
      "Train Epoch: 116 [40960/50000 (82%)]\tLoss: 0.960570\n",
      "Train Epoch: 116 [42240/50000 (84%)]\tLoss: 1.154325\n",
      "Train Epoch: 116 [43520/50000 (87%)]\tLoss: 1.036467\n",
      "Train Epoch: 116 [44800/50000 (90%)]\tLoss: 1.166699\n",
      "Train Epoch: 116 [46080/50000 (92%)]\tLoss: 0.852118\n",
      "Train Epoch: 116 [47360/50000 (95%)]\tLoss: 0.908913\n",
      "Train Epoch: 116 [48640/50000 (97%)]\tLoss: 1.316523\n",
      "Train Epoch: 116 [31200/50000 (100%)]\tLoss: 1.184866\n",
      "\n",
      "Test set: Avg. loss: 0.000418, Accuracy: 8315/9250 (89.89%)\n",
      "\n",
      "Train Epoch: 117 [0/50000 (0%)]\tLoss: 0.055785\n",
      "Train Epoch: 117 [1280/50000 (3%)]\tLoss: 1.073487\n",
      "Train Epoch: 117 [2560/50000 (5%)]\tLoss: 1.070145\n",
      "Train Epoch: 117 [3840/50000 (8%)]\tLoss: 0.941559\n",
      "Train Epoch: 117 [5120/50000 (10%)]\tLoss: 1.255362\n",
      "Train Epoch: 117 [6400/50000 (13%)]\tLoss: 0.987795\n",
      "Train Epoch: 117 [7680/50000 (15%)]\tLoss: 1.114242\n",
      "Train Epoch: 117 [8960/50000 (18%)]\tLoss: 1.029125\n",
      "Train Epoch: 117 [10240/50000 (20%)]\tLoss: 0.981749\n",
      "Train Epoch: 117 [11520/50000 (23%)]\tLoss: 0.851455\n",
      "Train Epoch: 117 [12800/50000 (26%)]\tLoss: 1.007495\n",
      "Train Epoch: 117 [14080/50000 (28%)]\tLoss: 1.010467\n",
      "Train Epoch: 117 [15360/50000 (31%)]\tLoss: 1.055596\n",
      "Train Epoch: 117 [16640/50000 (33%)]\tLoss: 1.063245\n",
      "Train Epoch: 117 [17920/50000 (36%)]\tLoss: 1.081524\n",
      "Train Epoch: 117 [19200/50000 (38%)]\tLoss: 1.064328\n",
      "Train Epoch: 117 [20480/50000 (41%)]\tLoss: 1.031174\n",
      "Train Epoch: 117 [21760/50000 (43%)]\tLoss: 1.184379\n",
      "Train Epoch: 117 [23040/50000 (46%)]\tLoss: 1.033278\n",
      "Train Epoch: 117 [24320/50000 (49%)]\tLoss: 0.878923\n",
      "Train Epoch: 117 [25600/50000 (51%)]\tLoss: 1.035011\n",
      "Train Epoch: 117 [26880/50000 (54%)]\tLoss: 0.947510\n",
      "Train Epoch: 117 [28160/50000 (56%)]\tLoss: 1.163226\n",
      "Train Epoch: 117 [29440/50000 (59%)]\tLoss: 1.138396\n",
      "Train Epoch: 117 [30720/50000 (61%)]\tLoss: 1.004656\n",
      "Train Epoch: 117 [32000/50000 (64%)]\tLoss: 0.937099\n",
      "Train Epoch: 117 [33280/50000 (66%)]\tLoss: 0.922290\n",
      "Train Epoch: 117 [34560/50000 (69%)]\tLoss: 1.054675\n",
      "Train Epoch: 117 [35840/50000 (72%)]\tLoss: 1.136719\n",
      "Train Epoch: 117 [37120/50000 (74%)]\tLoss: 1.118356\n",
      "Train Epoch: 117 [38400/50000 (77%)]\tLoss: 0.902113\n",
      "Train Epoch: 117 [39680/50000 (79%)]\tLoss: 1.101706\n",
      "Train Epoch: 117 [40960/50000 (82%)]\tLoss: 1.008213\n",
      "Train Epoch: 117 [42240/50000 (84%)]\tLoss: 1.084643\n",
      "Train Epoch: 117 [43520/50000 (87%)]\tLoss: 0.887681\n",
      "Train Epoch: 117 [44800/50000 (90%)]\tLoss: 0.996794\n",
      "Train Epoch: 117 [46080/50000 (92%)]\tLoss: 1.047808\n",
      "Train Epoch: 117 [47360/50000 (95%)]\tLoss: 1.094234\n",
      "Train Epoch: 117 [48640/50000 (97%)]\tLoss: 1.114401\n",
      "Train Epoch: 117 [31200/50000 (100%)]\tLoss: 1.219970\n",
      "\n",
      "Test set: Avg. loss: 0.000418, Accuracy: 8315/9250 (89.89%)\n",
      "\n",
      "Train Epoch: 118 [0/50000 (0%)]\tLoss: 0.121634\n",
      "Train Epoch: 118 [1280/50000 (3%)]\tLoss: 1.106408\n",
      "Train Epoch: 118 [2560/50000 (5%)]\tLoss: 1.119097\n",
      "Train Epoch: 118 [3840/50000 (8%)]\tLoss: 1.057417\n",
      "Train Epoch: 118 [5120/50000 (10%)]\tLoss: 1.221633\n",
      "Train Epoch: 118 [6400/50000 (13%)]\tLoss: 0.918885\n",
      "Train Epoch: 118 [7680/50000 (15%)]\tLoss: 1.096190\n",
      "Train Epoch: 118 [8960/50000 (18%)]\tLoss: 1.050049\n",
      "Train Epoch: 118 [10240/50000 (20%)]\tLoss: 0.967726\n",
      "Train Epoch: 118 [11520/50000 (23%)]\tLoss: 1.161716\n",
      "Train Epoch: 118 [12800/50000 (26%)]\tLoss: 1.021457\n",
      "Train Epoch: 118 [14080/50000 (28%)]\tLoss: 1.105552\n",
      "Train Epoch: 118 [15360/50000 (31%)]\tLoss: 1.343119\n",
      "Train Epoch: 118 [16640/50000 (33%)]\tLoss: 0.944241\n",
      "Train Epoch: 118 [17920/50000 (36%)]\tLoss: 1.052617\n",
      "Train Epoch: 118 [19200/50000 (38%)]\tLoss: 1.138368\n",
      "Train Epoch: 118 [20480/50000 (41%)]\tLoss: 1.246598\n",
      "Train Epoch: 118 [21760/50000 (43%)]\tLoss: 0.954598\n",
      "Train Epoch: 118 [23040/50000 (46%)]\tLoss: 1.115795\n",
      "Train Epoch: 118 [24320/50000 (49%)]\tLoss: 1.012516\n",
      "Train Epoch: 118 [25600/50000 (51%)]\tLoss: 0.876475\n",
      "Train Epoch: 118 [26880/50000 (54%)]\tLoss: 1.149439\n",
      "Train Epoch: 118 [28160/50000 (56%)]\tLoss: 1.290784\n",
      "Train Epoch: 118 [29440/50000 (59%)]\tLoss: 0.968564\n",
      "Train Epoch: 118 [30720/50000 (61%)]\tLoss: 0.877811\n",
      "Train Epoch: 118 [32000/50000 (64%)]\tLoss: 0.973601\n",
      "Train Epoch: 118 [33280/50000 (66%)]\tLoss: 1.098640\n",
      "Train Epoch: 118 [34560/50000 (69%)]\tLoss: 1.173848\n",
      "Train Epoch: 118 [35840/50000 (72%)]\tLoss: 0.977436\n",
      "Train Epoch: 118 [37120/50000 (74%)]\tLoss: 0.939488\n",
      "Train Epoch: 118 [38400/50000 (77%)]\tLoss: 1.099917\n",
      "Train Epoch: 118 [39680/50000 (79%)]\tLoss: 0.961085\n",
      "Train Epoch: 118 [40960/50000 (82%)]\tLoss: 1.215461\n",
      "Train Epoch: 118 [42240/50000 (84%)]\tLoss: 1.279369\n",
      "Train Epoch: 118 [43520/50000 (87%)]\tLoss: 1.149337\n",
      "Train Epoch: 118 [44800/50000 (90%)]\tLoss: 0.908925\n",
      "Train Epoch: 118 [46080/50000 (92%)]\tLoss: 1.242389\n",
      "Train Epoch: 118 [47360/50000 (95%)]\tLoss: 1.051032\n",
      "Train Epoch: 118 [48640/50000 (97%)]\tLoss: 1.187303\n",
      "Train Epoch: 118 [31200/50000 (100%)]\tLoss: 1.026955\n",
      "\n",
      "Test set: Avg. loss: 0.000422, Accuracy: 8269/9250 (89.39%)\n",
      "\n",
      "Train Epoch: 119 [0/50000 (0%)]\tLoss: 0.135604\n",
      "Train Epoch: 119 [1280/50000 (3%)]\tLoss: 1.218633\n",
      "Train Epoch: 119 [2560/50000 (5%)]\tLoss: 1.026274\n",
      "Train Epoch: 119 [3840/50000 (8%)]\tLoss: 1.208613\n",
      "Train Epoch: 119 [5120/50000 (10%)]\tLoss: 0.806661\n",
      "Train Epoch: 119 [6400/50000 (13%)]\tLoss: 0.991069\n",
      "Train Epoch: 119 [7680/50000 (15%)]\tLoss: 1.137582\n",
      "Train Epoch: 119 [8960/50000 (18%)]\tLoss: 1.219824\n",
      "Train Epoch: 119 [10240/50000 (20%)]\tLoss: 1.045667\n",
      "Train Epoch: 119 [11520/50000 (23%)]\tLoss: 1.077778\n",
      "Train Epoch: 119 [12800/50000 (26%)]\tLoss: 0.930049\n",
      "Train Epoch: 119 [14080/50000 (28%)]\tLoss: 1.153817\n",
      "Train Epoch: 119 [15360/50000 (31%)]\tLoss: 1.076088\n",
      "Train Epoch: 119 [16640/50000 (33%)]\tLoss: 1.062652\n",
      "Train Epoch: 119 [17920/50000 (36%)]\tLoss: 1.034720\n",
      "Train Epoch: 119 [19200/50000 (38%)]\tLoss: 1.072589\n",
      "Train Epoch: 119 [20480/50000 (41%)]\tLoss: 1.059379\n",
      "Train Epoch: 119 [21760/50000 (43%)]\tLoss: 0.954140\n",
      "Train Epoch: 119 [23040/50000 (46%)]\tLoss: 0.925749\n",
      "Train Epoch: 119 [24320/50000 (49%)]\tLoss: 1.115953\n",
      "Train Epoch: 119 [25600/50000 (51%)]\tLoss: 0.978510\n",
      "Train Epoch: 119 [26880/50000 (54%)]\tLoss: 1.161316\n",
      "Train Epoch: 119 [28160/50000 (56%)]\tLoss: 1.161007\n",
      "Train Epoch: 119 [29440/50000 (59%)]\tLoss: 1.092429\n",
      "Train Epoch: 119 [30720/50000 (61%)]\tLoss: 0.987418\n",
      "Train Epoch: 119 [32000/50000 (64%)]\tLoss: 0.845914\n",
      "Train Epoch: 119 [33280/50000 (66%)]\tLoss: 0.835679\n",
      "Train Epoch: 119 [34560/50000 (69%)]\tLoss: 1.312626\n",
      "Train Epoch: 119 [35840/50000 (72%)]\tLoss: 1.151654\n",
      "Train Epoch: 119 [37120/50000 (74%)]\tLoss: 1.054921\n",
      "Train Epoch: 119 [38400/50000 (77%)]\tLoss: 1.175997\n",
      "Train Epoch: 119 [39680/50000 (79%)]\tLoss: 0.947218\n",
      "Train Epoch: 119 [40960/50000 (82%)]\tLoss: 0.991772\n",
      "Train Epoch: 119 [42240/50000 (84%)]\tLoss: 1.076304\n",
      "Train Epoch: 119 [43520/50000 (87%)]\tLoss: 1.095516\n",
      "Train Epoch: 119 [44800/50000 (90%)]\tLoss: 1.190176\n",
      "Train Epoch: 119 [46080/50000 (92%)]\tLoss: 1.118919\n",
      "Train Epoch: 119 [47360/50000 (95%)]\tLoss: 1.042700\n",
      "Train Epoch: 119 [48640/50000 (97%)]\tLoss: 0.996210\n",
      "Train Epoch: 119 [31200/50000 (100%)]\tLoss: 1.280677\n",
      "\n",
      "Test set: Avg. loss: 0.000418, Accuracy: 8380/9250 (90.59%)\n",
      "\n",
      "Train Epoch: 120 [0/50000 (0%)]\tLoss: 0.133536\n",
      "Train Epoch: 120 [1280/50000 (3%)]\tLoss: 0.898648\n",
      "Train Epoch: 120 [2560/50000 (5%)]\tLoss: 0.815133\n",
      "Train Epoch: 120 [3840/50000 (8%)]\tLoss: 0.832107\n",
      "Train Epoch: 120 [5120/50000 (10%)]\tLoss: 1.043598\n",
      "Train Epoch: 120 [6400/50000 (13%)]\tLoss: 1.011510\n",
      "Train Epoch: 120 [7680/50000 (15%)]\tLoss: 1.032694\n",
      "Train Epoch: 120 [8960/50000 (18%)]\tLoss: 1.093035\n",
      "Train Epoch: 120 [10240/50000 (20%)]\tLoss: 1.048759\n",
      "Train Epoch: 120 [11520/50000 (23%)]\tLoss: 1.342655\n",
      "Train Epoch: 120 [12800/50000 (26%)]\tLoss: 1.100219\n",
      "Train Epoch: 120 [14080/50000 (28%)]\tLoss: 1.027223\n",
      "Train Epoch: 120 [15360/50000 (31%)]\tLoss: 0.925294\n",
      "Train Epoch: 120 [16640/50000 (33%)]\tLoss: 1.004290\n",
      "Train Epoch: 120 [17920/50000 (36%)]\tLoss: 1.216729\n",
      "Train Epoch: 120 [19200/50000 (38%)]\tLoss: 1.238019\n",
      "Train Epoch: 120 [20480/50000 (41%)]\tLoss: 1.135119\n",
      "Train Epoch: 120 [21760/50000 (43%)]\tLoss: 1.255657\n",
      "Train Epoch: 120 [23040/50000 (46%)]\tLoss: 1.087412\n",
      "Train Epoch: 120 [24320/50000 (49%)]\tLoss: 0.909798\n",
      "Train Epoch: 120 [25600/50000 (51%)]\tLoss: 0.962563\n",
      "Train Epoch: 120 [26880/50000 (54%)]\tLoss: 1.053378\n",
      "Train Epoch: 120 [28160/50000 (56%)]\tLoss: 1.043698\n",
      "Train Epoch: 120 [29440/50000 (59%)]\tLoss: 1.070484\n",
      "Train Epoch: 120 [30720/50000 (61%)]\tLoss: 0.997735\n",
      "Train Epoch: 120 [32000/50000 (64%)]\tLoss: 1.135073\n",
      "Train Epoch: 120 [33280/50000 (66%)]\tLoss: 0.798811\n",
      "Train Epoch: 120 [34560/50000 (69%)]\tLoss: 1.225743\n",
      "Train Epoch: 120 [35840/50000 (72%)]\tLoss: 1.016749\n",
      "Train Epoch: 120 [37120/50000 (74%)]\tLoss: 0.950172\n",
      "Train Epoch: 120 [38400/50000 (77%)]\tLoss: 1.189109\n",
      "Train Epoch: 120 [39680/50000 (79%)]\tLoss: 1.060468\n",
      "Train Epoch: 120 [40960/50000 (82%)]\tLoss: 1.099648\n",
      "Train Epoch: 120 [42240/50000 (84%)]\tLoss: 0.943697\n",
      "Train Epoch: 120 [43520/50000 (87%)]\tLoss: 1.168939\n",
      "Train Epoch: 120 [44800/50000 (90%)]\tLoss: 0.891779\n",
      "Train Epoch: 120 [46080/50000 (92%)]\tLoss: 1.034045\n",
      "Train Epoch: 120 [47360/50000 (95%)]\tLoss: 0.958083\n",
      "Train Epoch: 120 [48640/50000 (97%)]\tLoss: 1.060886\n",
      "Train Epoch: 120 [31200/50000 (100%)]\tLoss: 0.840849\n",
      "\n",
      "Test set: Avg. loss: 0.000382, Accuracy: 8387/9250 (90.67%)\n",
      "\n",
      "Train Epoch: 121 [0/50000 (0%)]\tLoss: 0.146249\n",
      "Train Epoch: 121 [1280/50000 (3%)]\tLoss: 0.958519\n",
      "Train Epoch: 121 [2560/50000 (5%)]\tLoss: 1.114794\n",
      "Train Epoch: 121 [3840/50000 (8%)]\tLoss: 1.074550\n",
      "Train Epoch: 121 [5120/50000 (10%)]\tLoss: 1.073945\n",
      "Train Epoch: 121 [6400/50000 (13%)]\tLoss: 0.802058\n",
      "Train Epoch: 121 [7680/50000 (15%)]\tLoss: 1.042766\n",
      "Train Epoch: 121 [8960/50000 (18%)]\tLoss: 1.069069\n",
      "Train Epoch: 121 [10240/50000 (20%)]\tLoss: 0.887751\n",
      "Train Epoch: 121 [11520/50000 (23%)]\tLoss: 1.107118\n",
      "Train Epoch: 121 [12800/50000 (26%)]\tLoss: 1.010595\n",
      "Train Epoch: 121 [14080/50000 (28%)]\tLoss: 0.964905\n",
      "Train Epoch: 121 [15360/50000 (31%)]\tLoss: 1.041569\n",
      "Train Epoch: 121 [16640/50000 (33%)]\tLoss: 1.009635\n",
      "Train Epoch: 121 [17920/50000 (36%)]\tLoss: 1.157724\n",
      "Train Epoch: 121 [19200/50000 (38%)]\tLoss: 1.210115\n",
      "Train Epoch: 121 [20480/50000 (41%)]\tLoss: 1.012684\n",
      "Train Epoch: 121 [21760/50000 (43%)]\tLoss: 1.143048\n",
      "Train Epoch: 121 [23040/50000 (46%)]\tLoss: 1.166494\n",
      "Train Epoch: 121 [24320/50000 (49%)]\tLoss: 0.936598\n",
      "Train Epoch: 121 [25600/50000 (51%)]\tLoss: 1.114658\n",
      "Train Epoch: 121 [26880/50000 (54%)]\tLoss: 1.172656\n",
      "Train Epoch: 121 [28160/50000 (56%)]\tLoss: 0.948174\n",
      "Train Epoch: 121 [29440/50000 (59%)]\tLoss: 1.225837\n",
      "Train Epoch: 121 [30720/50000 (61%)]\tLoss: 1.016820\n",
      "Train Epoch: 121 [32000/50000 (64%)]\tLoss: 1.337890\n",
      "Train Epoch: 121 [33280/50000 (66%)]\tLoss: 1.175051\n",
      "Train Epoch: 121 [34560/50000 (69%)]\tLoss: 0.838222\n",
      "Train Epoch: 121 [35840/50000 (72%)]\tLoss: 1.098813\n",
      "Train Epoch: 121 [37120/50000 (74%)]\tLoss: 1.255425\n",
      "Train Epoch: 121 [38400/50000 (77%)]\tLoss: 0.800986\n",
      "Train Epoch: 121 [39680/50000 (79%)]\tLoss: 0.925152\n",
      "Train Epoch: 121 [40960/50000 (82%)]\tLoss: 1.053863\n",
      "Train Epoch: 121 [42240/50000 (84%)]\tLoss: 0.999505\n",
      "Train Epoch: 121 [43520/50000 (87%)]\tLoss: 0.987228\n",
      "Train Epoch: 121 [44800/50000 (90%)]\tLoss: 0.938483\n",
      "Train Epoch: 121 [46080/50000 (92%)]\tLoss: 1.173114\n",
      "Train Epoch: 121 [47360/50000 (95%)]\tLoss: 0.948040\n",
      "Train Epoch: 121 [48640/50000 (97%)]\tLoss: 0.964660\n",
      "Train Epoch: 121 [31200/50000 (100%)]\tLoss: 1.257333\n",
      "\n",
      "Test set: Avg. loss: 0.000431, Accuracy: 8346/9250 (90.23%)\n",
      "\n",
      "Train Epoch: 122 [0/50000 (0%)]\tLoss: 0.126096\n",
      "Train Epoch: 122 [1280/50000 (3%)]\tLoss: 1.007004\n",
      "Train Epoch: 122 [2560/50000 (5%)]\tLoss: 0.899340\n",
      "Train Epoch: 122 [3840/50000 (8%)]\tLoss: 1.255535\n",
      "Train Epoch: 122 [5120/50000 (10%)]\tLoss: 1.168245\n",
      "Train Epoch: 122 [6400/50000 (13%)]\tLoss: 1.063324\n",
      "Train Epoch: 122 [7680/50000 (15%)]\tLoss: 1.068082\n",
      "Train Epoch: 122 [8960/50000 (18%)]\tLoss: 1.115609\n",
      "Train Epoch: 122 [10240/50000 (20%)]\tLoss: 1.068268\n",
      "Train Epoch: 122 [11520/50000 (23%)]\tLoss: 1.259042\n",
      "Train Epoch: 122 [12800/50000 (26%)]\tLoss: 1.008415\n",
      "Train Epoch: 122 [14080/50000 (28%)]\tLoss: 1.171157\n",
      "Train Epoch: 122 [15360/50000 (31%)]\tLoss: 1.296005\n",
      "Train Epoch: 122 [16640/50000 (33%)]\tLoss: 1.081670\n",
      "Train Epoch: 122 [17920/50000 (36%)]\tLoss: 1.011667\n",
      "Train Epoch: 122 [19200/50000 (38%)]\tLoss: 1.015198\n",
      "Train Epoch: 122 [20480/50000 (41%)]\tLoss: 1.104461\n",
      "Train Epoch: 122 [21760/50000 (43%)]\tLoss: 0.951685\n",
      "Train Epoch: 122 [23040/50000 (46%)]\tLoss: 1.211107\n",
      "Train Epoch: 122 [24320/50000 (49%)]\tLoss: 1.173229\n",
      "Train Epoch: 122 [25600/50000 (51%)]\tLoss: 1.022380\n",
      "Train Epoch: 122 [26880/50000 (54%)]\tLoss: 1.216630\n",
      "Train Epoch: 122 [28160/50000 (56%)]\tLoss: 1.006998\n",
      "Train Epoch: 122 [29440/50000 (59%)]\tLoss: 1.238226\n",
      "Train Epoch: 122 [30720/50000 (61%)]\tLoss: 1.040358\n",
      "Train Epoch: 122 [32000/50000 (64%)]\tLoss: 1.231825\n",
      "Train Epoch: 122 [33280/50000 (66%)]\tLoss: 0.970587\n",
      "Train Epoch: 122 [34560/50000 (69%)]\tLoss: 1.021316\n",
      "Train Epoch: 122 [35840/50000 (72%)]\tLoss: 1.119928\n",
      "Train Epoch: 122 [37120/50000 (74%)]\tLoss: 0.915066\n",
      "Train Epoch: 122 [38400/50000 (77%)]\tLoss: 0.912250\n",
      "Train Epoch: 122 [39680/50000 (79%)]\tLoss: 1.172525\n",
      "Train Epoch: 122 [40960/50000 (82%)]\tLoss: 1.033441\n",
      "Train Epoch: 122 [42240/50000 (84%)]\tLoss: 1.270425\n",
      "Train Epoch: 122 [43520/50000 (87%)]\tLoss: 0.881095\n",
      "Train Epoch: 122 [44800/50000 (90%)]\tLoss: 1.101201\n",
      "Train Epoch: 122 [46080/50000 (92%)]\tLoss: 1.061732\n",
      "Train Epoch: 122 [47360/50000 (95%)]\tLoss: 0.921706\n",
      "Train Epoch: 122 [48640/50000 (97%)]\tLoss: 0.850186\n",
      "Train Epoch: 122 [31200/50000 (100%)]\tLoss: 0.924049\n",
      "\n",
      "Test set: Avg. loss: 0.000387, Accuracy: 8365/9250 (90.43%)\n",
      "\n",
      "Train Epoch: 123 [0/50000 (0%)]\tLoss: 0.053892\n",
      "Train Epoch: 123 [1280/50000 (3%)]\tLoss: 1.071821\n",
      "Train Epoch: 123 [2560/50000 (5%)]\tLoss: 1.247827\n",
      "Train Epoch: 123 [3840/50000 (8%)]\tLoss: 1.079184\n",
      "Train Epoch: 123 [5120/50000 (10%)]\tLoss: 1.045930\n",
      "Train Epoch: 123 [6400/50000 (13%)]\tLoss: 1.219262\n",
      "Train Epoch: 123 [7680/50000 (15%)]\tLoss: 0.874956\n",
      "Train Epoch: 123 [8960/50000 (18%)]\tLoss: 1.009035\n",
      "Train Epoch: 123 [10240/50000 (20%)]\tLoss: 0.974602\n",
      "Train Epoch: 123 [11520/50000 (23%)]\tLoss: 1.013050\n",
      "Train Epoch: 123 [12800/50000 (26%)]\tLoss: 1.031487\n",
      "Train Epoch: 123 [14080/50000 (28%)]\tLoss: 1.175812\n",
      "Train Epoch: 123 [15360/50000 (31%)]\tLoss: 0.886212\n",
      "Train Epoch: 123 [16640/50000 (33%)]\tLoss: 0.999608\n",
      "Train Epoch: 123 [17920/50000 (36%)]\tLoss: 1.149177\n",
      "Train Epoch: 123 [19200/50000 (38%)]\tLoss: 1.127950\n",
      "Train Epoch: 123 [20480/50000 (41%)]\tLoss: 1.068177\n",
      "Train Epoch: 123 [21760/50000 (43%)]\tLoss: 1.153521\n",
      "Train Epoch: 123 [23040/50000 (46%)]\tLoss: 1.144011\n",
      "Train Epoch: 123 [24320/50000 (49%)]\tLoss: 1.157130\n",
      "Train Epoch: 123 [25600/50000 (51%)]\tLoss: 1.200043\n",
      "Train Epoch: 123 [26880/50000 (54%)]\tLoss: 1.054673\n",
      "Train Epoch: 123 [28160/50000 (56%)]\tLoss: 1.201247\n",
      "Train Epoch: 123 [29440/50000 (59%)]\tLoss: 1.122507\n",
      "Train Epoch: 123 [30720/50000 (61%)]\tLoss: 1.089250\n",
      "Train Epoch: 123 [32000/50000 (64%)]\tLoss: 1.142529\n",
      "Train Epoch: 123 [33280/50000 (66%)]\tLoss: 1.055056\n",
      "Train Epoch: 123 [34560/50000 (69%)]\tLoss: 1.159146\n",
      "Train Epoch: 123 [35840/50000 (72%)]\tLoss: 1.014720\n",
      "Train Epoch: 123 [37120/50000 (74%)]\tLoss: 1.014930\n",
      "Train Epoch: 123 [38400/50000 (77%)]\tLoss: 1.265384\n",
      "Train Epoch: 123 [39680/50000 (79%)]\tLoss: 1.166435\n",
      "Train Epoch: 123 [40960/50000 (82%)]\tLoss: 0.963067\n",
      "Train Epoch: 123 [42240/50000 (84%)]\tLoss: 1.091743\n",
      "Train Epoch: 123 [43520/50000 (87%)]\tLoss: 1.080241\n",
      "Train Epoch: 123 [44800/50000 (90%)]\tLoss: 1.128468\n",
      "Train Epoch: 123 [46080/50000 (92%)]\tLoss: 1.056368\n",
      "Train Epoch: 123 [47360/50000 (95%)]\tLoss: 0.847433\n",
      "Train Epoch: 123 [48640/50000 (97%)]\tLoss: 1.110564\n",
      "Train Epoch: 123 [31200/50000 (100%)]\tLoss: 1.002420\n",
      "\n",
      "Test set: Avg. loss: 0.000387, Accuracy: 8333/9250 (90.09%)\n",
      "\n",
      "Train Epoch: 124 [0/50000 (0%)]\tLoss: 0.033128\n",
      "Train Epoch: 124 [1280/50000 (3%)]\tLoss: 1.097315\n",
      "Train Epoch: 124 [2560/50000 (5%)]\tLoss: 0.964253\n",
      "Train Epoch: 124 [3840/50000 (8%)]\tLoss: 0.827075\n",
      "Train Epoch: 124 [5120/50000 (10%)]\tLoss: 1.096811\n",
      "Train Epoch: 124 [6400/50000 (13%)]\tLoss: 0.953055\n",
      "Train Epoch: 124 [7680/50000 (15%)]\tLoss: 1.231319\n",
      "Train Epoch: 124 [8960/50000 (18%)]\tLoss: 0.815617\n",
      "Train Epoch: 124 [10240/50000 (20%)]\tLoss: 0.734613\n",
      "Train Epoch: 124 [11520/50000 (23%)]\tLoss: 1.212023\n",
      "Train Epoch: 124 [12800/50000 (26%)]\tLoss: 1.149416\n",
      "Train Epoch: 124 [14080/50000 (28%)]\tLoss: 0.882843\n",
      "Train Epoch: 124 [15360/50000 (31%)]\tLoss: 1.020186\n",
      "Train Epoch: 124 [16640/50000 (33%)]\tLoss: 0.898759\n",
      "Train Epoch: 124 [17920/50000 (36%)]\tLoss: 0.776346\n",
      "Train Epoch: 124 [19200/50000 (38%)]\tLoss: 1.089411\n",
      "Train Epoch: 124 [20480/50000 (41%)]\tLoss: 1.037663\n",
      "Train Epoch: 124 [21760/50000 (43%)]\tLoss: 0.948351\n",
      "Train Epoch: 124 [23040/50000 (46%)]\tLoss: 0.949236\n",
      "Train Epoch: 124 [24320/50000 (49%)]\tLoss: 0.881526\n",
      "Train Epoch: 124 [25600/50000 (51%)]\tLoss: 0.943037\n",
      "Train Epoch: 124 [26880/50000 (54%)]\tLoss: 1.002609\n",
      "Train Epoch: 124 [28160/50000 (56%)]\tLoss: 1.143407\n",
      "Train Epoch: 124 [29440/50000 (59%)]\tLoss: 0.952780\n",
      "Train Epoch: 124 [30720/50000 (61%)]\tLoss: 1.031441\n",
      "Train Epoch: 124 [32000/50000 (64%)]\tLoss: 1.055631\n",
      "Train Epoch: 124 [33280/50000 (66%)]\tLoss: 0.763824\n",
      "Train Epoch: 124 [34560/50000 (69%)]\tLoss: 1.234515\n",
      "Train Epoch: 124 [35840/50000 (72%)]\tLoss: 1.061187\n",
      "Train Epoch: 124 [37120/50000 (74%)]\tLoss: 1.226259\n",
      "Train Epoch: 124 [38400/50000 (77%)]\tLoss: 0.926295\n",
      "Train Epoch: 124 [39680/50000 (79%)]\tLoss: 1.042060\n",
      "Train Epoch: 124 [40960/50000 (82%)]\tLoss: 1.087834\n",
      "Train Epoch: 124 [42240/50000 (84%)]\tLoss: 1.093486\n",
      "Train Epoch: 124 [43520/50000 (87%)]\tLoss: 1.031554\n",
      "Train Epoch: 124 [44800/50000 (90%)]\tLoss: 1.271543\n",
      "Train Epoch: 124 [46080/50000 (92%)]\tLoss: 0.979719\n",
      "Train Epoch: 124 [47360/50000 (95%)]\tLoss: 1.198213\n",
      "Train Epoch: 124 [48640/50000 (97%)]\tLoss: 1.026569\n",
      "Train Epoch: 124 [31200/50000 (100%)]\tLoss: 1.078158\n",
      "\n",
      "Test set: Avg. loss: 0.000382, Accuracy: 8391/9250 (90.71%)\n",
      "\n",
      "Train Epoch: 125 [0/50000 (0%)]\tLoss: 0.033564\n",
      "Train Epoch: 125 [1280/50000 (3%)]\tLoss: 1.009654\n",
      "Train Epoch: 125 [2560/50000 (5%)]\tLoss: 0.877160\n",
      "Train Epoch: 125 [3840/50000 (8%)]\tLoss: 0.949281\n",
      "Train Epoch: 125 [5120/50000 (10%)]\tLoss: 1.062633\n",
      "Train Epoch: 125 [6400/50000 (13%)]\tLoss: 1.090114\n",
      "Train Epoch: 125 [7680/50000 (15%)]\tLoss: 1.002185\n",
      "Train Epoch: 125 [8960/50000 (18%)]\tLoss: 0.767243\n",
      "Train Epoch: 125 [10240/50000 (20%)]\tLoss: 1.016419\n",
      "Train Epoch: 125 [11520/50000 (23%)]\tLoss: 1.131244\n",
      "Train Epoch: 125 [12800/50000 (26%)]\tLoss: 0.930382\n",
      "Train Epoch: 125 [14080/50000 (28%)]\tLoss: 1.155965\n",
      "Train Epoch: 125 [15360/50000 (31%)]\tLoss: 0.912187\n",
      "Train Epoch: 125 [16640/50000 (33%)]\tLoss: 1.119908\n",
      "Train Epoch: 125 [17920/50000 (36%)]\tLoss: 0.881002\n",
      "Train Epoch: 125 [19200/50000 (38%)]\tLoss: 1.284078\n",
      "Train Epoch: 125 [20480/50000 (41%)]\tLoss: 1.047260\n",
      "Train Epoch: 125 [21760/50000 (43%)]\tLoss: 1.222844\n",
      "Train Epoch: 125 [23040/50000 (46%)]\tLoss: 0.947614\n",
      "Train Epoch: 125 [24320/50000 (49%)]\tLoss: 0.999554\n",
      "Train Epoch: 125 [25600/50000 (51%)]\tLoss: 1.085369\n",
      "Train Epoch: 125 [26880/50000 (54%)]\tLoss: 1.158549\n",
      "Train Epoch: 125 [28160/50000 (56%)]\tLoss: 1.084270\n",
      "Train Epoch: 125 [29440/50000 (59%)]\tLoss: 1.382973\n",
      "Train Epoch: 125 [30720/50000 (61%)]\tLoss: 1.043018\n",
      "Train Epoch: 125 [32000/50000 (64%)]\tLoss: 1.153625\n",
      "Train Epoch: 125 [33280/50000 (66%)]\tLoss: 1.003741\n",
      "Train Epoch: 125 [34560/50000 (69%)]\tLoss: 0.841400\n",
      "Train Epoch: 125 [35840/50000 (72%)]\tLoss: 0.910636\n",
      "Train Epoch: 125 [37120/50000 (74%)]\tLoss: 0.827218\n",
      "Train Epoch: 125 [38400/50000 (77%)]\tLoss: 1.102786\n",
      "Train Epoch: 125 [39680/50000 (79%)]\tLoss: 1.207608\n",
      "Train Epoch: 125 [40960/50000 (82%)]\tLoss: 1.095469\n",
      "Train Epoch: 125 [42240/50000 (84%)]\tLoss: 1.076539\n",
      "Train Epoch: 125 [43520/50000 (87%)]\tLoss: 1.107640\n",
      "Train Epoch: 125 [44800/50000 (90%)]\tLoss: 1.002471\n",
      "Train Epoch: 125 [46080/50000 (92%)]\tLoss: 1.043966\n",
      "Train Epoch: 125 [47360/50000 (95%)]\tLoss: 0.838306\n",
      "Train Epoch: 125 [48640/50000 (97%)]\tLoss: 1.046693\n",
      "Train Epoch: 125 [31200/50000 (100%)]\tLoss: 1.082973\n",
      "\n",
      "Test set: Avg. loss: 0.000428, Accuracy: 8369/9250 (90.48%)\n",
      "\n",
      "Train Epoch: 126 [0/50000 (0%)]\tLoss: 0.147776\n",
      "Train Epoch: 126 [1280/50000 (3%)]\tLoss: 1.066463\n",
      "Train Epoch: 126 [2560/50000 (5%)]\tLoss: 0.748239\n",
      "Train Epoch: 126 [3840/50000 (8%)]\tLoss: 1.027381\n",
      "Train Epoch: 126 [5120/50000 (10%)]\tLoss: 1.015424\n",
      "Train Epoch: 126 [6400/50000 (13%)]\tLoss: 0.888772\n",
      "Train Epoch: 126 [7680/50000 (15%)]\tLoss: 1.077350\n",
      "Train Epoch: 126 [8960/50000 (18%)]\tLoss: 1.049663\n",
      "Train Epoch: 126 [10240/50000 (20%)]\tLoss: 1.182914\n",
      "Train Epoch: 126 [11520/50000 (23%)]\tLoss: 0.894921\n",
      "Train Epoch: 126 [12800/50000 (26%)]\tLoss: 1.099911\n",
      "Train Epoch: 126 [14080/50000 (28%)]\tLoss: 1.048989\n",
      "Train Epoch: 126 [15360/50000 (31%)]\tLoss: 1.191473\n",
      "Train Epoch: 126 [16640/50000 (33%)]\tLoss: 1.074961\n",
      "Train Epoch: 126 [17920/50000 (36%)]\tLoss: 1.040459\n",
      "Train Epoch: 126 [19200/50000 (38%)]\tLoss: 1.155046\n",
      "Train Epoch: 126 [20480/50000 (41%)]\tLoss: 1.132870\n",
      "Train Epoch: 126 [21760/50000 (43%)]\tLoss: 1.007639\n",
      "Train Epoch: 126 [23040/50000 (46%)]\tLoss: 0.868051\n",
      "Train Epoch: 126 [24320/50000 (49%)]\tLoss: 1.061944\n",
      "Train Epoch: 126 [25600/50000 (51%)]\tLoss: 1.016126\n",
      "Train Epoch: 126 [26880/50000 (54%)]\tLoss: 1.128742\n",
      "Train Epoch: 126 [28160/50000 (56%)]\tLoss: 0.794570\n",
      "Train Epoch: 126 [29440/50000 (59%)]\tLoss: 1.083680\n",
      "Train Epoch: 126 [30720/50000 (61%)]\tLoss: 1.289491\n",
      "Train Epoch: 126 [32000/50000 (64%)]\tLoss: 0.862223\n",
      "Train Epoch: 126 [33280/50000 (66%)]\tLoss: 1.036150\n",
      "Train Epoch: 126 [34560/50000 (69%)]\tLoss: 1.137504\n",
      "Train Epoch: 126 [35840/50000 (72%)]\tLoss: 0.936009\n",
      "Train Epoch: 126 [37120/50000 (74%)]\tLoss: 0.919837\n",
      "Train Epoch: 126 [38400/50000 (77%)]\tLoss: 1.205652\n",
      "Train Epoch: 126 [39680/50000 (79%)]\tLoss: 0.895980\n",
      "Train Epoch: 126 [40960/50000 (82%)]\tLoss: 1.125887\n",
      "Train Epoch: 126 [42240/50000 (84%)]\tLoss: 0.985100\n",
      "Train Epoch: 126 [43520/50000 (87%)]\tLoss: 1.034728\n",
      "Train Epoch: 126 [44800/50000 (90%)]\tLoss: 0.984960\n",
      "Train Epoch: 126 [46080/50000 (92%)]\tLoss: 0.932527\n",
      "Train Epoch: 126 [47360/50000 (95%)]\tLoss: 1.008803\n",
      "Train Epoch: 126 [48640/50000 (97%)]\tLoss: 1.015736\n",
      "Train Epoch: 126 [31200/50000 (100%)]\tLoss: 0.960718\n",
      "\n",
      "Test set: Avg. loss: 0.000408, Accuracy: 8357/9250 (90.35%)\n",
      "\n",
      "Train Epoch: 127 [0/50000 (0%)]\tLoss: 0.136651\n",
      "Train Epoch: 127 [1280/50000 (3%)]\tLoss: 1.023517\n",
      "Train Epoch: 127 [2560/50000 (5%)]\tLoss: 1.033864\n",
      "Train Epoch: 127 [3840/50000 (8%)]\tLoss: 1.126369\n",
      "Train Epoch: 127 [5120/50000 (10%)]\tLoss: 0.848049\n",
      "Train Epoch: 127 [6400/50000 (13%)]\tLoss: 0.874680\n",
      "Train Epoch: 127 [7680/50000 (15%)]\tLoss: 1.069072\n",
      "Train Epoch: 127 [8960/50000 (18%)]\tLoss: 1.016886\n",
      "Train Epoch: 127 [10240/50000 (20%)]\tLoss: 1.000895\n",
      "Train Epoch: 127 [11520/50000 (23%)]\tLoss: 1.185745\n",
      "Train Epoch: 127 [12800/50000 (26%)]\tLoss: 0.925254\n",
      "Train Epoch: 127 [14080/50000 (28%)]\tLoss: 0.874706\n",
      "Train Epoch: 127 [15360/50000 (31%)]\tLoss: 1.193830\n",
      "Train Epoch: 127 [16640/50000 (33%)]\tLoss: 1.093725\n",
      "Train Epoch: 127 [17920/50000 (36%)]\tLoss: 1.082109\n",
      "Train Epoch: 127 [19200/50000 (38%)]\tLoss: 1.285971\n",
      "Train Epoch: 127 [20480/50000 (41%)]\tLoss: 1.272710\n",
      "Train Epoch: 127 [21760/50000 (43%)]\tLoss: 1.035427\n",
      "Train Epoch: 127 [23040/50000 (46%)]\tLoss: 1.147299\n",
      "Train Epoch: 127 [24320/50000 (49%)]\tLoss: 1.048820\n",
      "Train Epoch: 127 [25600/50000 (51%)]\tLoss: 1.021916\n",
      "Train Epoch: 127 [26880/50000 (54%)]\tLoss: 1.096174\n",
      "Train Epoch: 127 [28160/50000 (56%)]\tLoss: 1.119263\n",
      "Train Epoch: 127 [29440/50000 (59%)]\tLoss: 1.029497\n",
      "Train Epoch: 127 [30720/50000 (61%)]\tLoss: 0.959378\n",
      "Train Epoch: 127 [32000/50000 (64%)]\tLoss: 1.154345\n",
      "Train Epoch: 127 [33280/50000 (66%)]\tLoss: 1.197135\n",
      "Train Epoch: 127 [34560/50000 (69%)]\tLoss: 0.979175\n",
      "Train Epoch: 127 [35840/50000 (72%)]\tLoss: 1.129227\n",
      "Train Epoch: 127 [37120/50000 (74%)]\tLoss: 1.080968\n",
      "Train Epoch: 127 [38400/50000 (77%)]\tLoss: 1.133891\n",
      "Train Epoch: 127 [39680/50000 (79%)]\tLoss: 1.102933\n",
      "Train Epoch: 127 [40960/50000 (82%)]\tLoss: 1.086719\n",
      "Train Epoch: 127 [42240/50000 (84%)]\tLoss: 0.918779\n",
      "Train Epoch: 127 [43520/50000 (87%)]\tLoss: 1.179023\n",
      "Train Epoch: 127 [44800/50000 (90%)]\tLoss: 1.038271\n",
      "Train Epoch: 127 [46080/50000 (92%)]\tLoss: 1.190106\n",
      "Train Epoch: 127 [47360/50000 (95%)]\tLoss: 1.059207\n",
      "Train Epoch: 127 [48640/50000 (97%)]\tLoss: 1.170502\n",
      "Train Epoch: 127 [31200/50000 (100%)]\tLoss: 1.025271\n",
      "\n",
      "Test set: Avg. loss: 0.000378, Accuracy: 8373/9250 (90.52%)\n",
      "\n",
      "Train Epoch: 128 [0/50000 (0%)]\tLoss: 0.121142\n",
      "Train Epoch: 128 [1280/50000 (3%)]\tLoss: 0.966941\n",
      "Train Epoch: 128 [2560/50000 (5%)]\tLoss: 0.882879\n",
      "Train Epoch: 128 [3840/50000 (8%)]\tLoss: 0.941363\n",
      "Train Epoch: 128 [5120/50000 (10%)]\tLoss: 0.917145\n",
      "Train Epoch: 128 [6400/50000 (13%)]\tLoss: 1.192162\n",
      "Train Epoch: 128 [7680/50000 (15%)]\tLoss: 1.327830\n",
      "Train Epoch: 128 [8960/50000 (18%)]\tLoss: 1.163599\n",
      "Train Epoch: 128 [10240/50000 (20%)]\tLoss: 1.153907\n",
      "Train Epoch: 128 [11520/50000 (23%)]\tLoss: 1.120306\n",
      "Train Epoch: 128 [12800/50000 (26%)]\tLoss: 0.806040\n",
      "Train Epoch: 128 [14080/50000 (28%)]\tLoss: 1.051844\n",
      "Train Epoch: 128 [15360/50000 (31%)]\tLoss: 0.927300\n",
      "Train Epoch: 128 [16640/50000 (33%)]\tLoss: 1.064386\n",
      "Train Epoch: 128 [17920/50000 (36%)]\tLoss: 1.042175\n",
      "Train Epoch: 128 [19200/50000 (38%)]\tLoss: 1.169314\n",
      "Train Epoch: 128 [20480/50000 (41%)]\tLoss: 0.780393\n",
      "Train Epoch: 128 [21760/50000 (43%)]\tLoss: 1.114628\n",
      "Train Epoch: 128 [23040/50000 (46%)]\tLoss: 1.020052\n",
      "Train Epoch: 128 [24320/50000 (49%)]\tLoss: 0.947363\n",
      "Train Epoch: 128 [25600/50000 (51%)]\tLoss: 0.893625\n",
      "Train Epoch: 128 [26880/50000 (54%)]\tLoss: 1.001348\n",
      "Train Epoch: 128 [28160/50000 (56%)]\tLoss: 1.062365\n",
      "Train Epoch: 128 [29440/50000 (59%)]\tLoss: 0.984903\n",
      "Train Epoch: 128 [30720/50000 (61%)]\tLoss: 0.853830\n",
      "Train Epoch: 128 [32000/50000 (64%)]\tLoss: 1.175844\n",
      "Train Epoch: 128 [33280/50000 (66%)]\tLoss: 0.847885\n",
      "Train Epoch: 128 [34560/50000 (69%)]\tLoss: 1.050487\n",
      "Train Epoch: 128 [35840/50000 (72%)]\tLoss: 0.878850\n",
      "Train Epoch: 128 [37120/50000 (74%)]\tLoss: 1.183228\n",
      "Train Epoch: 128 [38400/50000 (77%)]\tLoss: 1.050266\n",
      "Train Epoch: 128 [39680/50000 (79%)]\tLoss: 1.099968\n",
      "Train Epoch: 128 [40960/50000 (82%)]\tLoss: 0.953465\n",
      "Train Epoch: 128 [42240/50000 (84%)]\tLoss: 1.112378\n",
      "Train Epoch: 128 [43520/50000 (87%)]\tLoss: 1.042868\n",
      "Train Epoch: 128 [44800/50000 (90%)]\tLoss: 0.980799\n",
      "Train Epoch: 128 [46080/50000 (92%)]\tLoss: 1.100433\n",
      "Train Epoch: 128 [47360/50000 (95%)]\tLoss: 1.115568\n",
      "Train Epoch: 128 [48640/50000 (97%)]\tLoss: 1.160462\n",
      "Train Epoch: 128 [31200/50000 (100%)]\tLoss: 1.284017\n",
      "\n",
      "Test set: Avg. loss: 0.000423, Accuracy: 8334/9250 (90.10%)\n",
      "\n",
      "Train Epoch: 129 [0/50000 (0%)]\tLoss: 0.148643\n",
      "Train Epoch: 129 [1280/50000 (3%)]\tLoss: 1.038478\n",
      "Train Epoch: 129 [2560/50000 (5%)]\tLoss: 1.098094\n",
      "Train Epoch: 129 [3840/50000 (8%)]\tLoss: 1.037127\n",
      "Train Epoch: 129 [5120/50000 (10%)]\tLoss: 0.896866\n",
      "Train Epoch: 129 [6400/50000 (13%)]\tLoss: 0.982134\n",
      "Train Epoch: 129 [7680/50000 (15%)]\tLoss: 1.017764\n",
      "Train Epoch: 129 [8960/50000 (18%)]\tLoss: 0.837235\n",
      "Train Epoch: 129 [10240/50000 (20%)]\tLoss: 1.243297\n",
      "Train Epoch: 129 [11520/50000 (23%)]\tLoss: 0.892929\n",
      "Train Epoch: 129 [12800/50000 (26%)]\tLoss: 1.150847\n",
      "Train Epoch: 129 [14080/50000 (28%)]\tLoss: 1.148854\n",
      "Train Epoch: 129 [15360/50000 (31%)]\tLoss: 0.853610\n",
      "Train Epoch: 129 [16640/50000 (33%)]\tLoss: 1.117456\n",
      "Train Epoch: 129 [17920/50000 (36%)]\tLoss: 1.151276\n",
      "Train Epoch: 129 [19200/50000 (38%)]\tLoss: 0.979618\n",
      "Train Epoch: 129 [20480/50000 (41%)]\tLoss: 0.917859\n",
      "Train Epoch: 129 [21760/50000 (43%)]\tLoss: 0.941770\n",
      "Train Epoch: 129 [23040/50000 (46%)]\tLoss: 1.156285\n",
      "Train Epoch: 129 [24320/50000 (49%)]\tLoss: 1.101594\n",
      "Train Epoch: 129 [25600/50000 (51%)]\tLoss: 1.082498\n",
      "Train Epoch: 129 [26880/50000 (54%)]\tLoss: 1.087325\n",
      "Train Epoch: 129 [28160/50000 (56%)]\tLoss: 1.135887\n",
      "Train Epoch: 129 [29440/50000 (59%)]\tLoss: 0.897733\n",
      "Train Epoch: 129 [30720/50000 (61%)]\tLoss: 1.038236\n",
      "Train Epoch: 129 [32000/50000 (64%)]\tLoss: 1.091534\n",
      "Train Epoch: 129 [33280/50000 (66%)]\tLoss: 0.990494\n",
      "Train Epoch: 129 [34560/50000 (69%)]\tLoss: 1.072550\n",
      "Train Epoch: 129 [35840/50000 (72%)]\tLoss: 0.913828\n",
      "Train Epoch: 129 [37120/50000 (74%)]\tLoss: 0.803513\n",
      "Train Epoch: 129 [38400/50000 (77%)]\tLoss: 1.103366\n",
      "Train Epoch: 129 [39680/50000 (79%)]\tLoss: 1.126257\n",
      "Train Epoch: 129 [40960/50000 (82%)]\tLoss: 0.910689\n",
      "Train Epoch: 129 [42240/50000 (84%)]\tLoss: 1.157010\n",
      "Train Epoch: 129 [43520/50000 (87%)]\tLoss: 1.088286\n",
      "Train Epoch: 129 [44800/50000 (90%)]\tLoss: 0.982938\n",
      "Train Epoch: 129 [46080/50000 (92%)]\tLoss: 1.050118\n",
      "Train Epoch: 129 [47360/50000 (95%)]\tLoss: 1.079223\n",
      "Train Epoch: 129 [48640/50000 (97%)]\tLoss: 1.116678\n",
      "Train Epoch: 129 [31200/50000 (100%)]\tLoss: 1.150308\n",
      "\n",
      "Test set: Avg. loss: 0.000389, Accuracy: 8364/9250 (90.42%)\n",
      "\n",
      "Train Epoch: 130 [0/50000 (0%)]\tLoss: 0.078415\n",
      "Train Epoch: 130 [1280/50000 (3%)]\tLoss: 1.173325\n",
      "Train Epoch: 130 [2560/50000 (5%)]\tLoss: 1.024789\n",
      "Train Epoch: 130 [3840/50000 (8%)]\tLoss: 0.922931\n",
      "Train Epoch: 130 [5120/50000 (10%)]\tLoss: 1.042758\n",
      "Train Epoch: 130 [6400/50000 (13%)]\tLoss: 1.108467\n",
      "Train Epoch: 130 [7680/50000 (15%)]\tLoss: 1.089386\n",
      "Train Epoch: 130 [8960/50000 (18%)]\tLoss: 0.964485\n",
      "Train Epoch: 130 [10240/50000 (20%)]\tLoss: 1.099034\n",
      "Train Epoch: 130 [11520/50000 (23%)]\tLoss: 1.118479\n",
      "Train Epoch: 130 [12800/50000 (26%)]\tLoss: 1.094099\n",
      "Train Epoch: 130 [14080/50000 (28%)]\tLoss: 0.938905\n",
      "Train Epoch: 130 [15360/50000 (31%)]\tLoss: 1.041214\n",
      "Train Epoch: 130 [16640/50000 (33%)]\tLoss: 0.964015\n",
      "Train Epoch: 130 [17920/50000 (36%)]\tLoss: 1.023268\n",
      "Train Epoch: 130 [19200/50000 (38%)]\tLoss: 1.078645\n",
      "Train Epoch: 130 [20480/50000 (41%)]\tLoss: 1.054717\n",
      "Train Epoch: 130 [21760/50000 (43%)]\tLoss: 1.004502\n",
      "Train Epoch: 130 [23040/50000 (46%)]\tLoss: 0.974000\n",
      "Train Epoch: 130 [24320/50000 (49%)]\tLoss: 1.027258\n",
      "Train Epoch: 130 [25600/50000 (51%)]\tLoss: 1.037585\n",
      "Train Epoch: 130 [26880/50000 (54%)]\tLoss: 0.901275\n",
      "Train Epoch: 130 [28160/50000 (56%)]\tLoss: 1.138349\n",
      "Train Epoch: 130 [29440/50000 (59%)]\tLoss: 0.890603\n",
      "Train Epoch: 130 [30720/50000 (61%)]\tLoss: 1.035887\n",
      "Train Epoch: 130 [32000/50000 (64%)]\tLoss: 1.069060\n",
      "Train Epoch: 130 [33280/50000 (66%)]\tLoss: 1.149376\n",
      "Train Epoch: 130 [34560/50000 (69%)]\tLoss: 0.999134\n",
      "Train Epoch: 130 [35840/50000 (72%)]\tLoss: 1.011023\n",
      "Train Epoch: 130 [37120/50000 (74%)]\tLoss: 1.051333\n",
      "Train Epoch: 130 [38400/50000 (77%)]\tLoss: 1.050870\n",
      "Train Epoch: 130 [39680/50000 (79%)]\tLoss: 1.013962\n",
      "Train Epoch: 130 [40960/50000 (82%)]\tLoss: 1.168044\n",
      "Train Epoch: 130 [42240/50000 (84%)]\tLoss: 0.832225\n",
      "Train Epoch: 130 [43520/50000 (87%)]\tLoss: 0.708233\n",
      "Train Epoch: 130 [44800/50000 (90%)]\tLoss: 1.221917\n",
      "Train Epoch: 130 [46080/50000 (92%)]\tLoss: 1.113583\n",
      "Train Epoch: 130 [47360/50000 (95%)]\tLoss: 1.107204\n",
      "Train Epoch: 130 [48640/50000 (97%)]\tLoss: 1.061028\n",
      "Train Epoch: 130 [31200/50000 (100%)]\tLoss: 1.029005\n",
      "\n",
      "Test set: Avg. loss: 0.000379, Accuracy: 8373/9250 (90.52%)\n",
      "\n",
      "Train Epoch: 131 [0/50000 (0%)]\tLoss: 0.145490\n",
      "Train Epoch: 131 [1280/50000 (3%)]\tLoss: 1.002288\n",
      "Train Epoch: 131 [2560/50000 (5%)]\tLoss: 1.242054\n",
      "Train Epoch: 131 [3840/50000 (8%)]\tLoss: 1.069352\n",
      "Train Epoch: 131 [5120/50000 (10%)]\tLoss: 1.082577\n",
      "Train Epoch: 131 [6400/50000 (13%)]\tLoss: 1.184908\n",
      "Train Epoch: 131 [7680/50000 (15%)]\tLoss: 1.120637\n",
      "Train Epoch: 131 [8960/50000 (18%)]\tLoss: 1.102059\n",
      "Train Epoch: 131 [10240/50000 (20%)]\tLoss: 0.933044\n",
      "Train Epoch: 131 [11520/50000 (23%)]\tLoss: 0.870473\n",
      "Train Epoch: 131 [12800/50000 (26%)]\tLoss: 1.209766\n",
      "Train Epoch: 131 [14080/50000 (28%)]\tLoss: 0.928645\n",
      "Train Epoch: 131 [15360/50000 (31%)]\tLoss: 1.136552\n",
      "Train Epoch: 131 [16640/50000 (33%)]\tLoss: 1.000522\n",
      "Train Epoch: 131 [17920/50000 (36%)]\tLoss: 1.206731\n",
      "Train Epoch: 131 [19200/50000 (38%)]\tLoss: 1.143943\n",
      "Train Epoch: 131 [20480/50000 (41%)]\tLoss: 1.166507\n",
      "Train Epoch: 131 [21760/50000 (43%)]\tLoss: 1.126181\n",
      "Train Epoch: 131 [23040/50000 (46%)]\tLoss: 1.111296\n",
      "Train Epoch: 131 [24320/50000 (49%)]\tLoss: 1.016459\n",
      "Train Epoch: 131 [25600/50000 (51%)]\tLoss: 1.022560\n",
      "Train Epoch: 131 [26880/50000 (54%)]\tLoss: 0.981308\n",
      "Train Epoch: 131 [28160/50000 (56%)]\tLoss: 0.967370\n",
      "Train Epoch: 131 [29440/50000 (59%)]\tLoss: 1.000185\n",
      "Train Epoch: 131 [30720/50000 (61%)]\tLoss: 0.956433\n",
      "Train Epoch: 131 [32000/50000 (64%)]\tLoss: 0.997187\n",
      "Train Epoch: 131 [33280/50000 (66%)]\tLoss: 1.120141\n",
      "Train Epoch: 131 [34560/50000 (69%)]\tLoss: 1.173748\n",
      "Train Epoch: 131 [35840/50000 (72%)]\tLoss: 0.826597\n",
      "Train Epoch: 131 [37120/50000 (74%)]\tLoss: 1.160344\n",
      "Train Epoch: 131 [38400/50000 (77%)]\tLoss: 1.101219\n",
      "Train Epoch: 131 [39680/50000 (79%)]\tLoss: 1.147149\n",
      "Train Epoch: 131 [40960/50000 (82%)]\tLoss: 1.037914\n",
      "Train Epoch: 131 [42240/50000 (84%)]\tLoss: 1.032217\n",
      "Train Epoch: 131 [43520/50000 (87%)]\tLoss: 1.110419\n",
      "Train Epoch: 131 [44800/50000 (90%)]\tLoss: 1.142332\n",
      "Train Epoch: 131 [46080/50000 (92%)]\tLoss: 1.015208\n",
      "Train Epoch: 131 [47360/50000 (95%)]\tLoss: 0.974230\n",
      "Train Epoch: 131 [48640/50000 (97%)]\tLoss: 1.139733\n",
      "Train Epoch: 131 [31200/50000 (100%)]\tLoss: 1.015312\n",
      "\n",
      "Test set: Avg. loss: 0.000397, Accuracy: 8368/9250 (90.46%)\n",
      "\n",
      "Train Epoch: 132 [0/50000 (0%)]\tLoss: 0.081882\n",
      "Train Epoch: 132 [1280/50000 (3%)]\tLoss: 1.076322\n",
      "Train Epoch: 132 [2560/50000 (5%)]\tLoss: 1.202657\n",
      "Train Epoch: 132 [3840/50000 (8%)]\tLoss: 0.948218\n",
      "Train Epoch: 132 [5120/50000 (10%)]\tLoss: 1.032641\n",
      "Train Epoch: 132 [6400/50000 (13%)]\tLoss: 1.301828\n",
      "Train Epoch: 132 [7680/50000 (15%)]\tLoss: 1.099781\n",
      "Train Epoch: 132 [8960/50000 (18%)]\tLoss: 0.948735\n",
      "Train Epoch: 132 [10240/50000 (20%)]\tLoss: 1.022378\n",
      "Train Epoch: 132 [11520/50000 (23%)]\tLoss: 1.086557\n",
      "Train Epoch: 132 [12800/50000 (26%)]\tLoss: 1.122031\n",
      "Train Epoch: 132 [14080/50000 (28%)]\tLoss: 1.115398\n",
      "Train Epoch: 132 [15360/50000 (31%)]\tLoss: 1.096159\n",
      "Train Epoch: 132 [16640/50000 (33%)]\tLoss: 0.893676\n",
      "Train Epoch: 132 [17920/50000 (36%)]\tLoss: 0.983331\n",
      "Train Epoch: 132 [19200/50000 (38%)]\tLoss: 0.924067\n",
      "Train Epoch: 132 [20480/50000 (41%)]\tLoss: 1.049833\n",
      "Train Epoch: 132 [21760/50000 (43%)]\tLoss: 1.212215\n",
      "Train Epoch: 132 [23040/50000 (46%)]\tLoss: 0.985730\n",
      "Train Epoch: 132 [24320/50000 (49%)]\tLoss: 1.168474\n",
      "Train Epoch: 132 [25600/50000 (51%)]\tLoss: 1.155007\n",
      "Train Epoch: 132 [26880/50000 (54%)]\tLoss: 1.066662\n",
      "Train Epoch: 132 [28160/50000 (56%)]\tLoss: 0.781108\n",
      "Train Epoch: 132 [29440/50000 (59%)]\tLoss: 1.038244\n",
      "Train Epoch: 132 [30720/50000 (61%)]\tLoss: 1.140561\n",
      "Train Epoch: 132 [32000/50000 (64%)]\tLoss: 1.189460\n",
      "Train Epoch: 132 [33280/50000 (66%)]\tLoss: 0.984854\n",
      "Train Epoch: 132 [34560/50000 (69%)]\tLoss: 0.867962\n",
      "Train Epoch: 132 [35840/50000 (72%)]\tLoss: 0.914644\n",
      "Train Epoch: 132 [37120/50000 (74%)]\tLoss: 1.006103\n",
      "Train Epoch: 132 [38400/50000 (77%)]\tLoss: 0.854758\n",
      "Train Epoch: 132 [39680/50000 (79%)]\tLoss: 1.036582\n",
      "Train Epoch: 132 [40960/50000 (82%)]\tLoss: 1.036903\n",
      "Train Epoch: 132 [42240/50000 (84%)]\tLoss: 1.042194\n",
      "Train Epoch: 132 [43520/50000 (87%)]\tLoss: 1.201351\n",
      "Train Epoch: 132 [44800/50000 (90%)]\tLoss: 1.034539\n",
      "Train Epoch: 132 [46080/50000 (92%)]\tLoss: 1.010840\n",
      "Train Epoch: 132 [47360/50000 (95%)]\tLoss: 1.092446\n",
      "Train Epoch: 132 [48640/50000 (97%)]\tLoss: 1.002249\n",
      "Train Epoch: 132 [31200/50000 (100%)]\tLoss: 1.045743\n",
      "\n",
      "Test set: Avg. loss: 0.000387, Accuracy: 8359/9250 (90.37%)\n",
      "\n",
      "Train Epoch: 133 [0/50000 (0%)]\tLoss: 0.132008\n",
      "Train Epoch: 133 [1280/50000 (3%)]\tLoss: 0.928576\n",
      "Train Epoch: 133 [2560/50000 (5%)]\tLoss: 1.260676\n",
      "Train Epoch: 133 [3840/50000 (8%)]\tLoss: 1.089424\n",
      "Train Epoch: 133 [5120/50000 (10%)]\tLoss: 1.068210\n",
      "Train Epoch: 133 [6400/50000 (13%)]\tLoss: 0.818338\n",
      "Train Epoch: 133 [7680/50000 (15%)]\tLoss: 1.035448\n",
      "Train Epoch: 133 [8960/50000 (18%)]\tLoss: 1.042993\n",
      "Train Epoch: 133 [10240/50000 (20%)]\tLoss: 1.179081\n",
      "Train Epoch: 133 [11520/50000 (23%)]\tLoss: 1.005450\n",
      "Train Epoch: 133 [12800/50000 (26%)]\tLoss: 0.808855\n",
      "Train Epoch: 133 [14080/50000 (28%)]\tLoss: 1.138534\n",
      "Train Epoch: 133 [15360/50000 (31%)]\tLoss: 0.955133\n",
      "Train Epoch: 133 [16640/50000 (33%)]\tLoss: 0.996605\n",
      "Train Epoch: 133 [17920/50000 (36%)]\tLoss: 1.076937\n",
      "Train Epoch: 133 [19200/50000 (38%)]\tLoss: 0.987319\n",
      "Train Epoch: 133 [20480/50000 (41%)]\tLoss: 1.030464\n",
      "Train Epoch: 133 [21760/50000 (43%)]\tLoss: 0.948931\n",
      "Train Epoch: 133 [23040/50000 (46%)]\tLoss: 1.015093\n",
      "Train Epoch: 133 [24320/50000 (49%)]\tLoss: 0.916919\n",
      "Train Epoch: 133 [25600/50000 (51%)]\tLoss: 1.010570\n",
      "Train Epoch: 133 [26880/50000 (54%)]\tLoss: 1.086726\n",
      "Train Epoch: 133 [28160/50000 (56%)]\tLoss: 1.101593\n",
      "Train Epoch: 133 [29440/50000 (59%)]\tLoss: 1.065596\n",
      "Train Epoch: 133 [30720/50000 (61%)]\tLoss: 1.246559\n",
      "Train Epoch: 133 [32000/50000 (64%)]\tLoss: 1.076744\n",
      "Train Epoch: 133 [33280/50000 (66%)]\tLoss: 0.912069\n",
      "Train Epoch: 133 [34560/50000 (69%)]\tLoss: 0.870638\n",
      "Train Epoch: 133 [35840/50000 (72%)]\tLoss: 1.014238\n",
      "Train Epoch: 133 [37120/50000 (74%)]\tLoss: 1.076084\n",
      "Train Epoch: 133 [38400/50000 (77%)]\tLoss: 0.982436\n",
      "Train Epoch: 133 [39680/50000 (79%)]\tLoss: 1.012008\n",
      "Train Epoch: 133 [40960/50000 (82%)]\tLoss: 0.926333\n",
      "Train Epoch: 133 [42240/50000 (84%)]\tLoss: 0.913250\n",
      "Train Epoch: 133 [43520/50000 (87%)]\tLoss: 1.112889\n",
      "Train Epoch: 133 [44800/50000 (90%)]\tLoss: 1.071789\n",
      "Train Epoch: 133 [46080/50000 (92%)]\tLoss: 1.078723\n",
      "Train Epoch: 133 [47360/50000 (95%)]\tLoss: 1.175283\n",
      "Train Epoch: 133 [48640/50000 (97%)]\tLoss: 0.939610\n",
      "Train Epoch: 133 [31200/50000 (100%)]\tLoss: 1.112950\n",
      "\n",
      "Test set: Avg. loss: 0.000406, Accuracy: 8332/9250 (90.08%)\n",
      "\n",
      "Train Epoch: 134 [0/50000 (0%)]\tLoss: 0.037124\n",
      "Train Epoch: 134 [1280/50000 (3%)]\tLoss: 1.158648\n",
      "Train Epoch: 134 [2560/50000 (5%)]\tLoss: 1.027395\n",
      "Train Epoch: 134 [3840/50000 (8%)]\tLoss: 0.953242\n",
      "Train Epoch: 134 [5120/50000 (10%)]\tLoss: 0.804340\n",
      "Train Epoch: 134 [6400/50000 (13%)]\tLoss: 1.017204\n",
      "Train Epoch: 134 [7680/50000 (15%)]\tLoss: 1.012672\n",
      "Train Epoch: 134 [8960/50000 (18%)]\tLoss: 1.033038\n",
      "Train Epoch: 134 [10240/50000 (20%)]\tLoss: 0.886029\n",
      "Train Epoch: 134 [11520/50000 (23%)]\tLoss: 0.834056\n",
      "Train Epoch: 134 [12800/50000 (26%)]\tLoss: 0.991844\n",
      "Train Epoch: 134 [14080/50000 (28%)]\tLoss: 0.950960\n",
      "Train Epoch: 134 [15360/50000 (31%)]\tLoss: 1.117069\n",
      "Train Epoch: 134 [16640/50000 (33%)]\tLoss: 1.114538\n",
      "Train Epoch: 134 [17920/50000 (36%)]\tLoss: 0.856212\n",
      "Train Epoch: 134 [19200/50000 (38%)]\tLoss: 1.182755\n",
      "Train Epoch: 134 [20480/50000 (41%)]\tLoss: 1.040447\n",
      "Train Epoch: 134 [21760/50000 (43%)]\tLoss: 0.920129\n",
      "Train Epoch: 134 [23040/50000 (46%)]\tLoss: 1.019140\n",
      "Train Epoch: 134 [24320/50000 (49%)]\tLoss: 1.053459\n",
      "Train Epoch: 134 [25600/50000 (51%)]\tLoss: 1.006391\n",
      "Train Epoch: 134 [26880/50000 (54%)]\tLoss: 1.001792\n",
      "Train Epoch: 134 [28160/50000 (56%)]\tLoss: 1.012550\n",
      "Train Epoch: 134 [29440/50000 (59%)]\tLoss: 1.097923\n",
      "Train Epoch: 134 [30720/50000 (61%)]\tLoss: 1.020244\n",
      "Train Epoch: 134 [32000/50000 (64%)]\tLoss: 0.877494\n",
      "Train Epoch: 134 [33280/50000 (66%)]\tLoss: 1.134092\n",
      "Train Epoch: 134 [34560/50000 (69%)]\tLoss: 1.089240\n",
      "Train Epoch: 134 [35840/50000 (72%)]\tLoss: 1.146510\n",
      "Train Epoch: 134 [37120/50000 (74%)]\tLoss: 0.750910\n",
      "Train Epoch: 134 [38400/50000 (77%)]\tLoss: 0.887276\n",
      "Train Epoch: 134 [39680/50000 (79%)]\tLoss: 1.217562\n",
      "Train Epoch: 134 [40960/50000 (82%)]\tLoss: 1.006149\n",
      "Train Epoch: 134 [42240/50000 (84%)]\tLoss: 0.801904\n",
      "Train Epoch: 134 [43520/50000 (87%)]\tLoss: 0.849008\n",
      "Train Epoch: 134 [44800/50000 (90%)]\tLoss: 1.094036\n",
      "Train Epoch: 134 [46080/50000 (92%)]\tLoss: 1.179890\n",
      "Train Epoch: 134 [47360/50000 (95%)]\tLoss: 0.973426\n",
      "Train Epoch: 134 [48640/50000 (97%)]\tLoss: 1.022871\n",
      "Train Epoch: 134 [31200/50000 (100%)]\tLoss: 0.979931\n",
      "\n",
      "Test set: Avg. loss: 0.000377, Accuracy: 8418/9250 (91.01%)\n",
      "\n",
      "Train Epoch: 135 [0/50000 (0%)]\tLoss: 0.080611\n",
      "Train Epoch: 135 [1280/50000 (3%)]\tLoss: 0.953667\n",
      "Train Epoch: 135 [2560/50000 (5%)]\tLoss: 0.955894\n",
      "Train Epoch: 135 [3840/50000 (8%)]\tLoss: 1.092189\n",
      "Train Epoch: 135 [5120/50000 (10%)]\tLoss: 1.042535\n",
      "Train Epoch: 135 [6400/50000 (13%)]\tLoss: 0.938847\n",
      "Train Epoch: 135 [7680/50000 (15%)]\tLoss: 1.077121\n",
      "Train Epoch: 135 [8960/50000 (18%)]\tLoss: 1.078784\n",
      "Train Epoch: 135 [10240/50000 (20%)]\tLoss: 1.058427\n",
      "Train Epoch: 135 [11520/50000 (23%)]\tLoss: 1.067710\n",
      "Train Epoch: 135 [12800/50000 (26%)]\tLoss: 1.084723\n",
      "Train Epoch: 135 [14080/50000 (28%)]\tLoss: 1.138455\n",
      "Train Epoch: 135 [15360/50000 (31%)]\tLoss: 1.103402\n",
      "Train Epoch: 135 [16640/50000 (33%)]\tLoss: 0.922361\n",
      "Train Epoch: 135 [17920/50000 (36%)]\tLoss: 1.140554\n",
      "Train Epoch: 135 [19200/50000 (38%)]\tLoss: 0.972125\n",
      "Train Epoch: 135 [20480/50000 (41%)]\tLoss: 1.146084\n",
      "Train Epoch: 135 [21760/50000 (43%)]\tLoss: 0.946170\n",
      "Train Epoch: 135 [23040/50000 (46%)]\tLoss: 0.932147\n",
      "Train Epoch: 135 [24320/50000 (49%)]\tLoss: 1.149409\n",
      "Train Epoch: 135 [25600/50000 (51%)]\tLoss: 0.892198\n",
      "Train Epoch: 135 [26880/50000 (54%)]\tLoss: 1.076116\n",
      "Train Epoch: 135 [28160/50000 (56%)]\tLoss: 1.042247\n",
      "Train Epoch: 135 [29440/50000 (59%)]\tLoss: 1.192675\n",
      "Train Epoch: 135 [30720/50000 (61%)]\tLoss: 0.985624\n",
      "Train Epoch: 135 [32000/50000 (64%)]\tLoss: 1.081118\n",
      "Train Epoch: 135 [33280/50000 (66%)]\tLoss: 1.141015\n",
      "Train Epoch: 135 [34560/50000 (69%)]\tLoss: 1.076863\n",
      "Train Epoch: 135 [35840/50000 (72%)]\tLoss: 0.936170\n",
      "Train Epoch: 135 [37120/50000 (74%)]\tLoss: 1.052603\n",
      "Train Epoch: 135 [38400/50000 (77%)]\tLoss: 1.122077\n",
      "Train Epoch: 135 [39680/50000 (79%)]\tLoss: 1.126199\n",
      "Train Epoch: 135 [40960/50000 (82%)]\tLoss: 0.985499\n",
      "Train Epoch: 135 [42240/50000 (84%)]\tLoss: 0.846153\n",
      "Train Epoch: 135 [43520/50000 (87%)]\tLoss: 1.093628\n",
      "Train Epoch: 135 [44800/50000 (90%)]\tLoss: 0.974385\n",
      "Train Epoch: 135 [46080/50000 (92%)]\tLoss: 1.019494\n",
      "Train Epoch: 135 [47360/50000 (95%)]\tLoss: 0.943136\n",
      "Train Epoch: 135 [48640/50000 (97%)]\tLoss: 0.917582\n",
      "Train Epoch: 135 [31200/50000 (100%)]\tLoss: 1.046016\n",
      "\n",
      "Test set: Avg. loss: 0.000368, Accuracy: 8426/9250 (91.09%)\n",
      "\n",
      "Train Epoch: 136 [0/50000 (0%)]\tLoss: 0.144890\n",
      "Train Epoch: 136 [1280/50000 (3%)]\tLoss: 0.911111\n",
      "Train Epoch: 136 [2560/50000 (5%)]\tLoss: 1.217785\n",
      "Train Epoch: 136 [3840/50000 (8%)]\tLoss: 0.936755\n",
      "Train Epoch: 136 [5120/50000 (10%)]\tLoss: 1.068739\n",
      "Train Epoch: 136 [6400/50000 (13%)]\tLoss: 1.078742\n",
      "Train Epoch: 136 [7680/50000 (15%)]\tLoss: 0.993064\n",
      "Train Epoch: 136 [8960/50000 (18%)]\tLoss: 0.934303\n",
      "Train Epoch: 136 [10240/50000 (20%)]\tLoss: 0.871373\n",
      "Train Epoch: 136 [11520/50000 (23%)]\tLoss: 0.955298\n",
      "Train Epoch: 136 [12800/50000 (26%)]\tLoss: 0.962163\n",
      "Train Epoch: 136 [14080/50000 (28%)]\tLoss: 0.836928\n",
      "Train Epoch: 136 [15360/50000 (31%)]\tLoss: 1.182943\n",
      "Train Epoch: 136 [16640/50000 (33%)]\tLoss: 1.030164\n",
      "Train Epoch: 136 [17920/50000 (36%)]\tLoss: 1.025018\n",
      "Train Epoch: 136 [19200/50000 (38%)]\tLoss: 1.104429\n",
      "Train Epoch: 136 [20480/50000 (41%)]\tLoss: 0.930787\n",
      "Train Epoch: 136 [21760/50000 (43%)]\tLoss: 0.997848\n",
      "Train Epoch: 136 [23040/50000 (46%)]\tLoss: 0.917707\n",
      "Train Epoch: 136 [24320/50000 (49%)]\tLoss: 0.819240\n",
      "Train Epoch: 136 [25600/50000 (51%)]\tLoss: 0.910433\n",
      "Train Epoch: 136 [26880/50000 (54%)]\tLoss: 1.053892\n",
      "Train Epoch: 136 [28160/50000 (56%)]\tLoss: 0.983475\n",
      "Train Epoch: 136 [29440/50000 (59%)]\tLoss: 0.853013\n",
      "Train Epoch: 136 [30720/50000 (61%)]\tLoss: 0.959365\n",
      "Train Epoch: 136 [32000/50000 (64%)]\tLoss: 1.089997\n",
      "Train Epoch: 136 [33280/50000 (66%)]\tLoss: 0.975586\n",
      "Train Epoch: 136 [34560/50000 (69%)]\tLoss: 1.093838\n",
      "Train Epoch: 136 [35840/50000 (72%)]\tLoss: 1.079641\n",
      "Train Epoch: 136 [37120/50000 (74%)]\tLoss: 1.021566\n",
      "Train Epoch: 136 [38400/50000 (77%)]\tLoss: 1.049954\n",
      "Train Epoch: 136 [39680/50000 (79%)]\tLoss: 1.060380\n",
      "Train Epoch: 136 [40960/50000 (82%)]\tLoss: 0.957440\n",
      "Train Epoch: 136 [42240/50000 (84%)]\tLoss: 1.047834\n",
      "Train Epoch: 136 [43520/50000 (87%)]\tLoss: 0.995974\n",
      "Train Epoch: 136 [44800/50000 (90%)]\tLoss: 1.096590\n",
      "Train Epoch: 136 [46080/50000 (92%)]\tLoss: 0.796369\n",
      "Train Epoch: 136 [47360/50000 (95%)]\tLoss: 1.203330\n",
      "Train Epoch: 136 [48640/50000 (97%)]\tLoss: 0.957412\n",
      "Train Epoch: 136 [31200/50000 (100%)]\tLoss: 1.123893\n",
      "\n",
      "Test set: Avg. loss: 0.000379, Accuracy: 8401/9250 (90.82%)\n",
      "\n",
      "Train Epoch: 137 [0/50000 (0%)]\tLoss: 0.151186\n",
      "Train Epoch: 137 [1280/50000 (3%)]\tLoss: 1.010674\n",
      "Train Epoch: 137 [2560/50000 (5%)]\tLoss: 1.015458\n",
      "Train Epoch: 137 [3840/50000 (8%)]\tLoss: 1.027771\n",
      "Train Epoch: 137 [5120/50000 (10%)]\tLoss: 1.021805\n",
      "Train Epoch: 137 [6400/50000 (13%)]\tLoss: 0.982910\n",
      "Train Epoch: 137 [7680/50000 (15%)]\tLoss: 1.157266\n",
      "Train Epoch: 137 [8960/50000 (18%)]\tLoss: 0.949769\n",
      "Train Epoch: 137 [10240/50000 (20%)]\tLoss: 0.929067\n",
      "Train Epoch: 137 [11520/50000 (23%)]\tLoss: 0.724294\n",
      "Train Epoch: 137 [12800/50000 (26%)]\tLoss: 1.097784\n",
      "Train Epoch: 137 [14080/50000 (28%)]\tLoss: 0.874259\n",
      "Train Epoch: 137 [15360/50000 (31%)]\tLoss: 0.968993\n",
      "Train Epoch: 137 [16640/50000 (33%)]\tLoss: 1.122629\n",
      "Train Epoch: 137 [17920/50000 (36%)]\tLoss: 0.829707\n",
      "Train Epoch: 137 [19200/50000 (38%)]\tLoss: 0.967381\n",
      "Train Epoch: 137 [20480/50000 (41%)]\tLoss: 1.178649\n",
      "Train Epoch: 137 [21760/50000 (43%)]\tLoss: 1.125081\n",
      "Train Epoch: 137 [23040/50000 (46%)]\tLoss: 0.930964\n",
      "Train Epoch: 137 [24320/50000 (49%)]\tLoss: 1.112564\n",
      "Train Epoch: 137 [25600/50000 (51%)]\tLoss: 0.906635\n",
      "Train Epoch: 137 [26880/50000 (54%)]\tLoss: 0.986776\n",
      "Train Epoch: 137 [28160/50000 (56%)]\tLoss: 0.980656\n",
      "Train Epoch: 137 [29440/50000 (59%)]\tLoss: 1.123549\n",
      "Train Epoch: 137 [30720/50000 (61%)]\tLoss: 1.082926\n",
      "Train Epoch: 137 [32000/50000 (64%)]\tLoss: 1.167232\n",
      "Train Epoch: 137 [33280/50000 (66%)]\tLoss: 1.118388\n",
      "Train Epoch: 137 [34560/50000 (69%)]\tLoss: 0.971677\n",
      "Train Epoch: 137 [35840/50000 (72%)]\tLoss: 0.904197\n",
      "Train Epoch: 137 [37120/50000 (74%)]\tLoss: 1.055192\n",
      "Train Epoch: 137 [38400/50000 (77%)]\tLoss: 1.067605\n",
      "Train Epoch: 137 [39680/50000 (79%)]\tLoss: 0.931525\n",
      "Train Epoch: 137 [40960/50000 (82%)]\tLoss: 1.106386\n",
      "Train Epoch: 137 [42240/50000 (84%)]\tLoss: 1.047170\n",
      "Train Epoch: 137 [43520/50000 (87%)]\tLoss: 1.123031\n",
      "Train Epoch: 137 [44800/50000 (90%)]\tLoss: 0.888235\n",
      "Train Epoch: 137 [46080/50000 (92%)]\tLoss: 1.075810\n",
      "Train Epoch: 137 [47360/50000 (95%)]\tLoss: 1.201953\n",
      "Train Epoch: 137 [48640/50000 (97%)]\tLoss: 1.034893\n",
      "Train Epoch: 137 [31200/50000 (100%)]\tLoss: 0.971865\n",
      "\n",
      "Test set: Avg. loss: 0.000376, Accuracy: 8421/9250 (91.04%)\n",
      "\n",
      "Train Epoch: 138 [0/50000 (0%)]\tLoss: 0.076347\n",
      "Train Epoch: 138 [1280/50000 (3%)]\tLoss: 1.140925\n",
      "Train Epoch: 138 [2560/50000 (5%)]\tLoss: 1.112809\n",
      "Train Epoch: 138 [3840/50000 (8%)]\tLoss: 0.982785\n",
      "Train Epoch: 138 [5120/50000 (10%)]\tLoss: 1.109276\n",
      "Train Epoch: 138 [6400/50000 (13%)]\tLoss: 0.988782\n",
      "Train Epoch: 138 [7680/50000 (15%)]\tLoss: 1.068513\n",
      "Train Epoch: 138 [8960/50000 (18%)]\tLoss: 1.197629\n",
      "Train Epoch: 138 [10240/50000 (20%)]\tLoss: 1.025164\n",
      "Train Epoch: 138 [11520/50000 (23%)]\tLoss: 1.175738\n",
      "Train Epoch: 138 [12800/50000 (26%)]\tLoss: 1.088476\n",
      "Train Epoch: 138 [14080/50000 (28%)]\tLoss: 1.022546\n",
      "Train Epoch: 138 [15360/50000 (31%)]\tLoss: 1.147104\n",
      "Train Epoch: 138 [16640/50000 (33%)]\tLoss: 0.947813\n",
      "Train Epoch: 138 [17920/50000 (36%)]\tLoss: 0.993953\n",
      "Train Epoch: 138 [19200/50000 (38%)]\tLoss: 0.915709\n",
      "Train Epoch: 138 [20480/50000 (41%)]\tLoss: 1.007590\n",
      "Train Epoch: 138 [21760/50000 (43%)]\tLoss: 0.851634\n",
      "Train Epoch: 138 [23040/50000 (46%)]\tLoss: 0.815780\n",
      "Train Epoch: 138 [24320/50000 (49%)]\tLoss: 1.087949\n",
      "Train Epoch: 138 [25600/50000 (51%)]\tLoss: 1.059843\n",
      "Train Epoch: 138 [26880/50000 (54%)]\tLoss: 0.913972\n",
      "Train Epoch: 138 [28160/50000 (56%)]\tLoss: 0.959050\n",
      "Train Epoch: 138 [29440/50000 (59%)]\tLoss: 1.215726\n",
      "Train Epoch: 138 [30720/50000 (61%)]\tLoss: 0.971641\n",
      "Train Epoch: 138 [32000/50000 (64%)]\tLoss: 1.223609\n",
      "Train Epoch: 138 [33280/50000 (66%)]\tLoss: 0.993911\n",
      "Train Epoch: 138 [34560/50000 (69%)]\tLoss: 1.176737\n",
      "Train Epoch: 138 [35840/50000 (72%)]\tLoss: 1.105366\n",
      "Train Epoch: 138 [37120/50000 (74%)]\tLoss: 1.013351\n",
      "Train Epoch: 138 [38400/50000 (77%)]\tLoss: 0.809293\n",
      "Train Epoch: 138 [39680/50000 (79%)]\tLoss: 1.001903\n",
      "Train Epoch: 138 [40960/50000 (82%)]\tLoss: 0.851662\n",
      "Train Epoch: 138 [42240/50000 (84%)]\tLoss: 0.962636\n",
      "Train Epoch: 138 [43520/50000 (87%)]\tLoss: 0.914571\n",
      "Train Epoch: 138 [44800/50000 (90%)]\tLoss: 1.093914\n",
      "Train Epoch: 138 [46080/50000 (92%)]\tLoss: 0.724656\n",
      "Train Epoch: 138 [47360/50000 (95%)]\tLoss: 1.088634\n",
      "Train Epoch: 138 [48640/50000 (97%)]\tLoss: 1.031457\n",
      "Train Epoch: 138 [31200/50000 (100%)]\tLoss: 1.078020\n",
      "\n",
      "Test set: Avg. loss: 0.000367, Accuracy: 8429/9250 (91.12%)\n",
      "\n",
      "Train Epoch: 139 [0/50000 (0%)]\tLoss: 0.074891\n",
      "Train Epoch: 139 [1280/50000 (3%)]\tLoss: 0.989017\n",
      "Train Epoch: 139 [2560/50000 (5%)]\tLoss: 0.930154\n",
      "Train Epoch: 139 [3840/50000 (8%)]\tLoss: 1.118543\n",
      "Train Epoch: 139 [5120/50000 (10%)]\tLoss: 1.158317\n",
      "Train Epoch: 139 [6400/50000 (13%)]\tLoss: 1.103963\n",
      "Train Epoch: 139 [7680/50000 (15%)]\tLoss: 0.967730\n",
      "Train Epoch: 139 [8960/50000 (18%)]\tLoss: 0.942636\n",
      "Train Epoch: 139 [10240/50000 (20%)]\tLoss: 0.997188\n",
      "Train Epoch: 139 [11520/50000 (23%)]\tLoss: 0.881927\n",
      "Train Epoch: 139 [12800/50000 (26%)]\tLoss: 1.229012\n",
      "Train Epoch: 139 [14080/50000 (28%)]\tLoss: 0.922513\n",
      "Train Epoch: 139 [15360/50000 (31%)]\tLoss: 1.163968\n",
      "Train Epoch: 139 [16640/50000 (33%)]\tLoss: 0.895923\n",
      "Train Epoch: 139 [17920/50000 (36%)]\tLoss: 1.145555\n",
      "Train Epoch: 139 [19200/50000 (38%)]\tLoss: 1.048910\n",
      "Train Epoch: 139 [20480/50000 (41%)]\tLoss: 0.830112\n",
      "Train Epoch: 139 [21760/50000 (43%)]\tLoss: 1.245656\n",
      "Train Epoch: 139 [23040/50000 (46%)]\tLoss: 1.014883\n",
      "Train Epoch: 139 [24320/50000 (49%)]\tLoss: 0.911644\n",
      "Train Epoch: 139 [25600/50000 (51%)]\tLoss: 1.186299\n",
      "Train Epoch: 139 [26880/50000 (54%)]\tLoss: 1.010898\n",
      "Train Epoch: 139 [28160/50000 (56%)]\tLoss: 1.117356\n",
      "Train Epoch: 139 [29440/50000 (59%)]\tLoss: 0.890089\n",
      "Train Epoch: 139 [30720/50000 (61%)]\tLoss: 0.985866\n",
      "Train Epoch: 139 [32000/50000 (64%)]\tLoss: 1.168266\n",
      "Train Epoch: 139 [33280/50000 (66%)]\tLoss: 0.956408\n",
      "Train Epoch: 139 [34560/50000 (69%)]\tLoss: 1.005015\n",
      "Train Epoch: 139 [35840/50000 (72%)]\tLoss: 1.128612\n",
      "Train Epoch: 139 [37120/50000 (74%)]\tLoss: 1.022129\n",
      "Train Epoch: 139 [38400/50000 (77%)]\tLoss: 0.955247\n",
      "Train Epoch: 139 [39680/50000 (79%)]\tLoss: 0.878857\n",
      "Train Epoch: 139 [40960/50000 (82%)]\tLoss: 1.151193\n",
      "Train Epoch: 139 [42240/50000 (84%)]\tLoss: 1.056730\n",
      "Train Epoch: 139 [43520/50000 (87%)]\tLoss: 1.166168\n",
      "Train Epoch: 139 [44800/50000 (90%)]\tLoss: 0.839920\n",
      "Train Epoch: 139 [46080/50000 (92%)]\tLoss: 0.959168\n",
      "Train Epoch: 139 [47360/50000 (95%)]\tLoss: 0.992446\n",
      "Train Epoch: 139 [48640/50000 (97%)]\tLoss: 1.072080\n",
      "Train Epoch: 139 [31200/50000 (100%)]\tLoss: 1.087404\n",
      "\n",
      "Test set: Avg. loss: 0.000386, Accuracy: 8385/9250 (90.65%)\n",
      "\n",
      "Train Epoch: 140 [0/50000 (0%)]\tLoss: 0.041648\n",
      "Train Epoch: 140 [1280/50000 (3%)]\tLoss: 1.106024\n",
      "Train Epoch: 140 [2560/50000 (5%)]\tLoss: 1.187110\n",
      "Train Epoch: 140 [3840/50000 (8%)]\tLoss: 0.947485\n",
      "Train Epoch: 140 [5120/50000 (10%)]\tLoss: 0.955958\n",
      "Train Epoch: 140 [6400/50000 (13%)]\tLoss: 0.931311\n",
      "Train Epoch: 140 [7680/50000 (15%)]\tLoss: 1.117857\n",
      "Train Epoch: 140 [8960/50000 (18%)]\tLoss: 1.299374\n",
      "Train Epoch: 140 [10240/50000 (20%)]\tLoss: 1.051236\n",
      "Train Epoch: 140 [11520/50000 (23%)]\tLoss: 0.909849\n",
      "Train Epoch: 140 [12800/50000 (26%)]\tLoss: 1.034003\n",
      "Train Epoch: 140 [14080/50000 (28%)]\tLoss: 0.905182\n",
      "Train Epoch: 140 [15360/50000 (31%)]\tLoss: 0.876002\n",
      "Train Epoch: 140 [16640/50000 (33%)]\tLoss: 1.066721\n",
      "Train Epoch: 140 [17920/50000 (36%)]\tLoss: 0.973385\n",
      "Train Epoch: 140 [19200/50000 (38%)]\tLoss: 0.945423\n",
      "Train Epoch: 140 [20480/50000 (41%)]\tLoss: 1.121512\n",
      "Train Epoch: 140 [21760/50000 (43%)]\tLoss: 1.035600\n",
      "Train Epoch: 140 [23040/50000 (46%)]\tLoss: 1.051007\n",
      "Train Epoch: 140 [24320/50000 (49%)]\tLoss: 0.952180\n",
      "Train Epoch: 140 [25600/50000 (51%)]\tLoss: 0.925456\n",
      "Train Epoch: 140 [26880/50000 (54%)]\tLoss: 1.007995\n",
      "Train Epoch: 140 [28160/50000 (56%)]\tLoss: 1.177233\n",
      "Train Epoch: 140 [29440/50000 (59%)]\tLoss: 0.889388\n",
      "Train Epoch: 140 [30720/50000 (61%)]\tLoss: 0.793525\n",
      "Train Epoch: 140 [32000/50000 (64%)]\tLoss: 1.054416\n",
      "Train Epoch: 140 [33280/50000 (66%)]\tLoss: 1.004558\n",
      "Train Epoch: 140 [34560/50000 (69%)]\tLoss: 1.203776\n",
      "Train Epoch: 140 [35840/50000 (72%)]\tLoss: 1.002741\n",
      "Train Epoch: 140 [37120/50000 (74%)]\tLoss: 1.158187\n",
      "Train Epoch: 140 [38400/50000 (77%)]\tLoss: 1.201088\n",
      "Train Epoch: 140 [39680/50000 (79%)]\tLoss: 0.966355\n",
      "Train Epoch: 140 [40960/50000 (82%)]\tLoss: 0.967041\n",
      "Train Epoch: 140 [42240/50000 (84%)]\tLoss: 1.092578\n",
      "Train Epoch: 140 [43520/50000 (87%)]\tLoss: 0.721104\n",
      "Train Epoch: 140 [44800/50000 (90%)]\tLoss: 1.261774\n",
      "Train Epoch: 140 [46080/50000 (92%)]\tLoss: 1.019750\n",
      "Train Epoch: 140 [47360/50000 (95%)]\tLoss: 1.050526\n",
      "Train Epoch: 140 [48640/50000 (97%)]\tLoss: 1.051247\n",
      "Train Epoch: 140 [31200/50000 (100%)]\tLoss: 1.012174\n",
      "\n",
      "Test set: Avg. loss: 0.000379, Accuracy: 8403/9250 (90.84%)\n",
      "\n",
      "Train Epoch: 141 [0/50000 (0%)]\tLoss: 0.140548\n",
      "Train Epoch: 141 [1280/50000 (3%)]\tLoss: 0.983139\n",
      "Train Epoch: 141 [2560/50000 (5%)]\tLoss: 1.028910\n",
      "Train Epoch: 141 [3840/50000 (8%)]\tLoss: 0.984369\n",
      "Train Epoch: 141 [5120/50000 (10%)]\tLoss: 1.121612\n",
      "Train Epoch: 141 [6400/50000 (13%)]\tLoss: 1.002666\n",
      "Train Epoch: 141 [7680/50000 (15%)]\tLoss: 0.769836\n",
      "Train Epoch: 141 [8960/50000 (18%)]\tLoss: 0.872818\n",
      "Train Epoch: 141 [10240/50000 (20%)]\tLoss: 1.036704\n",
      "Train Epoch: 141 [11520/50000 (23%)]\tLoss: 1.059626\n",
      "Train Epoch: 141 [12800/50000 (26%)]\tLoss: 0.987877\n",
      "Train Epoch: 141 [14080/50000 (28%)]\tLoss: 0.981784\n",
      "Train Epoch: 141 [15360/50000 (31%)]\tLoss: 0.977684\n",
      "Train Epoch: 141 [16640/50000 (33%)]\tLoss: 1.033312\n",
      "Train Epoch: 141 [17920/50000 (36%)]\tLoss: 1.052325\n",
      "Train Epoch: 141 [19200/50000 (38%)]\tLoss: 1.207578\n",
      "Train Epoch: 141 [20480/50000 (41%)]\tLoss: 1.203113\n",
      "Train Epoch: 141 [21760/50000 (43%)]\tLoss: 1.059004\n",
      "Train Epoch: 141 [23040/50000 (46%)]\tLoss: 0.902892\n",
      "Train Epoch: 141 [24320/50000 (49%)]\tLoss: 1.033580\n",
      "Train Epoch: 141 [25600/50000 (51%)]\tLoss: 1.018635\n",
      "Train Epoch: 141 [26880/50000 (54%)]\tLoss: 1.107712\n",
      "Train Epoch: 141 [28160/50000 (56%)]\tLoss: 1.094343\n",
      "Train Epoch: 141 [29440/50000 (59%)]\tLoss: 1.015544\n",
      "Train Epoch: 141 [30720/50000 (61%)]\tLoss: 0.860355\n",
      "Train Epoch: 141 [32000/50000 (64%)]\tLoss: 1.066809\n",
      "Train Epoch: 141 [33280/50000 (66%)]\tLoss: 1.131709\n",
      "Train Epoch: 141 [34560/50000 (69%)]\tLoss: 1.186079\n",
      "Train Epoch: 141 [35840/50000 (72%)]\tLoss: 0.918912\n",
      "Train Epoch: 141 [37120/50000 (74%)]\tLoss: 1.000203\n",
      "Train Epoch: 141 [38400/50000 (77%)]\tLoss: 0.898124\n",
      "Train Epoch: 141 [39680/50000 (79%)]\tLoss: 1.058771\n",
      "Train Epoch: 141 [40960/50000 (82%)]\tLoss: 1.061695\n",
      "Train Epoch: 141 [42240/50000 (84%)]\tLoss: 1.182008\n",
      "Train Epoch: 141 [43520/50000 (87%)]\tLoss: 1.014741\n",
      "Train Epoch: 141 [44800/50000 (90%)]\tLoss: 0.941195\n",
      "Train Epoch: 141 [46080/50000 (92%)]\tLoss: 1.039245\n",
      "Train Epoch: 141 [47360/50000 (95%)]\tLoss: 0.968154\n",
      "Train Epoch: 141 [48640/50000 (97%)]\tLoss: 1.014365\n",
      "Train Epoch: 141 [31200/50000 (100%)]\tLoss: 1.145177\n",
      "\n",
      "Test set: Avg. loss: 0.000378, Accuracy: 8406/9250 (90.88%)\n",
      "\n",
      "Train Epoch: 142 [0/50000 (0%)]\tLoss: 0.052303\n",
      "Train Epoch: 142 [1280/50000 (3%)]\tLoss: 0.603167\n",
      "Train Epoch: 142 [2560/50000 (5%)]\tLoss: 1.176283\n",
      "Train Epoch: 142 [3840/50000 (8%)]\tLoss: 1.086959\n",
      "Train Epoch: 142 [5120/50000 (10%)]\tLoss: 0.904438\n",
      "Train Epoch: 142 [6400/50000 (13%)]\tLoss: 1.132369\n",
      "Train Epoch: 142 [7680/50000 (15%)]\tLoss: 1.002726\n",
      "Train Epoch: 142 [8960/50000 (18%)]\tLoss: 1.034540\n",
      "Train Epoch: 142 [10240/50000 (20%)]\tLoss: 0.866531\n",
      "Train Epoch: 142 [11520/50000 (23%)]\tLoss: 1.087598\n",
      "Train Epoch: 142 [12800/50000 (26%)]\tLoss: 0.909660\n",
      "Train Epoch: 142 [14080/50000 (28%)]\tLoss: 1.049693\n",
      "Train Epoch: 142 [15360/50000 (31%)]\tLoss: 1.117517\n",
      "Train Epoch: 142 [16640/50000 (33%)]\tLoss: 0.937036\n",
      "Train Epoch: 142 [17920/50000 (36%)]\tLoss: 0.950921\n",
      "Train Epoch: 142 [19200/50000 (38%)]\tLoss: 0.770372\n",
      "Train Epoch: 142 [20480/50000 (41%)]\tLoss: 1.078361\n",
      "Train Epoch: 142 [21760/50000 (43%)]\tLoss: 1.110374\n",
      "Train Epoch: 142 [23040/50000 (46%)]\tLoss: 1.133024\n",
      "Train Epoch: 142 [24320/50000 (49%)]\tLoss: 1.036742\n",
      "Train Epoch: 142 [25600/50000 (51%)]\tLoss: 1.084254\n",
      "Train Epoch: 142 [26880/50000 (54%)]\tLoss: 1.276578\n",
      "Train Epoch: 142 [28160/50000 (56%)]\tLoss: 1.040879\n",
      "Train Epoch: 142 [29440/50000 (59%)]\tLoss: 0.820313\n",
      "Train Epoch: 142 [30720/50000 (61%)]\tLoss: 0.833900\n",
      "Train Epoch: 142 [32000/50000 (64%)]\tLoss: 1.089443\n",
      "Train Epoch: 142 [33280/50000 (66%)]\tLoss: 1.113517\n",
      "Train Epoch: 142 [34560/50000 (69%)]\tLoss: 1.124273\n",
      "Train Epoch: 142 [35840/50000 (72%)]\tLoss: 1.027093\n",
      "Train Epoch: 142 [37120/50000 (74%)]\tLoss: 0.967753\n",
      "Train Epoch: 142 [38400/50000 (77%)]\tLoss: 1.092530\n",
      "Train Epoch: 142 [39680/50000 (79%)]\tLoss: 1.249269\n",
      "Train Epoch: 142 [40960/50000 (82%)]\tLoss: 0.898093\n",
      "Train Epoch: 142 [42240/50000 (84%)]\tLoss: 0.932359\n",
      "Train Epoch: 142 [43520/50000 (87%)]\tLoss: 0.969372\n",
      "Train Epoch: 142 [44800/50000 (90%)]\tLoss: 0.917486\n",
      "Train Epoch: 142 [46080/50000 (92%)]\tLoss: 1.082050\n",
      "Train Epoch: 142 [47360/50000 (95%)]\tLoss: 1.037970\n",
      "Train Epoch: 142 [48640/50000 (97%)]\tLoss: 0.792847\n",
      "Train Epoch: 142 [31200/50000 (100%)]\tLoss: 1.099768\n",
      "\n",
      "Test set: Avg. loss: 0.000375, Accuracy: 8451/9250 (91.36%)\n",
      "\n",
      "Train Epoch: 143 [0/50000 (0%)]\tLoss: 0.136398\n",
      "Train Epoch: 143 [1280/50000 (3%)]\tLoss: 0.878401\n",
      "Train Epoch: 143 [2560/50000 (5%)]\tLoss: 1.082765\n",
      "Train Epoch: 143 [3840/50000 (8%)]\tLoss: 0.948919\n",
      "Train Epoch: 143 [5120/50000 (10%)]\tLoss: 1.042248\n",
      "Train Epoch: 143 [6400/50000 (13%)]\tLoss: 1.105772\n",
      "Train Epoch: 143 [7680/50000 (15%)]\tLoss: 1.171351\n",
      "Train Epoch: 143 [8960/50000 (18%)]\tLoss: 0.949789\n",
      "Train Epoch: 143 [10240/50000 (20%)]\tLoss: 1.067314\n",
      "Train Epoch: 143 [11520/50000 (23%)]\tLoss: 1.073545\n",
      "Train Epoch: 143 [12800/50000 (26%)]\tLoss: 0.968868\n",
      "Train Epoch: 143 [14080/50000 (28%)]\tLoss: 0.912676\n",
      "Train Epoch: 143 [15360/50000 (31%)]\tLoss: 0.902608\n",
      "Train Epoch: 143 [16640/50000 (33%)]\tLoss: 0.881492\n",
      "Train Epoch: 143 [17920/50000 (36%)]\tLoss: 1.042387\n",
      "Train Epoch: 143 [19200/50000 (38%)]\tLoss: 1.088094\n",
      "Train Epoch: 143 [20480/50000 (41%)]\tLoss: 0.848100\n",
      "Train Epoch: 143 [21760/50000 (43%)]\tLoss: 1.160365\n",
      "Train Epoch: 143 [23040/50000 (46%)]\tLoss: 0.898258\n",
      "Train Epoch: 143 [24320/50000 (49%)]\tLoss: 1.079519\n",
      "Train Epoch: 143 [25600/50000 (51%)]\tLoss: 1.080292\n",
      "Train Epoch: 143 [26880/50000 (54%)]\tLoss: 1.052676\n",
      "Train Epoch: 143 [28160/50000 (56%)]\tLoss: 1.146124\n",
      "Train Epoch: 143 [29440/50000 (59%)]\tLoss: 1.159428\n",
      "Train Epoch: 143 [30720/50000 (61%)]\tLoss: 1.102354\n",
      "Train Epoch: 143 [32000/50000 (64%)]\tLoss: 0.978588\n",
      "Train Epoch: 143 [33280/50000 (66%)]\tLoss: 1.286236\n",
      "Train Epoch: 143 [34560/50000 (69%)]\tLoss: 1.005305\n",
      "Train Epoch: 143 [35840/50000 (72%)]\tLoss: 0.788457\n",
      "Train Epoch: 143 [37120/50000 (74%)]\tLoss: 0.981030\n",
      "Train Epoch: 143 [38400/50000 (77%)]\tLoss: 1.125691\n",
      "Train Epoch: 143 [39680/50000 (79%)]\tLoss: 0.972334\n",
      "Train Epoch: 143 [40960/50000 (82%)]\tLoss: 0.777656\n",
      "Train Epoch: 143 [42240/50000 (84%)]\tLoss: 1.286434\n",
      "Train Epoch: 143 [43520/50000 (87%)]\tLoss: 1.210093\n",
      "Train Epoch: 143 [44800/50000 (90%)]\tLoss: 0.894008\n",
      "Train Epoch: 143 [46080/50000 (92%)]\tLoss: 1.149357\n",
      "Train Epoch: 143 [47360/50000 (95%)]\tLoss: 1.107205\n",
      "Train Epoch: 143 [48640/50000 (97%)]\tLoss: 1.038803\n",
      "Train Epoch: 143 [31200/50000 (100%)]\tLoss: 1.101692\n",
      "\n",
      "Test set: Avg. loss: 0.000385, Accuracy: 8426/9250 (91.09%)\n",
      "\n",
      "Train Epoch: 144 [0/50000 (0%)]\tLoss: 0.024024\n",
      "Train Epoch: 144 [1280/50000 (3%)]\tLoss: 1.073286\n",
      "Train Epoch: 144 [2560/50000 (5%)]\tLoss: 1.122708\n",
      "Train Epoch: 144 [3840/50000 (8%)]\tLoss: 1.157449\n",
      "Train Epoch: 144 [5120/50000 (10%)]\tLoss: 0.806725\n",
      "Train Epoch: 144 [6400/50000 (13%)]\tLoss: 1.012391\n",
      "Train Epoch: 144 [7680/50000 (15%)]\tLoss: 0.830536\n",
      "Train Epoch: 144 [8960/50000 (18%)]\tLoss: 1.059592\n",
      "Train Epoch: 144 [10240/50000 (20%)]\tLoss: 1.063580\n",
      "Train Epoch: 144 [11520/50000 (23%)]\tLoss: 0.854393\n",
      "Train Epoch: 144 [12800/50000 (26%)]\tLoss: 1.032087\n",
      "Train Epoch: 144 [14080/50000 (28%)]\tLoss: 0.862691\n",
      "Train Epoch: 144 [15360/50000 (31%)]\tLoss: 1.097129\n",
      "Train Epoch: 144 [16640/50000 (33%)]\tLoss: 1.098629\n",
      "Train Epoch: 144 [17920/50000 (36%)]\tLoss: 0.979829\n",
      "Train Epoch: 144 [19200/50000 (38%)]\tLoss: 0.795085\n",
      "Train Epoch: 144 [20480/50000 (41%)]\tLoss: 0.856283\n",
      "Train Epoch: 144 [21760/50000 (43%)]\tLoss: 0.815338\n",
      "Train Epoch: 144 [23040/50000 (46%)]\tLoss: 1.220190\n",
      "Train Epoch: 144 [24320/50000 (49%)]\tLoss: 0.791613\n",
      "Train Epoch: 144 [25600/50000 (51%)]\tLoss: 1.163616\n",
      "Train Epoch: 144 [26880/50000 (54%)]\tLoss: 1.212030\n",
      "Train Epoch: 144 [28160/50000 (56%)]\tLoss: 1.010270\n",
      "Train Epoch: 144 [29440/50000 (59%)]\tLoss: 1.099800\n",
      "Train Epoch: 144 [30720/50000 (61%)]\tLoss: 0.892310\n",
      "Train Epoch: 144 [32000/50000 (64%)]\tLoss: 1.028020\n",
      "Train Epoch: 144 [33280/50000 (66%)]\tLoss: 0.965023\n",
      "Train Epoch: 144 [34560/50000 (69%)]\tLoss: 1.058065\n",
      "Train Epoch: 144 [35840/50000 (72%)]\tLoss: 1.191948\n",
      "Train Epoch: 144 [37120/50000 (74%)]\tLoss: 0.950215\n",
      "Train Epoch: 144 [38400/50000 (77%)]\tLoss: 0.967956\n",
      "Train Epoch: 144 [39680/50000 (79%)]\tLoss: 0.840176\n",
      "Train Epoch: 144 [40960/50000 (82%)]\tLoss: 0.934894\n",
      "Train Epoch: 144 [42240/50000 (84%)]\tLoss: 1.115224\n",
      "Train Epoch: 144 [43520/50000 (87%)]\tLoss: 1.240963\n",
      "Train Epoch: 144 [44800/50000 (90%)]\tLoss: 0.946902\n",
      "Train Epoch: 144 [46080/50000 (92%)]\tLoss: 1.085738\n",
      "Train Epoch: 144 [47360/50000 (95%)]\tLoss: 1.068793\n",
      "Train Epoch: 144 [48640/50000 (97%)]\tLoss: 0.921585\n",
      "Train Epoch: 144 [31200/50000 (100%)]\tLoss: 1.035440\n",
      "\n",
      "Test set: Avg. loss: 0.000356, Accuracy: 8451/9250 (91.36%)\n",
      "\n",
      "Train Epoch: 145 [0/50000 (0%)]\tLoss: 0.085241\n",
      "Train Epoch: 145 [1280/50000 (3%)]\tLoss: 0.980860\n",
      "Train Epoch: 145 [2560/50000 (5%)]\tLoss: 0.910848\n",
      "Train Epoch: 145 [3840/50000 (8%)]\tLoss: 1.172589\n",
      "Train Epoch: 145 [5120/50000 (10%)]\tLoss: 1.106880\n",
      "Train Epoch: 145 [6400/50000 (13%)]\tLoss: 0.856110\n",
      "Train Epoch: 145 [7680/50000 (15%)]\tLoss: 1.085583\n",
      "Train Epoch: 145 [8960/50000 (18%)]\tLoss: 1.036643\n",
      "Train Epoch: 145 [10240/50000 (20%)]\tLoss: 1.064423\n",
      "Train Epoch: 145 [11520/50000 (23%)]\tLoss: 1.059009\n",
      "Train Epoch: 145 [12800/50000 (26%)]\tLoss: 0.939280\n",
      "Train Epoch: 145 [14080/50000 (28%)]\tLoss: 1.031987\n",
      "Train Epoch: 145 [15360/50000 (31%)]\tLoss: 1.071752\n",
      "Train Epoch: 145 [16640/50000 (33%)]\tLoss: 1.007429\n",
      "Train Epoch: 145 [17920/50000 (36%)]\tLoss: 1.028580\n",
      "Train Epoch: 145 [19200/50000 (38%)]\tLoss: 1.013042\n",
      "Train Epoch: 145 [20480/50000 (41%)]\tLoss: 1.089381\n",
      "Train Epoch: 145 [21760/50000 (43%)]\tLoss: 0.955071\n",
      "Train Epoch: 145 [23040/50000 (46%)]\tLoss: 1.013149\n",
      "Train Epoch: 145 [24320/50000 (49%)]\tLoss: 1.050804\n",
      "Train Epoch: 145 [25600/50000 (51%)]\tLoss: 0.899277\n",
      "Train Epoch: 145 [26880/50000 (54%)]\tLoss: 0.837400\n",
      "Train Epoch: 145 [28160/50000 (56%)]\tLoss: 1.047704\n",
      "Train Epoch: 145 [29440/50000 (59%)]\tLoss: 0.912511\n",
      "Train Epoch: 145 [30720/50000 (61%)]\tLoss: 0.890101\n",
      "Train Epoch: 145 [32000/50000 (64%)]\tLoss: 1.154897\n",
      "Train Epoch: 145 [33280/50000 (66%)]\tLoss: 0.787685\n",
      "Train Epoch: 145 [34560/50000 (69%)]\tLoss: 0.994551\n",
      "Train Epoch: 145 [35840/50000 (72%)]\tLoss: 1.068090\n",
      "Train Epoch: 145 [37120/50000 (74%)]\tLoss: 0.944483\n",
      "Train Epoch: 145 [38400/50000 (77%)]\tLoss: 1.171094\n",
      "Train Epoch: 145 [39680/50000 (79%)]\tLoss: 0.974332\n",
      "Train Epoch: 145 [40960/50000 (82%)]\tLoss: 0.834991\n",
      "Train Epoch: 145 [42240/50000 (84%)]\tLoss: 0.797695\n",
      "Train Epoch: 145 [43520/50000 (87%)]\tLoss: 0.867440\n",
      "Train Epoch: 145 [44800/50000 (90%)]\tLoss: 1.054198\n",
      "Train Epoch: 145 [46080/50000 (92%)]\tLoss: 0.950447\n",
      "Train Epoch: 145 [47360/50000 (95%)]\tLoss: 1.105948\n",
      "Train Epoch: 145 [48640/50000 (97%)]\tLoss: 1.018146\n",
      "Train Epoch: 145 [31200/50000 (100%)]\tLoss: 0.995977\n",
      "\n",
      "Test set: Avg. loss: 0.000363, Accuracy: 8451/9250 (91.36%)\n",
      "\n",
      "Train Epoch: 146 [0/50000 (0%)]\tLoss: 0.138978\n",
      "Train Epoch: 146 [1280/50000 (3%)]\tLoss: 0.865335\n",
      "Train Epoch: 146 [2560/50000 (5%)]\tLoss: 0.807501\n",
      "Train Epoch: 146 [3840/50000 (8%)]\tLoss: 1.262166\n",
      "Train Epoch: 146 [5120/50000 (10%)]\tLoss: 1.032772\n",
      "Train Epoch: 146 [6400/50000 (13%)]\tLoss: 1.037992\n",
      "Train Epoch: 146 [7680/50000 (15%)]\tLoss: 1.012574\n",
      "Train Epoch: 146 [8960/50000 (18%)]\tLoss: 1.020763\n",
      "Train Epoch: 146 [10240/50000 (20%)]\tLoss: 0.830463\n",
      "Train Epoch: 146 [11520/50000 (23%)]\tLoss: 0.875030\n",
      "Train Epoch: 146 [12800/50000 (26%)]\tLoss: 1.003273\n",
      "Train Epoch: 146 [14080/50000 (28%)]\tLoss: 1.112512\n",
      "Train Epoch: 146 [15360/50000 (31%)]\tLoss: 0.765449\n",
      "Train Epoch: 146 [16640/50000 (33%)]\tLoss: 0.737358\n",
      "Train Epoch: 146 [17920/50000 (36%)]\tLoss: 1.170467\n",
      "Train Epoch: 146 [19200/50000 (38%)]\tLoss: 0.944120\n",
      "Train Epoch: 146 [20480/50000 (41%)]\tLoss: 1.148144\n",
      "Train Epoch: 146 [21760/50000 (43%)]\tLoss: 0.946859\n",
      "Train Epoch: 146 [23040/50000 (46%)]\tLoss: 1.048593\n",
      "Train Epoch: 146 [24320/50000 (49%)]\tLoss: 1.154927\n",
      "Train Epoch: 146 [25600/50000 (51%)]\tLoss: 1.073018\n",
      "Train Epoch: 146 [26880/50000 (54%)]\tLoss: 0.994951\n",
      "Train Epoch: 146 [28160/50000 (56%)]\tLoss: 0.972623\n",
      "Train Epoch: 146 [29440/50000 (59%)]\tLoss: 1.118462\n",
      "Train Epoch: 146 [30720/50000 (61%)]\tLoss: 0.996283\n",
      "Train Epoch: 146 [32000/50000 (64%)]\tLoss: 0.885946\n",
      "Train Epoch: 146 [33280/50000 (66%)]\tLoss: 0.989577\n",
      "Train Epoch: 146 [34560/50000 (69%)]\tLoss: 0.912723\n",
      "Train Epoch: 146 [35840/50000 (72%)]\tLoss: 1.052654\n",
      "Train Epoch: 146 [37120/50000 (74%)]\tLoss: 1.037805\n",
      "Train Epoch: 146 [38400/50000 (77%)]\tLoss: 1.052163\n",
      "Train Epoch: 146 [39680/50000 (79%)]\tLoss: 0.936401\n",
      "Train Epoch: 146 [40960/50000 (82%)]\tLoss: 1.063060\n",
      "Train Epoch: 146 [42240/50000 (84%)]\tLoss: 1.129022\n",
      "Train Epoch: 146 [43520/50000 (87%)]\tLoss: 1.133553\n",
      "Train Epoch: 146 [44800/50000 (90%)]\tLoss: 0.972179\n",
      "Train Epoch: 146 [46080/50000 (92%)]\tLoss: 1.064358\n",
      "Train Epoch: 146 [47360/50000 (95%)]\tLoss: 1.011775\n",
      "Train Epoch: 146 [48640/50000 (97%)]\tLoss: 0.837506\n",
      "Train Epoch: 146 [31200/50000 (100%)]\tLoss: 0.859332\n",
      "\n",
      "Test set: Avg. loss: 0.000332, Accuracy: 8461/9250 (91.47%)\n",
      "\n",
      "Train Epoch: 147 [0/50000 (0%)]\tLoss: 0.118023\n",
      "Train Epoch: 147 [1280/50000 (3%)]\tLoss: 0.870218\n",
      "Train Epoch: 147 [2560/50000 (5%)]\tLoss: 0.790651\n",
      "Train Epoch: 147 [3840/50000 (8%)]\tLoss: 1.030952\n",
      "Train Epoch: 147 [5120/50000 (10%)]\tLoss: 1.031864\n",
      "Train Epoch: 147 [6400/50000 (13%)]\tLoss: 1.010857\n",
      "Train Epoch: 147 [7680/50000 (15%)]\tLoss: 1.070002\n",
      "Train Epoch: 147 [8960/50000 (18%)]\tLoss: 1.218472\n",
      "Train Epoch: 147 [10240/50000 (20%)]\tLoss: 0.952226\n",
      "Train Epoch: 147 [11520/50000 (23%)]\tLoss: 1.143491\n",
      "Train Epoch: 147 [12800/50000 (26%)]\tLoss: 1.084687\n",
      "Train Epoch: 147 [14080/50000 (28%)]\tLoss: 1.067499\n",
      "Train Epoch: 147 [15360/50000 (31%)]\tLoss: 1.069530\n",
      "Train Epoch: 147 [16640/50000 (33%)]\tLoss: 1.047264\n",
      "Train Epoch: 147 [17920/50000 (36%)]\tLoss: 1.052184\n",
      "Train Epoch: 147 [19200/50000 (38%)]\tLoss: 1.052327\n",
      "Train Epoch: 147 [20480/50000 (41%)]\tLoss: 1.037990\n",
      "Train Epoch: 147 [21760/50000 (43%)]\tLoss: 1.047981\n",
      "Train Epoch: 147 [23040/50000 (46%)]\tLoss: 1.035443\n",
      "Train Epoch: 147 [24320/50000 (49%)]\tLoss: 1.087952\n",
      "Train Epoch: 147 [25600/50000 (51%)]\tLoss: 1.131438\n",
      "Train Epoch: 147 [26880/50000 (54%)]\tLoss: 0.950899\n",
      "Train Epoch: 147 [28160/50000 (56%)]\tLoss: 1.060947\n",
      "Train Epoch: 147 [29440/50000 (59%)]\tLoss: 1.014798\n",
      "Train Epoch: 147 [30720/50000 (61%)]\tLoss: 1.087632\n",
      "Train Epoch: 147 [32000/50000 (64%)]\tLoss: 0.815890\n",
      "Train Epoch: 147 [33280/50000 (66%)]\tLoss: 1.006765\n",
      "Train Epoch: 147 [34560/50000 (69%)]\tLoss: 0.881172\n",
      "Train Epoch: 147 [35840/50000 (72%)]\tLoss: 1.096101\n",
      "Train Epoch: 147 [37120/50000 (74%)]\tLoss: 1.041195\n",
      "Train Epoch: 147 [38400/50000 (77%)]\tLoss: 0.922020\n",
      "Train Epoch: 147 [39680/50000 (79%)]\tLoss: 0.995061\n",
      "Train Epoch: 147 [40960/50000 (82%)]\tLoss: 1.044666\n",
      "Train Epoch: 147 [42240/50000 (84%)]\tLoss: 1.124307\n",
      "Train Epoch: 147 [43520/50000 (87%)]\tLoss: 1.086569\n",
      "Train Epoch: 147 [44800/50000 (90%)]\tLoss: 1.130828\n",
      "Train Epoch: 147 [46080/50000 (92%)]\tLoss: 1.014453\n",
      "Train Epoch: 147 [47360/50000 (95%)]\tLoss: 0.984673\n",
      "Train Epoch: 147 [48640/50000 (97%)]\tLoss: 1.138092\n",
      "Train Epoch: 147 [31200/50000 (100%)]\tLoss: 0.908499\n",
      "\n",
      "Test set: Avg. loss: 0.000355, Accuracy: 8460/9250 (91.46%)\n",
      "\n",
      "Train Epoch: 148 [0/50000 (0%)]\tLoss: 0.041625\n",
      "Train Epoch: 148 [1280/50000 (3%)]\tLoss: 0.987824\n",
      "Train Epoch: 148 [2560/50000 (5%)]\tLoss: 1.087014\n",
      "Train Epoch: 148 [3840/50000 (8%)]\tLoss: 1.031356\n",
      "Train Epoch: 148 [5120/50000 (10%)]\tLoss: 1.025081\n",
      "Train Epoch: 148 [6400/50000 (13%)]\tLoss: 1.078946\n",
      "Train Epoch: 148 [7680/50000 (15%)]\tLoss: 0.812356\n",
      "Train Epoch: 148 [8960/50000 (18%)]\tLoss: 1.035641\n",
      "Train Epoch: 148 [10240/50000 (20%)]\tLoss: 0.822874\n",
      "Train Epoch: 148 [11520/50000 (23%)]\tLoss: 1.078390\n",
      "Train Epoch: 148 [12800/50000 (26%)]\tLoss: 1.035809\n",
      "Train Epoch: 148 [14080/50000 (28%)]\tLoss: 1.108898\n",
      "Train Epoch: 148 [15360/50000 (31%)]\tLoss: 0.934417\n",
      "Train Epoch: 148 [16640/50000 (33%)]\tLoss: 0.987915\n",
      "Train Epoch: 148 [17920/50000 (36%)]\tLoss: 0.798199\n",
      "Train Epoch: 148 [19200/50000 (38%)]\tLoss: 0.936614\n",
      "Train Epoch: 148 [20480/50000 (41%)]\tLoss: 0.928175\n",
      "Train Epoch: 148 [21760/50000 (43%)]\tLoss: 1.013151\n",
      "Train Epoch: 148 [23040/50000 (46%)]\tLoss: 1.028534\n",
      "Train Epoch: 148 [24320/50000 (49%)]\tLoss: 1.124824\n",
      "Train Epoch: 148 [25600/50000 (51%)]\tLoss: 0.870253\n",
      "Train Epoch: 148 [26880/50000 (54%)]\tLoss: 1.098813\n",
      "Train Epoch: 148 [28160/50000 (56%)]\tLoss: 1.019909\n",
      "Train Epoch: 148 [29440/50000 (59%)]\tLoss: 1.075759\n",
      "Train Epoch: 148 [30720/50000 (61%)]\tLoss: 0.959968\n",
      "Train Epoch: 148 [32000/50000 (64%)]\tLoss: 1.026172\n",
      "Train Epoch: 148 [33280/50000 (66%)]\tLoss: 1.151781\n",
      "Train Epoch: 148 [34560/50000 (69%)]\tLoss: 1.093463\n",
      "Train Epoch: 148 [35840/50000 (72%)]\tLoss: 0.774251\n",
      "Train Epoch: 148 [37120/50000 (74%)]\tLoss: 1.022366\n",
      "Train Epoch: 148 [38400/50000 (77%)]\tLoss: 0.934559\n",
      "Train Epoch: 148 [39680/50000 (79%)]\tLoss: 1.032677\n",
      "Train Epoch: 148 [40960/50000 (82%)]\tLoss: 1.060308\n",
      "Train Epoch: 148 [42240/50000 (84%)]\tLoss: 1.124018\n",
      "Train Epoch: 148 [43520/50000 (87%)]\tLoss: 1.086057\n",
      "Train Epoch: 148 [44800/50000 (90%)]\tLoss: 1.036646\n",
      "Train Epoch: 148 [46080/50000 (92%)]\tLoss: 0.984980\n",
      "Train Epoch: 148 [47360/50000 (95%)]\tLoss: 1.053492\n",
      "Train Epoch: 148 [48640/50000 (97%)]\tLoss: 0.983151\n",
      "Train Epoch: 148 [31200/50000 (100%)]\tLoss: 0.954038\n",
      "Train Epoch: 149 [0/50000 (0%)]\tLoss: 0.132135\n",
      "Train Epoch: 149 [1280/50000 (3%)]\tLoss: 1.132496\n",
      "Train Epoch: 149 [2560/50000 (5%)]\tLoss: 1.149614\n",
      "Train Epoch: 149 [3840/50000 (8%)]\tLoss: 1.025311\n",
      "Train Epoch: 149 [5120/50000 (10%)]\tLoss: 1.119981\n",
      "Train Epoch: 149 [6400/50000 (13%)]\tLoss: 0.966056\n",
      "Train Epoch: 149 [7680/50000 (15%)]\tLoss: 1.100438\n",
      "Train Epoch: 149 [8960/50000 (18%)]\tLoss: 1.081395\n",
      "Train Epoch: 149 [10240/50000 (20%)]\tLoss: 0.825675\n",
      "Train Epoch: 149 [11520/50000 (23%)]\tLoss: 1.052669\n",
      "Train Epoch: 149 [12800/50000 (26%)]\tLoss: 1.089646\n",
      "Train Epoch: 149 [14080/50000 (28%)]\tLoss: 0.900913\n",
      "Train Epoch: 149 [15360/50000 (31%)]\tLoss: 1.028646\n",
      "Train Epoch: 149 [16640/50000 (33%)]\tLoss: 0.845531\n",
      "Train Epoch: 149 [17920/50000 (36%)]\tLoss: 0.865708\n",
      "Train Epoch: 149 [19200/50000 (38%)]\tLoss: 0.948706\n",
      "Train Epoch: 149 [20480/50000 (41%)]\tLoss: 1.156863\n",
      "Train Epoch: 149 [21760/50000 (43%)]\tLoss: 1.194059\n",
      "Train Epoch: 149 [23040/50000 (46%)]\tLoss: 0.909991\n",
      "Train Epoch: 149 [24320/50000 (49%)]\tLoss: 1.103461\n",
      "Train Epoch: 149 [25600/50000 (51%)]\tLoss: 1.039983\n",
      "Train Epoch: 149 [26880/50000 (54%)]\tLoss: 1.018975\n",
      "Train Epoch: 149 [28160/50000 (56%)]\tLoss: 1.070199\n",
      "Train Epoch: 149 [29440/50000 (59%)]\tLoss: 1.014820\n",
      "Train Epoch: 149 [30720/50000 (61%)]\tLoss: 1.124340\n",
      "Train Epoch: 149 [32000/50000 (64%)]\tLoss: 1.107258\n",
      "Train Epoch: 149 [33280/50000 (66%)]\tLoss: 0.927496\n",
      "Train Epoch: 149 [34560/50000 (69%)]\tLoss: 1.136652\n",
      "Train Epoch: 149 [35840/50000 (72%)]\tLoss: 1.087619\n",
      "Train Epoch: 149 [37120/50000 (74%)]\tLoss: 0.969067\n",
      "Train Epoch: 149 [38400/50000 (77%)]\tLoss: 1.059064\n",
      "Train Epoch: 149 [39680/50000 (79%)]\tLoss: 0.959960\n",
      "Train Epoch: 149 [40960/50000 (82%)]\tLoss: 0.861794\n",
      "Train Epoch: 149 [42240/50000 (84%)]\tLoss: 0.782729\n",
      "Train Epoch: 149 [43520/50000 (87%)]\tLoss: 1.206728\n",
      "Train Epoch: 149 [44800/50000 (90%)]\tLoss: 0.930096\n",
      "Train Epoch: 149 [46080/50000 (92%)]\tLoss: 0.923901\n",
      "Train Epoch: 149 [47360/50000 (95%)]\tLoss: 1.008829\n",
      "Train Epoch: 149 [48640/50000 (97%)]\tLoss: 0.979910\n",
      "Train Epoch: 149 [31200/50000 (100%)]\tLoss: 1.031465\n",
      "\n",
      "Test set: Avg. loss: 0.000367, Accuracy: 8462/9250 (91.48%)\n",
      "\n",
      "Train Epoch: 150 [0/50000 (0%)]\tLoss: 0.142901\n",
      "Train Epoch: 150 [1280/50000 (3%)]\tLoss: 0.916339\n",
      "Train Epoch: 150 [2560/50000 (5%)]\tLoss: 1.050914\n",
      "Train Epoch: 150 [3840/50000 (8%)]\tLoss: 0.965121\n",
      "Train Epoch: 150 [5120/50000 (10%)]\tLoss: 1.055434\n",
      "Train Epoch: 150 [6400/50000 (13%)]\tLoss: 1.051782\n",
      "Train Epoch: 150 [7680/50000 (15%)]\tLoss: 0.971270\n",
      "Train Epoch: 150 [8960/50000 (18%)]\tLoss: 1.008295\n",
      "Train Epoch: 150 [10240/50000 (20%)]\tLoss: 0.856835\n",
      "Train Epoch: 150 [11520/50000 (23%)]\tLoss: 1.159588\n",
      "Train Epoch: 150 [12800/50000 (26%)]\tLoss: 0.800448\n",
      "Train Epoch: 150 [14080/50000 (28%)]\tLoss: 0.922944\n",
      "Train Epoch: 150 [15360/50000 (31%)]\tLoss: 0.919017\n",
      "Train Epoch: 150 [16640/50000 (33%)]\tLoss: 1.082902\n",
      "Train Epoch: 150 [17920/50000 (36%)]\tLoss: 1.159326\n",
      "Train Epoch: 150 [19200/50000 (38%)]\tLoss: 0.904550\n",
      "Train Epoch: 150 [20480/50000 (41%)]\tLoss: 0.975799\n",
      "Train Epoch: 150 [21760/50000 (43%)]\tLoss: 0.752828\n",
      "Train Epoch: 150 [23040/50000 (46%)]\tLoss: 1.035368\n",
      "Train Epoch: 150 [24320/50000 (49%)]\tLoss: 0.967641\n",
      "Train Epoch: 150 [25600/50000 (51%)]\tLoss: 0.898491\n",
      "Train Epoch: 150 [26880/50000 (54%)]\tLoss: 1.074736\n",
      "Train Epoch: 150 [28160/50000 (56%)]\tLoss: 0.812897\n",
      "Train Epoch: 150 [29440/50000 (59%)]\tLoss: 0.963875\n",
      "Train Epoch: 150 [30720/50000 (61%)]\tLoss: 1.100261\n",
      "Train Epoch: 150 [32000/50000 (64%)]\tLoss: 1.071536\n",
      "Train Epoch: 150 [33280/50000 (66%)]\tLoss: 0.754420\n",
      "Train Epoch: 150 [34560/50000 (69%)]\tLoss: 0.792842\n",
      "Train Epoch: 150 [35840/50000 (72%)]\tLoss: 0.988153\n",
      "Train Epoch: 150 [37120/50000 (74%)]\tLoss: 0.969708\n",
      "Train Epoch: 150 [38400/50000 (77%)]\tLoss: 0.926317\n",
      "Train Epoch: 150 [39680/50000 (79%)]\tLoss: 1.054657\n",
      "Train Epoch: 150 [40960/50000 (82%)]\tLoss: 1.167269\n",
      "Train Epoch: 150 [42240/50000 (84%)]\tLoss: 0.898263\n",
      "Train Epoch: 150 [43520/50000 (87%)]\tLoss: 0.983401\n",
      "Train Epoch: 150 [44800/50000 (90%)]\tLoss: 0.945933\n",
      "Train Epoch: 150 [46080/50000 (92%)]\tLoss: 0.995989\n",
      "Train Epoch: 150 [47360/50000 (95%)]\tLoss: 1.037396\n",
      "Train Epoch: 150 [48640/50000 (97%)]\tLoss: 0.903288\n",
      "Train Epoch: 150 [31200/50000 (100%)]\tLoss: 1.016137\n",
      "\n",
      "Test set: Avg. loss: 0.000380, Accuracy: 8444/9250 (91.29%)\n",
      "\n",
      "Train Epoch: 151 [0/50000 (0%)]\tLoss: 0.048107\n",
      "Train Epoch: 151 [1280/50000 (3%)]\tLoss: 1.020850\n",
      "Train Epoch: 151 [2560/50000 (5%)]\tLoss: 1.034015\n",
      "Train Epoch: 151 [3840/50000 (8%)]\tLoss: 0.904351\n",
      "Train Epoch: 151 [5120/50000 (10%)]\tLoss: 1.063648\n",
      "Train Epoch: 151 [6400/50000 (13%)]\tLoss: 1.114181\n",
      "Train Epoch: 151 [7680/50000 (15%)]\tLoss: 0.916557\n",
      "Train Epoch: 151 [8960/50000 (18%)]\tLoss: 0.790615\n",
      "Train Epoch: 151 [10240/50000 (20%)]\tLoss: 0.854980\n",
      "Train Epoch: 151 [11520/50000 (23%)]\tLoss: 1.069472\n",
      "Train Epoch: 151 [12800/50000 (26%)]\tLoss: 0.764731\n",
      "Train Epoch: 151 [14080/50000 (28%)]\tLoss: 0.837647\n",
      "Train Epoch: 151 [15360/50000 (31%)]\tLoss: 1.073912\n",
      "Train Epoch: 151 [16640/50000 (33%)]\tLoss: 1.109192\n",
      "Train Epoch: 151 [17920/50000 (36%)]\tLoss: 1.056782\n",
      "Train Epoch: 151 [19200/50000 (38%)]\tLoss: 1.069270\n",
      "Train Epoch: 151 [20480/50000 (41%)]\tLoss: 0.893435\n",
      "Train Epoch: 151 [21760/50000 (43%)]\tLoss: 1.019288\n",
      "Train Epoch: 151 [23040/50000 (46%)]\tLoss: 0.971398\n",
      "Train Epoch: 151 [24320/50000 (49%)]\tLoss: 0.941137\n",
      "Train Epoch: 151 [25600/50000 (51%)]\tLoss: 1.007043\n",
      "Train Epoch: 151 [26880/50000 (54%)]\tLoss: 1.201459\n",
      "Train Epoch: 151 [28160/50000 (56%)]\tLoss: 0.896825\n",
      "Train Epoch: 151 [29440/50000 (59%)]\tLoss: 0.931843\n",
      "Train Epoch: 151 [30720/50000 (61%)]\tLoss: 1.182410\n",
      "Train Epoch: 151 [32000/50000 (64%)]\tLoss: 1.087466\n",
      "Train Epoch: 151 [33280/50000 (66%)]\tLoss: 0.980482\n",
      "Train Epoch: 151 [34560/50000 (69%)]\tLoss: 1.068403\n",
      "Train Epoch: 151 [35840/50000 (72%)]\tLoss: 0.932568\n",
      "Train Epoch: 151 [37120/50000 (74%)]\tLoss: 1.196274\n",
      "Train Epoch: 151 [38400/50000 (77%)]\tLoss: 0.998055\n",
      "Train Epoch: 151 [39680/50000 (79%)]\tLoss: 0.890553\n",
      "Train Epoch: 151 [40960/50000 (82%)]\tLoss: 1.097465\n",
      "Train Epoch: 151 [42240/50000 (84%)]\tLoss: 1.043809\n",
      "Train Epoch: 151 [43520/50000 (87%)]\tLoss: 1.128687\n",
      "Train Epoch: 151 [44800/50000 (90%)]\tLoss: 0.922421\n",
      "Train Epoch: 151 [46080/50000 (92%)]\tLoss: 1.075646\n",
      "Train Epoch: 151 [47360/50000 (95%)]\tLoss: 1.104825\n",
      "Train Epoch: 151 [48640/50000 (97%)]\tLoss: 1.031466\n",
      "Train Epoch: 151 [31200/50000 (100%)]\tLoss: 1.047570\n",
      "\n",
      "Test set: Avg. loss: 0.000348, Accuracy: 8473/9250 (91.60%)\n",
      "\n",
      "Train Epoch: 152 [0/50000 (0%)]\tLoss: 0.036413\n",
      "Train Epoch: 152 [1280/50000 (3%)]\tLoss: 0.984856\n",
      "Train Epoch: 152 [2560/50000 (5%)]\tLoss: 1.108265\n",
      "Train Epoch: 152 [3840/50000 (8%)]\tLoss: 0.871749\n",
      "Train Epoch: 152 [5120/50000 (10%)]\tLoss: 1.186228\n",
      "Train Epoch: 152 [6400/50000 (13%)]\tLoss: 0.936785\n",
      "Train Epoch: 152 [7680/50000 (15%)]\tLoss: 0.952312\n",
      "Train Epoch: 152 [8960/50000 (18%)]\tLoss: 1.120275\n",
      "Train Epoch: 152 [10240/50000 (20%)]\tLoss: 1.056316\n",
      "Train Epoch: 152 [11520/50000 (23%)]\tLoss: 0.793206\n",
      "Train Epoch: 152 [12800/50000 (26%)]\tLoss: 1.034066\n",
      "Train Epoch: 152 [14080/50000 (28%)]\tLoss: 0.918600\n",
      "Train Epoch: 152 [15360/50000 (31%)]\tLoss: 1.037745\n",
      "Train Epoch: 152 [16640/50000 (33%)]\tLoss: 0.797827\n",
      "Train Epoch: 152 [17920/50000 (36%)]\tLoss: 1.059382\n",
      "Train Epoch: 152 [19200/50000 (38%)]\tLoss: 1.147854\n",
      "Train Epoch: 152 [20480/50000 (41%)]\tLoss: 1.085290\n",
      "Train Epoch: 152 [21760/50000 (43%)]\tLoss: 0.965508\n",
      "Train Epoch: 152 [23040/50000 (46%)]\tLoss: 0.838508\n",
      "Train Epoch: 152 [24320/50000 (49%)]\tLoss: 0.907713\n",
      "Train Epoch: 152 [25600/50000 (51%)]\tLoss: 1.038899\n",
      "Train Epoch: 152 [26880/50000 (54%)]\tLoss: 0.823731\n",
      "Train Epoch: 152 [28160/50000 (56%)]\tLoss: 0.993823\n",
      "Train Epoch: 152 [29440/50000 (59%)]\tLoss: 0.732869\n",
      "Train Epoch: 152 [30720/50000 (61%)]\tLoss: 0.805500\n",
      "Train Epoch: 152 [32000/50000 (64%)]\tLoss: 1.013866\n",
      "Train Epoch: 152 [33280/50000 (66%)]\tLoss: 1.082721\n",
      "Train Epoch: 152 [34560/50000 (69%)]\tLoss: 0.918884\n",
      "Train Epoch: 152 [35840/50000 (72%)]\tLoss: 1.013888\n",
      "Train Epoch: 152 [37120/50000 (74%)]\tLoss: 0.899893\n",
      "Train Epoch: 152 [38400/50000 (77%)]\tLoss: 1.175271\n",
      "Train Epoch: 152 [39680/50000 (79%)]\tLoss: 1.157153\n",
      "Train Epoch: 152 [40960/50000 (82%)]\tLoss: 1.012537\n",
      "Train Epoch: 152 [42240/50000 (84%)]\tLoss: 1.018338\n",
      "Train Epoch: 152 [43520/50000 (87%)]\tLoss: 0.983406\n",
      "Train Epoch: 152 [44800/50000 (90%)]\tLoss: 1.065930\n",
      "Train Epoch: 152 [46080/50000 (92%)]\tLoss: 1.131255\n",
      "Train Epoch: 152 [47360/50000 (95%)]\tLoss: 0.938840\n",
      "Train Epoch: 152 [48640/50000 (97%)]\tLoss: 1.065398\n",
      "Train Epoch: 152 [31200/50000 (100%)]\tLoss: 1.190469\n",
      "\n",
      "Test set: Avg. loss: 0.000363, Accuracy: 8493/9250 (91.82%)\n",
      "\n",
      "Train Epoch: 153 [0/50000 (0%)]\tLoss: 0.126351\n",
      "Train Epoch: 153 [1280/50000 (3%)]\tLoss: 1.100742\n",
      "Train Epoch: 153 [2560/50000 (5%)]\tLoss: 0.733396\n",
      "Train Epoch: 153 [3840/50000 (8%)]\tLoss: 0.934167\n",
      "Train Epoch: 153 [5120/50000 (10%)]\tLoss: 1.039899\n",
      "Train Epoch: 153 [6400/50000 (13%)]\tLoss: 0.970394\n",
      "Train Epoch: 153 [7680/50000 (15%)]\tLoss: 0.962090\n",
      "Train Epoch: 153 [8960/50000 (18%)]\tLoss: 1.075543\n",
      "Train Epoch: 153 [10240/50000 (20%)]\tLoss: 0.882045\n",
      "Train Epoch: 153 [11520/50000 (23%)]\tLoss: 0.950046\n",
      "Train Epoch: 153 [12800/50000 (26%)]\tLoss: 0.832806\n",
      "Train Epoch: 153 [14080/50000 (28%)]\tLoss: 1.188417\n",
      "Train Epoch: 153 [15360/50000 (31%)]\tLoss: 0.999081\n",
      "Train Epoch: 153 [16640/50000 (33%)]\tLoss: 1.129627\n",
      "Train Epoch: 153 [17920/50000 (36%)]\tLoss: 0.987160\n",
      "Train Epoch: 153 [19200/50000 (38%)]\tLoss: 0.949661\n",
      "Train Epoch: 153 [20480/50000 (41%)]\tLoss: 0.919918\n",
      "Train Epoch: 153 [21760/50000 (43%)]\tLoss: 1.072523\n",
      "Train Epoch: 153 [23040/50000 (46%)]\tLoss: 0.909797\n",
      "Train Epoch: 153 [24320/50000 (49%)]\tLoss: 1.105928\n",
      "Train Epoch: 153 [25600/50000 (51%)]\tLoss: 0.782478\n",
      "Train Epoch: 153 [26880/50000 (54%)]\tLoss: 1.034990\n",
      "Train Epoch: 153 [28160/50000 (56%)]\tLoss: 1.068032\n",
      "Train Epoch: 153 [29440/50000 (59%)]\tLoss: 1.080583\n",
      "Train Epoch: 153 [30720/50000 (61%)]\tLoss: 0.979210\n",
      "Train Epoch: 153 [32000/50000 (64%)]\tLoss: 1.184733\n",
      "Train Epoch: 153 [33280/50000 (66%)]\tLoss: 1.175395\n",
      "Train Epoch: 153 [34560/50000 (69%)]\tLoss: 1.089844\n",
      "Train Epoch: 153 [35840/50000 (72%)]\tLoss: 1.135836\n",
      "Train Epoch: 153 [37120/50000 (74%)]\tLoss: 1.222439\n",
      "Train Epoch: 153 [38400/50000 (77%)]\tLoss: 0.923581\n",
      "Train Epoch: 153 [39680/50000 (79%)]\tLoss: 1.101896\n",
      "Train Epoch: 153 [40960/50000 (82%)]\tLoss: 1.047643\n",
      "Train Epoch: 153 [42240/50000 (84%)]\tLoss: 1.094336\n",
      "Train Epoch: 153 [43520/50000 (87%)]\tLoss: 1.011778\n",
      "Train Epoch: 153 [44800/50000 (90%)]\tLoss: 0.966437\n",
      "Train Epoch: 153 [46080/50000 (92%)]\tLoss: 0.999517\n",
      "Train Epoch: 153 [47360/50000 (95%)]\tLoss: 0.972195\n",
      "Train Epoch: 153 [48640/50000 (97%)]\tLoss: 1.138871\n",
      "Train Epoch: 153 [31200/50000 (100%)]\tLoss: 0.830968\n",
      "\n",
      "Test set: Avg. loss: 0.000359, Accuracy: 8451/9250 (91.36%)\n",
      "\n",
      "Train Epoch: 154 [0/50000 (0%)]\tLoss: 0.066989\n",
      "Train Epoch: 154 [1280/50000 (3%)]\tLoss: 1.015705\n",
      "Train Epoch: 154 [2560/50000 (5%)]\tLoss: 1.026470\n",
      "Train Epoch: 154 [3840/50000 (8%)]\tLoss: 1.036281\n",
      "Train Epoch: 154 [5120/50000 (10%)]\tLoss: 1.172705\n",
      "Train Epoch: 154 [6400/50000 (13%)]\tLoss: 0.918340\n",
      "Train Epoch: 154 [7680/50000 (15%)]\tLoss: 1.010379\n",
      "Train Epoch: 154 [8960/50000 (18%)]\tLoss: 0.968796\n",
      "Train Epoch: 154 [10240/50000 (20%)]\tLoss: 1.211672\n",
      "Train Epoch: 154 [11520/50000 (23%)]\tLoss: 1.082208\n",
      "Train Epoch: 154 [12800/50000 (26%)]\tLoss: 1.065686\n",
      "Train Epoch: 154 [14080/50000 (28%)]\tLoss: 0.828783\n",
      "Train Epoch: 154 [15360/50000 (31%)]\tLoss: 0.866530\n",
      "Train Epoch: 154 [16640/50000 (33%)]\tLoss: 0.963623\n",
      "Train Epoch: 154 [17920/50000 (36%)]\tLoss: 0.786768\n",
      "Train Epoch: 154 [19200/50000 (38%)]\tLoss: 0.855071\n",
      "Train Epoch: 154 [20480/50000 (41%)]\tLoss: 1.040238\n",
      "Train Epoch: 154 [21760/50000 (43%)]\tLoss: 1.100127\n",
      "Train Epoch: 154 [23040/50000 (46%)]\tLoss: 1.116426\n",
      "Train Epoch: 154 [24320/50000 (49%)]\tLoss: 0.835018\n",
      "Train Epoch: 154 [25600/50000 (51%)]\tLoss: 0.948875\n",
      "Train Epoch: 154 [26880/50000 (54%)]\tLoss: 1.014139\n",
      "Train Epoch: 154 [28160/50000 (56%)]\tLoss: 0.913301\n",
      "Train Epoch: 154 [29440/50000 (59%)]\tLoss: 0.711295\n",
      "Train Epoch: 154 [30720/50000 (61%)]\tLoss: 0.980752\n",
      "Train Epoch: 154 [32000/50000 (64%)]\tLoss: 0.954660\n",
      "Train Epoch: 154 [33280/50000 (66%)]\tLoss: 0.878815\n",
      "Train Epoch: 154 [34560/50000 (69%)]\tLoss: 0.899940\n",
      "Train Epoch: 154 [35840/50000 (72%)]\tLoss: 0.965400\n",
      "Train Epoch: 154 [37120/50000 (74%)]\tLoss: 1.178019\n",
      "Train Epoch: 154 [38400/50000 (77%)]\tLoss: 1.033024\n",
      "Train Epoch: 154 [39680/50000 (79%)]\tLoss: 0.823241\n",
      "Train Epoch: 154 [40960/50000 (82%)]\tLoss: 1.062738\n",
      "Train Epoch: 154 [42240/50000 (84%)]\tLoss: 1.089418\n",
      "Train Epoch: 154 [43520/50000 (87%)]\tLoss: 0.981409\n",
      "Train Epoch: 154 [44800/50000 (90%)]\tLoss: 1.099341\n",
      "Train Epoch: 154 [46080/50000 (92%)]\tLoss: 1.029164\n",
      "Train Epoch: 154 [47360/50000 (95%)]\tLoss: 1.029848\n",
      "Train Epoch: 154 [48640/50000 (97%)]\tLoss: 0.938003\n",
      "Train Epoch: 154 [31200/50000 (100%)]\tLoss: 1.078322\n",
      "\n",
      "Test set: Avg. loss: 0.000352, Accuracy: 8488/9250 (91.76%)\n",
      "\n",
      "Train Epoch: 155 [0/50000 (0%)]\tLoss: 0.124929\n",
      "Train Epoch: 155 [1280/50000 (3%)]\tLoss: 0.935405\n",
      "Train Epoch: 155 [2560/50000 (5%)]\tLoss: 0.911773\n",
      "Train Epoch: 155 [3840/50000 (8%)]\tLoss: 1.217716\n",
      "Train Epoch: 155 [5120/50000 (10%)]\tLoss: 1.051416\n",
      "Train Epoch: 155 [6400/50000 (13%)]\tLoss: 1.031679\n",
      "Train Epoch: 155 [7680/50000 (15%)]\tLoss: 0.919803\n",
      "Train Epoch: 155 [8960/50000 (18%)]\tLoss: 0.877698\n",
      "Train Epoch: 155 [10240/50000 (20%)]\tLoss: 0.994493\n",
      "Train Epoch: 155 [11520/50000 (23%)]\tLoss: 1.037738\n",
      "Train Epoch: 155 [12800/50000 (26%)]\tLoss: 1.015428\n",
      "Train Epoch: 155 [14080/50000 (28%)]\tLoss: 1.030658\n",
      "Train Epoch: 155 [15360/50000 (31%)]\tLoss: 1.104900\n",
      "Train Epoch: 155 [16640/50000 (33%)]\tLoss: 1.223053\n",
      "Train Epoch: 155 [17920/50000 (36%)]\tLoss: 0.992692\n",
      "Train Epoch: 155 [19200/50000 (38%)]\tLoss: 1.148377\n",
      "Train Epoch: 155 [20480/50000 (41%)]\tLoss: 0.987373\n",
      "Train Epoch: 155 [21760/50000 (43%)]\tLoss: 0.945945\n",
      "Train Epoch: 155 [23040/50000 (46%)]\tLoss: 0.788248\n",
      "Train Epoch: 155 [24320/50000 (49%)]\tLoss: 0.905059\n",
      "Train Epoch: 155 [25600/50000 (51%)]\tLoss: 0.589943\n",
      "Train Epoch: 155 [26880/50000 (54%)]\tLoss: 0.961114\n",
      "Train Epoch: 155 [28160/50000 (56%)]\tLoss: 0.962979\n",
      "Train Epoch: 155 [29440/50000 (59%)]\tLoss: 1.134813\n",
      "Train Epoch: 155 [30720/50000 (61%)]\tLoss: 0.870210\n",
      "Train Epoch: 155 [32000/50000 (64%)]\tLoss: 1.075372\n",
      "Train Epoch: 155 [33280/50000 (66%)]\tLoss: 0.917362\n",
      "Train Epoch: 155 [34560/50000 (69%)]\tLoss: 0.914836\n",
      "Train Epoch: 155 [35840/50000 (72%)]\tLoss: 0.900548\n",
      "Train Epoch: 155 [37120/50000 (74%)]\tLoss: 1.060422\n",
      "Train Epoch: 155 [38400/50000 (77%)]\tLoss: 0.866025\n",
      "Train Epoch: 155 [39680/50000 (79%)]\tLoss: 1.158314\n",
      "Train Epoch: 155 [40960/50000 (82%)]\tLoss: 0.901623\n",
      "Train Epoch: 155 [42240/50000 (84%)]\tLoss: 1.101885\n",
      "Train Epoch: 155 [43520/50000 (87%)]\tLoss: 0.983084\n",
      "Train Epoch: 155 [44800/50000 (90%)]\tLoss: 0.986390\n",
      "Train Epoch: 155 [46080/50000 (92%)]\tLoss: 1.056625\n",
      "Train Epoch: 155 [47360/50000 (95%)]\tLoss: 0.940040\n",
      "Train Epoch: 155 [48640/50000 (97%)]\tLoss: 1.137001\n",
      "Train Epoch: 155 [31200/50000 (100%)]\tLoss: 1.011935\n",
      "\n",
      "Test set: Avg. loss: 0.000373, Accuracy: 8478/9250 (91.65%)\n",
      "\n",
      "Train Epoch: 156 [0/50000 (0%)]\tLoss: 0.063915\n",
      "Train Epoch: 156 [1280/50000 (3%)]\tLoss: 0.867654\n",
      "Train Epoch: 156 [2560/50000 (5%)]\tLoss: 1.060200\n",
      "Train Epoch: 156 [3840/50000 (8%)]\tLoss: 1.100192\n",
      "Train Epoch: 156 [5120/50000 (10%)]\tLoss: 0.952820\n",
      "Train Epoch: 156 [6400/50000 (13%)]\tLoss: 1.093254\n",
      "Train Epoch: 156 [7680/50000 (15%)]\tLoss: 1.017626\n",
      "Train Epoch: 156 [8960/50000 (18%)]\tLoss: 0.894188\n",
      "Train Epoch: 156 [10240/50000 (20%)]\tLoss: 1.003037\n",
      "Train Epoch: 156 [11520/50000 (23%)]\tLoss: 0.759739\n",
      "Train Epoch: 156 [12800/50000 (26%)]\tLoss: 0.964069\n",
      "Train Epoch: 156 [14080/50000 (28%)]\tLoss: 0.980754\n",
      "Train Epoch: 156 [15360/50000 (31%)]\tLoss: 0.953859\n",
      "Train Epoch: 156 [16640/50000 (33%)]\tLoss: 1.167496\n",
      "Train Epoch: 156 [17920/50000 (36%)]\tLoss: 1.023370\n",
      "Train Epoch: 156 [19200/50000 (38%)]\tLoss: 0.810319\n",
      "Train Epoch: 156 [20480/50000 (41%)]\tLoss: 1.134964\n",
      "Train Epoch: 156 [21760/50000 (43%)]\tLoss: 0.992025\n",
      "Train Epoch: 156 [23040/50000 (46%)]\tLoss: 1.087197\n",
      "Train Epoch: 156 [24320/50000 (49%)]\tLoss: 0.922456\n",
      "Train Epoch: 156 [25600/50000 (51%)]\tLoss: 1.060087\n",
      "Train Epoch: 156 [26880/50000 (54%)]\tLoss: 1.048486\n",
      "Train Epoch: 156 [28160/50000 (56%)]\tLoss: 0.928246\n",
      "Train Epoch: 156 [29440/50000 (59%)]\tLoss: 0.903814\n",
      "Train Epoch: 156 [30720/50000 (61%)]\tLoss: 0.775545\n",
      "Train Epoch: 156 [32000/50000 (64%)]\tLoss: 1.206289\n",
      "Train Epoch: 156 [33280/50000 (66%)]\tLoss: 0.788659\n",
      "Train Epoch: 156 [34560/50000 (69%)]\tLoss: 1.103492\n",
      "Train Epoch: 156 [35840/50000 (72%)]\tLoss: 1.098343\n",
      "Train Epoch: 156 [37120/50000 (74%)]\tLoss: 0.974648\n",
      "Train Epoch: 156 [38400/50000 (77%)]\tLoss: 1.263103\n",
      "Train Epoch: 156 [39680/50000 (79%)]\tLoss: 1.063456\n",
      "Train Epoch: 156 [40960/50000 (82%)]\tLoss: 1.026263\n",
      "Train Epoch: 156 [42240/50000 (84%)]\tLoss: 1.190072\n",
      "Train Epoch: 156 [43520/50000 (87%)]\tLoss: 1.040139\n",
      "Train Epoch: 156 [44800/50000 (90%)]\tLoss: 0.974844\n",
      "Train Epoch: 156 [46080/50000 (92%)]\tLoss: 0.963373\n",
      "Train Epoch: 156 [47360/50000 (95%)]\tLoss: 1.055422\n",
      "Train Epoch: 156 [48640/50000 (97%)]\tLoss: 0.955086\n",
      "Train Epoch: 156 [31200/50000 (100%)]\tLoss: 1.172604\n",
      "\n",
      "Test set: Avg. loss: 0.000375, Accuracy: 8477/9250 (91.64%)\n",
      "\n",
      "Train Epoch: 157 [0/50000 (0%)]\tLoss: 0.034155\n",
      "Train Epoch: 157 [1280/50000 (3%)]\tLoss: 0.944848\n",
      "Train Epoch: 157 [2560/50000 (5%)]\tLoss: 0.938611\n",
      "Train Epoch: 157 [3840/50000 (8%)]\tLoss: 0.977554\n",
      "Train Epoch: 157 [5120/50000 (10%)]\tLoss: 0.863929\n",
      "Train Epoch: 157 [6400/50000 (13%)]\tLoss: 0.959306\n",
      "Train Epoch: 157 [7680/50000 (15%)]\tLoss: 0.756714\n",
      "Train Epoch: 157 [8960/50000 (18%)]\tLoss: 1.098537\n",
      "Train Epoch: 157 [10240/50000 (20%)]\tLoss: 1.219208\n",
      "Train Epoch: 157 [11520/50000 (23%)]\tLoss: 1.000283\n",
      "Train Epoch: 157 [12800/50000 (26%)]\tLoss: 1.079857\n",
      "Train Epoch: 157 [14080/50000 (28%)]\tLoss: 0.964509\n",
      "Train Epoch: 157 [15360/50000 (31%)]\tLoss: 0.931002\n",
      "Train Epoch: 157 [16640/50000 (33%)]\tLoss: 0.998113\n",
      "Train Epoch: 157 [17920/50000 (36%)]\tLoss: 1.229410\n",
      "Train Epoch: 157 [19200/50000 (38%)]\tLoss: 1.103352\n",
      "Train Epoch: 157 [20480/50000 (41%)]\tLoss: 1.108682\n",
      "Train Epoch: 157 [21760/50000 (43%)]\tLoss: 1.150782\n",
      "Train Epoch: 157 [23040/50000 (46%)]\tLoss: 0.969013\n",
      "Train Epoch: 157 [24320/50000 (49%)]\tLoss: 0.781211\n",
      "Train Epoch: 157 [25600/50000 (51%)]\tLoss: 0.702303\n",
      "Train Epoch: 157 [26880/50000 (54%)]\tLoss: 0.990652\n",
      "Train Epoch: 157 [28160/50000 (56%)]\tLoss: 1.093887\n",
      "Train Epoch: 157 [29440/50000 (59%)]\tLoss: 0.832952\n",
      "Train Epoch: 157 [30720/50000 (61%)]\tLoss: 0.972826\n",
      "Train Epoch: 157 [32000/50000 (64%)]\tLoss: 0.809923\n",
      "Train Epoch: 157 [33280/50000 (66%)]\tLoss: 1.047685\n",
      "Train Epoch: 157 [34560/50000 (69%)]\tLoss: 0.847638\n",
      "Train Epoch: 157 [35840/50000 (72%)]\tLoss: 0.874638\n",
      "Train Epoch: 157 [37120/50000 (74%)]\tLoss: 0.766927\n",
      "Train Epoch: 157 [38400/50000 (77%)]\tLoss: 1.012986\n",
      "Train Epoch: 157 [39680/50000 (79%)]\tLoss: 0.831838\n",
      "Train Epoch: 157 [40960/50000 (82%)]\tLoss: 0.898094\n",
      "Train Epoch: 157 [42240/50000 (84%)]\tLoss: 1.066616\n",
      "Train Epoch: 157 [43520/50000 (87%)]\tLoss: 1.076697\n",
      "Train Epoch: 157 [44800/50000 (90%)]\tLoss: 0.851588\n",
      "Train Epoch: 157 [46080/50000 (92%)]\tLoss: 1.071468\n",
      "Train Epoch: 157 [47360/50000 (95%)]\tLoss: 1.094843\n",
      "Train Epoch: 157 [48640/50000 (97%)]\tLoss: 0.918749\n",
      "Train Epoch: 157 [31200/50000 (100%)]\tLoss: 0.923434\n",
      "\n",
      "Test set: Avg. loss: 0.000331, Accuracy: 8485/9250 (91.73%)\n",
      "\n",
      "Train Epoch: 158 [0/50000 (0%)]\tLoss: 0.139132\n",
      "Train Epoch: 158 [1280/50000 (3%)]\tLoss: 0.915346\n",
      "Train Epoch: 158 [2560/50000 (5%)]\tLoss: 1.100446\n",
      "Train Epoch: 158 [3840/50000 (8%)]\tLoss: 1.159711\n",
      "Train Epoch: 158 [5120/50000 (10%)]\tLoss: 0.867255\n",
      "Train Epoch: 158 [6400/50000 (13%)]\tLoss: 0.982773\n",
      "Train Epoch: 158 [7680/50000 (15%)]\tLoss: 0.980045\n",
      "Train Epoch: 158 [8960/50000 (18%)]\tLoss: 1.076353\n",
      "Train Epoch: 158 [10240/50000 (20%)]\tLoss: 1.011995\n",
      "Train Epoch: 158 [11520/50000 (23%)]\tLoss: 1.053127\n",
      "Train Epoch: 158 [12800/50000 (26%)]\tLoss: 1.053019\n",
      "Train Epoch: 158 [14080/50000 (28%)]\tLoss: 0.996420\n",
      "Train Epoch: 158 [15360/50000 (31%)]\tLoss: 1.155334\n",
      "Train Epoch: 158 [16640/50000 (33%)]\tLoss: 1.117179\n",
      "Train Epoch: 158 [17920/50000 (36%)]\tLoss: 1.220485\n",
      "Train Epoch: 158 [19200/50000 (38%)]\tLoss: 1.033026\n",
      "Train Epoch: 158 [20480/50000 (41%)]\tLoss: 0.954268\n",
      "Train Epoch: 158 [21760/50000 (43%)]\tLoss: 1.088237\n",
      "Train Epoch: 158 [23040/50000 (46%)]\tLoss: 0.979533\n",
      "Train Epoch: 158 [24320/50000 (49%)]\tLoss: 1.034786\n",
      "Train Epoch: 158 [25600/50000 (51%)]\tLoss: 1.022498\n",
      "Train Epoch: 158 [26880/50000 (54%)]\tLoss: 0.853175\n",
      "Train Epoch: 158 [28160/50000 (56%)]\tLoss: 0.994234\n",
      "Train Epoch: 158 [29440/50000 (59%)]\tLoss: 1.153641\n",
      "Train Epoch: 158 [30720/50000 (61%)]\tLoss: 1.184072\n",
      "Train Epoch: 158 [32000/50000 (64%)]\tLoss: 1.033649\n",
      "Train Epoch: 158 [33280/50000 (66%)]\tLoss: 1.076374\n",
      "Train Epoch: 158 [34560/50000 (69%)]\tLoss: 0.968029\n",
      "Train Epoch: 158 [35840/50000 (72%)]\tLoss: 0.831576\n",
      "Train Epoch: 158 [37120/50000 (74%)]\tLoss: 0.849811\n",
      "Train Epoch: 158 [38400/50000 (77%)]\tLoss: 1.210917\n",
      "Train Epoch: 158 [39680/50000 (79%)]\tLoss: 1.037950\n",
      "Train Epoch: 158 [40960/50000 (82%)]\tLoss: 1.149741\n",
      "Train Epoch: 158 [42240/50000 (84%)]\tLoss: 1.066651\n",
      "Train Epoch: 158 [43520/50000 (87%)]\tLoss: 0.693873\n",
      "Train Epoch: 158 [44800/50000 (90%)]\tLoss: 0.958106\n",
      "Train Epoch: 158 [46080/50000 (92%)]\tLoss: 1.145737\n",
      "Train Epoch: 158 [47360/50000 (95%)]\tLoss: 1.071783\n",
      "Train Epoch: 158 [48640/50000 (97%)]\tLoss: 1.174980\n",
      "Train Epoch: 158 [31200/50000 (100%)]\tLoss: 0.898781\n",
      "\n",
      "Test set: Avg. loss: 0.000343, Accuracy: 8504/9250 (91.94%)\n",
      "\n",
      "Train Epoch: 159 [0/50000 (0%)]\tLoss: 0.136858\n",
      "Train Epoch: 159 [1280/50000 (3%)]\tLoss: 0.868606\n",
      "Train Epoch: 159 [2560/50000 (5%)]\tLoss: 0.968212\n",
      "Train Epoch: 159 [3840/50000 (8%)]\tLoss: 0.885896\n",
      "Train Epoch: 159 [5120/50000 (10%)]\tLoss: 1.032883\n",
      "Train Epoch: 159 [6400/50000 (13%)]\tLoss: 0.756640\n",
      "Train Epoch: 159 [7680/50000 (15%)]\tLoss: 1.012429\n",
      "Train Epoch: 159 [8960/50000 (18%)]\tLoss: 0.976954\n",
      "Train Epoch: 159 [10240/50000 (20%)]\tLoss: 1.009893\n",
      "Train Epoch: 159 [11520/50000 (23%)]\tLoss: 1.122460\n",
      "Train Epoch: 159 [12800/50000 (26%)]\tLoss: 0.967237\n",
      "Train Epoch: 159 [14080/50000 (28%)]\tLoss: 0.960187\n",
      "Train Epoch: 159 [15360/50000 (31%)]\tLoss: 0.893177\n",
      "Train Epoch: 159 [16640/50000 (33%)]\tLoss: 0.833939\n",
      "Train Epoch: 159 [17920/50000 (36%)]\tLoss: 0.814862\n",
      "Train Epoch: 159 [19200/50000 (38%)]\tLoss: 1.209050\n",
      "Train Epoch: 159 [20480/50000 (41%)]\tLoss: 1.010301\n",
      "Train Epoch: 159 [21760/50000 (43%)]\tLoss: 0.923568\n",
      "Train Epoch: 159 [23040/50000 (46%)]\tLoss: 1.071533\n",
      "Train Epoch: 159 [24320/50000 (49%)]\tLoss: 1.005007\n",
      "Train Epoch: 159 [25600/50000 (51%)]\tLoss: 0.968704\n",
      "Train Epoch: 159 [26880/50000 (54%)]\tLoss: 0.912741\n",
      "Train Epoch: 159 [28160/50000 (56%)]\tLoss: 1.079807\n",
      "Train Epoch: 159 [29440/50000 (59%)]\tLoss: 1.115457\n",
      "Train Epoch: 159 [30720/50000 (61%)]\tLoss: 1.031257\n",
      "Train Epoch: 159 [32000/50000 (64%)]\tLoss: 1.084190\n",
      "Train Epoch: 159 [33280/50000 (66%)]\tLoss: 0.992869\n",
      "Train Epoch: 159 [34560/50000 (69%)]\tLoss: 0.948194\n",
      "Train Epoch: 159 [35840/50000 (72%)]\tLoss: 1.007051\n",
      "Train Epoch: 159 [37120/50000 (74%)]\tLoss: 0.879531\n",
      "Train Epoch: 159 [38400/50000 (77%)]\tLoss: 0.907391\n",
      "Train Epoch: 159 [39680/50000 (79%)]\tLoss: 1.075483\n",
      "Train Epoch: 159 [40960/50000 (82%)]\tLoss: 1.124017\n",
      "Train Epoch: 159 [42240/50000 (84%)]\tLoss: 0.953879\n",
      "Train Epoch: 159 [43520/50000 (87%)]\tLoss: 1.090106\n",
      "Train Epoch: 159 [44800/50000 (90%)]\tLoss: 0.889347\n",
      "Train Epoch: 159 [46080/50000 (92%)]\tLoss: 1.099670\n",
      "Train Epoch: 159 [47360/50000 (95%)]\tLoss: 0.922605\n",
      "Train Epoch: 159 [48640/50000 (97%)]\tLoss: 1.022059\n",
      "Train Epoch: 159 [31200/50000 (100%)]\tLoss: 1.099317\n",
      "\n",
      "Test set: Avg. loss: 0.000366, Accuracy: 8483/9250 (91.71%)\n",
      "\n",
      "Train Epoch: 160 [0/50000 (0%)]\tLoss: 0.037367\n",
      "Train Epoch: 160 [1280/50000 (3%)]\tLoss: 1.193876\n",
      "Train Epoch: 160 [2560/50000 (5%)]\tLoss: 0.939823\n",
      "Train Epoch: 160 [3840/50000 (8%)]\tLoss: 1.270761\n",
      "Train Epoch: 160 [5120/50000 (10%)]\tLoss: 0.924841\n",
      "Train Epoch: 160 [6400/50000 (13%)]\tLoss: 1.139530\n",
      "Train Epoch: 160 [7680/50000 (15%)]\tLoss: 0.910312\n",
      "Train Epoch: 160 [8960/50000 (18%)]\tLoss: 0.837199\n",
      "Train Epoch: 160 [10240/50000 (20%)]\tLoss: 1.094657\n",
      "Train Epoch: 160 [11520/50000 (23%)]\tLoss: 0.894408\n",
      "Train Epoch: 160 [12800/50000 (26%)]\tLoss: 1.007741\n",
      "Train Epoch: 160 [14080/50000 (28%)]\tLoss: 0.959369\n",
      "Train Epoch: 160 [15360/50000 (31%)]\tLoss: 1.009823\n",
      "Train Epoch: 160 [16640/50000 (33%)]\tLoss: 1.079666\n",
      "Train Epoch: 160 [17920/50000 (36%)]\tLoss: 0.833193\n",
      "Train Epoch: 160 [19200/50000 (38%)]\tLoss: 1.113042\n",
      "Train Epoch: 160 [20480/50000 (41%)]\tLoss: 0.979916\n",
      "Train Epoch: 160 [21760/50000 (43%)]\tLoss: 1.092335\n",
      "Train Epoch: 160 [23040/50000 (46%)]\tLoss: 1.073954\n",
      "Train Epoch: 160 [24320/50000 (49%)]\tLoss: 0.937076\n",
      "Train Epoch: 160 [25600/50000 (51%)]\tLoss: 1.229902\n",
      "Train Epoch: 160 [26880/50000 (54%)]\tLoss: 1.029337\n",
      "Train Epoch: 160 [28160/50000 (56%)]\tLoss: 0.974718\n",
      "Train Epoch: 160 [29440/50000 (59%)]\tLoss: 0.994772\n",
      "Train Epoch: 160 [30720/50000 (61%)]\tLoss: 1.123139\n",
      "Train Epoch: 160 [32000/50000 (64%)]\tLoss: 0.923768\n",
      "Train Epoch: 160 [33280/50000 (66%)]\tLoss: 0.831778\n",
      "Train Epoch: 160 [34560/50000 (69%)]\tLoss: 1.127125\n",
      "Train Epoch: 160 [35840/50000 (72%)]\tLoss: 1.021962\n",
      "Train Epoch: 160 [37120/50000 (74%)]\tLoss: 0.761920\n",
      "Train Epoch: 160 [38400/50000 (77%)]\tLoss: 1.181544\n",
      "Train Epoch: 160 [39680/50000 (79%)]\tLoss: 1.106631\n",
      "Train Epoch: 160 [40960/50000 (82%)]\tLoss: 1.021966\n",
      "Train Epoch: 160 [42240/50000 (84%)]\tLoss: 1.191188\n",
      "Train Epoch: 160 [43520/50000 (87%)]\tLoss: 1.051933\n",
      "Train Epoch: 160 [44800/50000 (90%)]\tLoss: 1.033222\n",
      "Train Epoch: 160 [46080/50000 (92%)]\tLoss: 1.065570\n",
      "Train Epoch: 160 [47360/50000 (95%)]\tLoss: 0.888360\n",
      "Train Epoch: 160 [48640/50000 (97%)]\tLoss: 1.019413\n",
      "Train Epoch: 160 [31200/50000 (100%)]\tLoss: 0.993362\n",
      "\n",
      "Test set: Avg. loss: 0.000368, Accuracy: 8452/9250 (91.37%)\n",
      "\n",
      "Train Epoch: 161 [0/50000 (0%)]\tLoss: 0.092261\n",
      "Train Epoch: 161 [1280/50000 (3%)]\tLoss: 1.083094\n",
      "Train Epoch: 161 [2560/50000 (5%)]\tLoss: 0.998026\n",
      "Train Epoch: 161 [3840/50000 (8%)]\tLoss: 0.883810\n",
      "Train Epoch: 161 [5120/50000 (10%)]\tLoss: 1.044267\n",
      "Train Epoch: 161 [6400/50000 (13%)]\tLoss: 1.003304\n",
      "Train Epoch: 161 [7680/50000 (15%)]\tLoss: 0.902296\n",
      "Train Epoch: 161 [8960/50000 (18%)]\tLoss: 1.022690\n",
      "Train Epoch: 161 [10240/50000 (20%)]\tLoss: 1.066430\n",
      "Train Epoch: 161 [11520/50000 (23%)]\tLoss: 1.021775\n",
      "Train Epoch: 161 [12800/50000 (26%)]\tLoss: 1.141920\n",
      "Train Epoch: 161 [14080/50000 (28%)]\tLoss: 1.046885\n",
      "Train Epoch: 161 [15360/50000 (31%)]\tLoss: 0.960484\n",
      "Train Epoch: 161 [16640/50000 (33%)]\tLoss: 1.070026\n",
      "Train Epoch: 161 [17920/50000 (36%)]\tLoss: 0.992851\n",
      "Train Epoch: 161 [19200/50000 (38%)]\tLoss: 0.878486\n",
      "Train Epoch: 161 [20480/50000 (41%)]\tLoss: 1.007821\n",
      "Train Epoch: 161 [21760/50000 (43%)]\tLoss: 0.862291\n",
      "Train Epoch: 161 [23040/50000 (46%)]\tLoss: 1.141966\n",
      "Train Epoch: 161 [24320/50000 (49%)]\tLoss: 0.953739\n",
      "Train Epoch: 161 [25600/50000 (51%)]\tLoss: 0.985584\n",
      "Train Epoch: 161 [26880/50000 (54%)]\tLoss: 1.151381\n",
      "Train Epoch: 161 [28160/50000 (56%)]\tLoss: 1.055310\n",
      "Train Epoch: 161 [29440/50000 (59%)]\tLoss: 1.029141\n",
      "Train Epoch: 161 [30720/50000 (61%)]\tLoss: 1.085672\n",
      "Train Epoch: 161 [32000/50000 (64%)]\tLoss: 1.099775\n",
      "Train Epoch: 161 [33280/50000 (66%)]\tLoss: 0.816717\n",
      "Train Epoch: 161 [34560/50000 (69%)]\tLoss: 1.043395\n",
      "Train Epoch: 161 [35840/50000 (72%)]\tLoss: 0.996097\n",
      "Train Epoch: 161 [37120/50000 (74%)]\tLoss: 1.122115\n",
      "Train Epoch: 161 [38400/50000 (77%)]\tLoss: 1.206937\n",
      "Train Epoch: 161 [39680/50000 (79%)]\tLoss: 0.880428\n",
      "Train Epoch: 161 [40960/50000 (82%)]\tLoss: 0.902118\n",
      "Train Epoch: 161 [42240/50000 (84%)]\tLoss: 1.135740\n",
      "Train Epoch: 161 [43520/50000 (87%)]\tLoss: 0.854403\n",
      "Train Epoch: 161 [44800/50000 (90%)]\tLoss: 0.931087\n",
      "Train Epoch: 161 [46080/50000 (92%)]\tLoss: 0.930871\n",
      "Train Epoch: 161 [47360/50000 (95%)]\tLoss: 0.970765\n",
      "Train Epoch: 161 [48640/50000 (97%)]\tLoss: 0.861165\n",
      "Train Epoch: 161 [31200/50000 (100%)]\tLoss: 1.061582\n",
      "\n",
      "Test set: Avg. loss: 0.000352, Accuracy: 8477/9250 (91.64%)\n",
      "\n",
      "Train Epoch: 162 [0/50000 (0%)]\tLoss: 0.057275\n",
      "Train Epoch: 162 [1280/50000 (3%)]\tLoss: 0.908485\n",
      "Train Epoch: 162 [2560/50000 (5%)]\tLoss: 0.992693\n",
      "Train Epoch: 162 [3840/50000 (8%)]\tLoss: 1.112786\n",
      "Train Epoch: 162 [5120/50000 (10%)]\tLoss: 0.923854\n",
      "Train Epoch: 162 [6400/50000 (13%)]\tLoss: 0.930585\n",
      "Train Epoch: 162 [7680/50000 (15%)]\tLoss: 1.041238\n",
      "Train Epoch: 162 [8960/50000 (18%)]\tLoss: 1.012077\n",
      "Train Epoch: 162 [10240/50000 (20%)]\tLoss: 1.000214\n",
      "Train Epoch: 162 [11520/50000 (23%)]\tLoss: 0.731120\n",
      "Train Epoch: 162 [12800/50000 (26%)]\tLoss: 1.039394\n",
      "Train Epoch: 162 [14080/50000 (28%)]\tLoss: 0.995666\n",
      "Train Epoch: 162 [15360/50000 (31%)]\tLoss: 0.955300\n",
      "Train Epoch: 162 [16640/50000 (33%)]\tLoss: 1.086733\n",
      "Train Epoch: 162 [17920/50000 (36%)]\tLoss: 1.046678\n",
      "Train Epoch: 162 [19200/50000 (38%)]\tLoss: 1.122475\n",
      "Train Epoch: 162 [20480/50000 (41%)]\tLoss: 0.951214\n",
      "Train Epoch: 162 [21760/50000 (43%)]\tLoss: 0.944432\n",
      "Train Epoch: 162 [23040/50000 (46%)]\tLoss: 0.750983\n",
      "Train Epoch: 162 [24320/50000 (49%)]\tLoss: 1.043451\n",
      "Train Epoch: 162 [25600/50000 (51%)]\tLoss: 0.941633\n",
      "Train Epoch: 162 [26880/50000 (54%)]\tLoss: 1.095385\n",
      "Train Epoch: 162 [28160/50000 (56%)]\tLoss: 0.891843\n",
      "Train Epoch: 162 [29440/50000 (59%)]\tLoss: 1.093204\n",
      "Train Epoch: 162 [30720/50000 (61%)]\tLoss: 0.941759\n",
      "Train Epoch: 162 [32000/50000 (64%)]\tLoss: 0.816687\n",
      "Train Epoch: 162 [33280/50000 (66%)]\tLoss: 1.031045\n",
      "Train Epoch: 162 [34560/50000 (69%)]\tLoss: 1.069619\n",
      "Train Epoch: 162 [35840/50000 (72%)]\tLoss: 0.995212\n",
      "Train Epoch: 162 [37120/50000 (74%)]\tLoss: 1.073013\n",
      "Train Epoch: 162 [38400/50000 (77%)]\tLoss: 1.165173\n",
      "Train Epoch: 162 [39680/50000 (79%)]\tLoss: 0.935151\n",
      "Train Epoch: 162 [40960/50000 (82%)]\tLoss: 0.829686\n",
      "Train Epoch: 162 [42240/50000 (84%)]\tLoss: 0.962342\n",
      "Train Epoch: 162 [43520/50000 (87%)]\tLoss: 0.975742\n",
      "Train Epoch: 162 [44800/50000 (90%)]\tLoss: 0.802663\n",
      "Train Epoch: 162 [46080/50000 (92%)]\tLoss: 0.896417\n",
      "Train Epoch: 162 [47360/50000 (95%)]\tLoss: 0.777481\n",
      "Train Epoch: 162 [48640/50000 (97%)]\tLoss: 1.015977\n",
      "Train Epoch: 162 [31200/50000 (100%)]\tLoss: 0.911640\n",
      "\n",
      "Test set: Avg. loss: 0.000343, Accuracy: 8492/9250 (91.81%)\n",
      "\n",
      "Train Epoch: 163 [0/50000 (0%)]\tLoss: 0.140412\n",
      "Train Epoch: 163 [1280/50000 (3%)]\tLoss: 1.087996\n",
      "Train Epoch: 163 [2560/50000 (5%)]\tLoss: 0.950143\n",
      "Train Epoch: 163 [3840/50000 (8%)]\tLoss: 0.962006\n",
      "Train Epoch: 163 [5120/50000 (10%)]\tLoss: 1.018802\n",
      "Train Epoch: 163 [6400/50000 (13%)]\tLoss: 1.009587\n",
      "Train Epoch: 163 [7680/50000 (15%)]\tLoss: 1.035782\n",
      "Train Epoch: 163 [8960/50000 (18%)]\tLoss: 0.823377\n",
      "Train Epoch: 163 [10240/50000 (20%)]\tLoss: 0.986800\n",
      "Train Epoch: 163 [11520/50000 (23%)]\tLoss: 1.024220\n",
      "Train Epoch: 163 [12800/50000 (26%)]\tLoss: 0.892362\n",
      "Train Epoch: 163 [14080/50000 (28%)]\tLoss: 1.024844\n",
      "Train Epoch: 163 [15360/50000 (31%)]\tLoss: 0.788647\n",
      "Train Epoch: 163 [16640/50000 (33%)]\tLoss: 0.816052\n",
      "Train Epoch: 163 [17920/50000 (36%)]\tLoss: 1.106361\n",
      "Train Epoch: 163 [19200/50000 (38%)]\tLoss: 0.894869\n",
      "Train Epoch: 163 [20480/50000 (41%)]\tLoss: 1.053024\n",
      "Train Epoch: 163 [21760/50000 (43%)]\tLoss: 0.963654\n",
      "Train Epoch: 163 [23040/50000 (46%)]\tLoss: 0.981809\n",
      "Train Epoch: 163 [24320/50000 (49%)]\tLoss: 0.822679\n",
      "Train Epoch: 163 [25600/50000 (51%)]\tLoss: 1.095506\n",
      "Train Epoch: 163 [26880/50000 (54%)]\tLoss: 1.195460\n",
      "Train Epoch: 163 [28160/50000 (56%)]\tLoss: 1.102664\n",
      "Train Epoch: 163 [29440/50000 (59%)]\tLoss: 1.040181\n",
      "Train Epoch: 163 [30720/50000 (61%)]\tLoss: 1.138891\n",
      "Train Epoch: 163 [32000/50000 (64%)]\tLoss: 0.982211\n",
      "Train Epoch: 163 [33280/50000 (66%)]\tLoss: 1.098323\n",
      "Train Epoch: 163 [34560/50000 (69%)]\tLoss: 0.946070\n",
      "Train Epoch: 163 [35840/50000 (72%)]\tLoss: 0.969766\n",
      "Train Epoch: 163 [37120/50000 (74%)]\tLoss: 1.026126\n",
      "Train Epoch: 163 [38400/50000 (77%)]\tLoss: 0.915402\n",
      "Train Epoch: 163 [39680/50000 (79%)]\tLoss: 0.924191\n",
      "Train Epoch: 163 [40960/50000 (82%)]\tLoss: 1.022987\n",
      "Train Epoch: 163 [42240/50000 (84%)]\tLoss: 0.865014\n",
      "Train Epoch: 163 [43520/50000 (87%)]\tLoss: 1.094065\n",
      "Train Epoch: 163 [44800/50000 (90%)]\tLoss: 0.817126\n",
      "Train Epoch: 163 [46080/50000 (92%)]\tLoss: 0.707031\n",
      "Train Epoch: 163 [47360/50000 (95%)]\tLoss: 1.095998\n",
      "Train Epoch: 163 [48640/50000 (97%)]\tLoss: 0.887080\n",
      "Train Epoch: 163 [31200/50000 (100%)]\tLoss: 1.003885\n",
      "\n",
      "Test set: Avg. loss: 0.000353, Accuracy: 8477/9250 (91.64%)\n",
      "\n",
      "Train Epoch: 164 [0/50000 (0%)]\tLoss: 0.123232\n",
      "Train Epoch: 164 [1280/50000 (3%)]\tLoss: 0.943630\n",
      "Train Epoch: 164 [2560/50000 (5%)]\tLoss: 0.845385\n",
      "Train Epoch: 164 [3840/50000 (8%)]\tLoss: 0.971413\n",
      "Train Epoch: 164 [5120/50000 (10%)]\tLoss: 0.995968\n",
      "Train Epoch: 164 [6400/50000 (13%)]\tLoss: 0.831454\n",
      "Train Epoch: 164 [7680/50000 (15%)]\tLoss: 0.772326\n",
      "Train Epoch: 164 [8960/50000 (18%)]\tLoss: 0.980667\n",
      "Train Epoch: 164 [10240/50000 (20%)]\tLoss: 0.980660\n",
      "Train Epoch: 164 [11520/50000 (23%)]\tLoss: 0.872462\n",
      "Train Epoch: 164 [12800/50000 (26%)]\tLoss: 0.889833\n",
      "Train Epoch: 164 [14080/50000 (28%)]\tLoss: 0.769548\n",
      "Train Epoch: 164 [15360/50000 (31%)]\tLoss: 0.898755\n",
      "Train Epoch: 164 [16640/50000 (33%)]\tLoss: 1.025246\n",
      "Train Epoch: 164 [17920/50000 (36%)]\tLoss: 0.797811\n",
      "Train Epoch: 164 [19200/50000 (38%)]\tLoss: 1.176475\n",
      "Train Epoch: 164 [20480/50000 (41%)]\tLoss: 0.933311\n",
      "Train Epoch: 164 [21760/50000 (43%)]\tLoss: 1.076378\n",
      "Train Epoch: 164 [23040/50000 (46%)]\tLoss: 1.114618\n",
      "Train Epoch: 164 [24320/50000 (49%)]\tLoss: 0.989926\n",
      "Train Epoch: 164 [25600/50000 (51%)]\tLoss: 1.036960\n",
      "Train Epoch: 164 [26880/50000 (54%)]\tLoss: 0.973524\n",
      "Train Epoch: 164 [28160/50000 (56%)]\tLoss: 0.991622\n",
      "Train Epoch: 164 [29440/50000 (59%)]\tLoss: 1.000818\n",
      "Train Epoch: 164 [30720/50000 (61%)]\tLoss: 1.039183\n",
      "Train Epoch: 164 [32000/50000 (64%)]\tLoss: 0.902950\n",
      "Train Epoch: 164 [33280/50000 (66%)]\tLoss: 1.088367\n",
      "Train Epoch: 164 [34560/50000 (69%)]\tLoss: 1.038485\n",
      "Train Epoch: 164 [35840/50000 (72%)]\tLoss: 0.950500\n",
      "Train Epoch: 164 [37120/50000 (74%)]\tLoss: 1.054391\n",
      "Train Epoch: 164 [38400/50000 (77%)]\tLoss: 0.774985\n",
      "Train Epoch: 164 [39680/50000 (79%)]\tLoss: 1.135316\n",
      "Train Epoch: 164 [40960/50000 (82%)]\tLoss: 0.828963\n",
      "Train Epoch: 164 [42240/50000 (84%)]\tLoss: 0.970591\n",
      "Train Epoch: 164 [43520/50000 (87%)]\tLoss: 0.971401\n",
      "Train Epoch: 164 [44800/50000 (90%)]\tLoss: 0.888347\n",
      "Train Epoch: 164 [46080/50000 (92%)]\tLoss: 1.088521\n",
      "Train Epoch: 164 [47360/50000 (95%)]\tLoss: 1.099702\n",
      "Train Epoch: 164 [48640/50000 (97%)]\tLoss: 0.660299\n",
      "Train Epoch: 164 [31200/50000 (100%)]\tLoss: 0.959217\n",
      "\n",
      "Test set: Avg. loss: 0.000326, Accuracy: 8500/9250 (91.89%)\n",
      "\n",
      "Train Epoch: 165 [0/50000 (0%)]\tLoss: 0.021393\n",
      "Train Epoch: 165 [1280/50000 (3%)]\tLoss: 1.057829\n",
      "Train Epoch: 165 [2560/50000 (5%)]\tLoss: 0.969625\n",
      "Train Epoch: 165 [3840/50000 (8%)]\tLoss: 0.907071\n",
      "Train Epoch: 165 [5120/50000 (10%)]\tLoss: 0.934490\n",
      "Train Epoch: 165 [6400/50000 (13%)]\tLoss: 1.149011\n",
      "Train Epoch: 165 [7680/50000 (15%)]\tLoss: 1.052768\n",
      "Train Epoch: 165 [8960/50000 (18%)]\tLoss: 1.057726\n",
      "Train Epoch: 165 [10240/50000 (20%)]\tLoss: 1.123119\n",
      "Train Epoch: 165 [11520/50000 (23%)]\tLoss: 0.672361\n",
      "Train Epoch: 165 [12800/50000 (26%)]\tLoss: 1.164642\n",
      "Train Epoch: 165 [14080/50000 (28%)]\tLoss: 1.097737\n",
      "Train Epoch: 165 [15360/50000 (31%)]\tLoss: 1.078239\n",
      "Train Epoch: 165 [16640/50000 (33%)]\tLoss: 1.034293\n",
      "Train Epoch: 165 [17920/50000 (36%)]\tLoss: 0.752272\n",
      "Train Epoch: 165 [19200/50000 (38%)]\tLoss: 0.888786\n",
      "Train Epoch: 165 [20480/50000 (41%)]\tLoss: 0.998484\n",
      "Train Epoch: 165 [21760/50000 (43%)]\tLoss: 1.019437\n",
      "Train Epoch: 165 [23040/50000 (46%)]\tLoss: 1.025557\n",
      "Train Epoch: 165 [24320/50000 (49%)]\tLoss: 0.818711\n",
      "Train Epoch: 165 [25600/50000 (51%)]\tLoss: 0.826065\n",
      "Train Epoch: 165 [26880/50000 (54%)]\tLoss: 0.950412\n",
      "Train Epoch: 165 [28160/50000 (56%)]\tLoss: 0.996633\n",
      "Train Epoch: 165 [29440/50000 (59%)]\tLoss: 1.079793\n",
      "Train Epoch: 165 [30720/50000 (61%)]\tLoss: 0.736970\n",
      "Train Epoch: 165 [32000/50000 (64%)]\tLoss: 0.995591\n",
      "Train Epoch: 165 [33280/50000 (66%)]\tLoss: 1.122094\n",
      "Train Epoch: 165 [34560/50000 (69%)]\tLoss: 1.070736\n",
      "Train Epoch: 165 [35840/50000 (72%)]\tLoss: 0.941540\n",
      "Train Epoch: 165 [37120/50000 (74%)]\tLoss: 0.952347\n",
      "Train Epoch: 165 [38400/50000 (77%)]\tLoss: 0.892474\n",
      "Train Epoch: 165 [39680/50000 (79%)]\tLoss: 0.959062\n",
      "Train Epoch: 165 [40960/50000 (82%)]\tLoss: 0.955153\n",
      "Train Epoch: 165 [42240/50000 (84%)]\tLoss: 1.038134\n",
      "Train Epoch: 165 [43520/50000 (87%)]\tLoss: 1.089579\n",
      "Train Epoch: 165 [44800/50000 (90%)]\tLoss: 0.973282\n",
      "Train Epoch: 165 [46080/50000 (92%)]\tLoss: 0.889668\n",
      "Train Epoch: 165 [47360/50000 (95%)]\tLoss: 0.911465\n",
      "Train Epoch: 165 [48640/50000 (97%)]\tLoss: 0.944637\n",
      "Train Epoch: 165 [31200/50000 (100%)]\tLoss: 1.049933\n",
      "\n",
      "Test set: Avg. loss: 0.000349, Accuracy: 8507/9250 (91.97%)\n",
      "\n",
      "Train Epoch: 166 [0/50000 (0%)]\tLoss: 0.092849\n",
      "Train Epoch: 166 [1280/50000 (3%)]\tLoss: 1.040711\n",
      "Train Epoch: 166 [2560/50000 (5%)]\tLoss: 0.955976\n",
      "Train Epoch: 166 [3840/50000 (8%)]\tLoss: 0.975678\n",
      "Train Epoch: 166 [5120/50000 (10%)]\tLoss: 1.131500\n",
      "Train Epoch: 166 [6400/50000 (13%)]\tLoss: 1.078678\n",
      "Train Epoch: 166 [7680/50000 (15%)]\tLoss: 0.863834\n",
      "Train Epoch: 166 [8960/50000 (18%)]\tLoss: 0.956518\n",
      "Train Epoch: 166 [10240/50000 (20%)]\tLoss: 1.119750\n",
      "Train Epoch: 166 [11520/50000 (23%)]\tLoss: 0.823323\n",
      "Train Epoch: 166 [12800/50000 (26%)]\tLoss: 0.981578\n",
      "Train Epoch: 166 [14080/50000 (28%)]\tLoss: 0.737519\n",
      "Train Epoch: 166 [15360/50000 (31%)]\tLoss: 0.914412\n",
      "Train Epoch: 166 [16640/50000 (33%)]\tLoss: 1.052099\n",
      "Train Epoch: 166 [17920/50000 (36%)]\tLoss: 1.031372\n",
      "Train Epoch: 166 [19200/50000 (38%)]\tLoss: 0.835798\n",
      "Train Epoch: 166 [20480/50000 (41%)]\tLoss: 0.928029\n",
      "Train Epoch: 166 [21760/50000 (43%)]\tLoss: 0.893362\n",
      "Train Epoch: 166 [23040/50000 (46%)]\tLoss: 0.741576\n",
      "Train Epoch: 166 [24320/50000 (49%)]\tLoss: 0.970962\n",
      "Train Epoch: 166 [25600/50000 (51%)]\tLoss: 1.010102\n",
      "Train Epoch: 166 [26880/50000 (54%)]\tLoss: 1.063639\n",
      "Train Epoch: 166 [28160/50000 (56%)]\tLoss: 0.710139\n",
      "Train Epoch: 166 [29440/50000 (59%)]\tLoss: 1.120360\n",
      "Train Epoch: 166 [30720/50000 (61%)]\tLoss: 1.108250\n",
      "Train Epoch: 166 [32000/50000 (64%)]\tLoss: 0.993763\n",
      "Train Epoch: 166 [33280/50000 (66%)]\tLoss: 1.035262\n",
      "Train Epoch: 166 [34560/50000 (69%)]\tLoss: 0.879714\n",
      "Train Epoch: 166 [35840/50000 (72%)]\tLoss: 0.983982\n",
      "Train Epoch: 166 [37120/50000 (74%)]\tLoss: 0.893106\n",
      "Train Epoch: 166 [38400/50000 (77%)]\tLoss: 1.015532\n",
      "Train Epoch: 166 [39680/50000 (79%)]\tLoss: 1.069515\n",
      "Train Epoch: 166 [40960/50000 (82%)]\tLoss: 1.093481\n",
      "Train Epoch: 166 [42240/50000 (84%)]\tLoss: 0.983096\n",
      "Train Epoch: 166 [43520/50000 (87%)]\tLoss: 0.823275\n",
      "Train Epoch: 166 [44800/50000 (90%)]\tLoss: 0.953014\n",
      "Train Epoch: 166 [46080/50000 (92%)]\tLoss: 1.105414\n",
      "Train Epoch: 166 [47360/50000 (95%)]\tLoss: 0.887490\n",
      "Train Epoch: 166 [48640/50000 (97%)]\tLoss: 0.976279\n",
      "Train Epoch: 166 [31200/50000 (100%)]\tLoss: 0.813786\n",
      "\n",
      "Test set: Avg. loss: 0.000334, Accuracy: 8489/9250 (91.77%)\n",
      "\n",
      "Train Epoch: 167 [0/50000 (0%)]\tLoss: 0.118601\n",
      "Train Epoch: 167 [1280/50000 (3%)]\tLoss: 1.089608\n",
      "Train Epoch: 167 [2560/50000 (5%)]\tLoss: 0.891111\n",
      "Train Epoch: 167 [3840/50000 (8%)]\tLoss: 1.020397\n",
      "Train Epoch: 167 [5120/50000 (10%)]\tLoss: 0.974818\n",
      "Train Epoch: 167 [6400/50000 (13%)]\tLoss: 1.044932\n",
      "Train Epoch: 167 [7680/50000 (15%)]\tLoss: 1.033687\n",
      "Train Epoch: 167 [8960/50000 (18%)]\tLoss: 0.853782\n",
      "Train Epoch: 167 [10240/50000 (20%)]\tLoss: 0.942973\n",
      "Train Epoch: 167 [11520/50000 (23%)]\tLoss: 1.053725\n",
      "Train Epoch: 167 [12800/50000 (26%)]\tLoss: 1.003952\n",
      "Train Epoch: 167 [14080/50000 (28%)]\tLoss: 1.038568\n",
      "Train Epoch: 167 [15360/50000 (31%)]\tLoss: 0.951594\n",
      "Train Epoch: 167 [16640/50000 (33%)]\tLoss: 0.747312\n",
      "Train Epoch: 167 [17920/50000 (36%)]\tLoss: 1.041196\n",
      "Train Epoch: 167 [19200/50000 (38%)]\tLoss: 0.928692\n",
      "Train Epoch: 167 [20480/50000 (41%)]\tLoss: 1.214583\n",
      "Train Epoch: 167 [21760/50000 (43%)]\tLoss: 0.961561\n",
      "Train Epoch: 167 [23040/50000 (46%)]\tLoss: 0.866940\n",
      "Train Epoch: 167 [24320/50000 (49%)]\tLoss: 0.982223\n",
      "Train Epoch: 167 [25600/50000 (51%)]\tLoss: 0.853146\n",
      "Train Epoch: 167 [26880/50000 (54%)]\tLoss: 0.924684\n",
      "Train Epoch: 167 [28160/50000 (56%)]\tLoss: 1.008640\n",
      "Train Epoch: 167 [29440/50000 (59%)]\tLoss: 0.661084\n",
      "Train Epoch: 167 [30720/50000 (61%)]\tLoss: 0.855984\n",
      "Train Epoch: 167 [32000/50000 (64%)]\tLoss: 1.008169\n",
      "Train Epoch: 167 [33280/50000 (66%)]\tLoss: 0.980149\n",
      "Train Epoch: 167 [34560/50000 (69%)]\tLoss: 0.958131\n",
      "Train Epoch: 167 [35840/50000 (72%)]\tLoss: 1.075829\n",
      "Train Epoch: 167 [37120/50000 (74%)]\tLoss: 1.059723\n",
      "Train Epoch: 167 [38400/50000 (77%)]\tLoss: 0.977713\n",
      "Train Epoch: 167 [39680/50000 (79%)]\tLoss: 0.921957\n",
      "Train Epoch: 167 [40960/50000 (82%)]\tLoss: 0.897392\n",
      "Train Epoch: 167 [42240/50000 (84%)]\tLoss: 1.034807\n",
      "Train Epoch: 167 [43520/50000 (87%)]\tLoss: 0.848171\n",
      "Train Epoch: 167 [44800/50000 (90%)]\tLoss: 0.893864\n",
      "Train Epoch: 167 [46080/50000 (92%)]\tLoss: 1.044347\n",
      "Train Epoch: 167 [47360/50000 (95%)]\tLoss: 0.811424\n",
      "Train Epoch: 167 [48640/50000 (97%)]\tLoss: 1.182477\n",
      "Train Epoch: 167 [31200/50000 (100%)]\tLoss: 1.099434\n",
      "\n",
      "Test set: Avg. loss: 0.000360, Accuracy: 8503/9250 (91.92%)\n",
      "\n",
      "Train Epoch: 168 [0/50000 (0%)]\tLoss: 0.121981\n",
      "Train Epoch: 168 [1280/50000 (3%)]\tLoss: 1.016004\n",
      "Train Epoch: 168 [2560/50000 (5%)]\tLoss: 1.040863\n",
      "Train Epoch: 168 [3840/50000 (8%)]\tLoss: 1.097326\n",
      "Train Epoch: 168 [5120/50000 (10%)]\tLoss: 0.906856\n",
      "Train Epoch: 168 [6400/50000 (13%)]\tLoss: 0.920967\n",
      "Train Epoch: 168 [7680/50000 (15%)]\tLoss: 1.038515\n",
      "Train Epoch: 168 [8960/50000 (18%)]\tLoss: 0.814310\n",
      "Train Epoch: 168 [10240/50000 (20%)]\tLoss: 1.180906\n",
      "Train Epoch: 168 [11520/50000 (23%)]\tLoss: 1.086060\n",
      "Train Epoch: 168 [12800/50000 (26%)]\tLoss: 0.860343\n",
      "Train Epoch: 168 [14080/50000 (28%)]\tLoss: 0.828841\n",
      "Train Epoch: 168 [15360/50000 (31%)]\tLoss: 1.261650\n",
      "Train Epoch: 168 [16640/50000 (33%)]\tLoss: 1.010450\n",
      "Train Epoch: 168 [17920/50000 (36%)]\tLoss: 0.902495\n",
      "Train Epoch: 168 [19200/50000 (38%)]\tLoss: 0.836231\n",
      "Train Epoch: 168 [20480/50000 (41%)]\tLoss: 0.982224\n",
      "Train Epoch: 168 [21760/50000 (43%)]\tLoss: 0.980573\n",
      "Train Epoch: 168 [23040/50000 (46%)]\tLoss: 0.829237\n",
      "Train Epoch: 168 [24320/50000 (49%)]\tLoss: 0.822416\n",
      "Train Epoch: 168 [25600/50000 (51%)]\tLoss: 1.049888\n",
      "Train Epoch: 168 [26880/50000 (54%)]\tLoss: 1.129157\n",
      "Train Epoch: 168 [28160/50000 (56%)]\tLoss: 0.949483\n",
      "Train Epoch: 168 [29440/50000 (59%)]\tLoss: 0.931773\n",
      "Train Epoch: 168 [30720/50000 (61%)]\tLoss: 0.992334\n",
      "Train Epoch: 168 [32000/50000 (64%)]\tLoss: 0.795701\n",
      "Train Epoch: 168 [33280/50000 (66%)]\tLoss: 0.983486\n",
      "Train Epoch: 168 [34560/50000 (69%)]\tLoss: 0.902399\n",
      "Train Epoch: 168 [35840/50000 (72%)]\tLoss: 0.995119\n",
      "Train Epoch: 168 [37120/50000 (74%)]\tLoss: 0.790867\n",
      "Train Epoch: 168 [38400/50000 (77%)]\tLoss: 0.859849\n",
      "Train Epoch: 168 [39680/50000 (79%)]\tLoss: 0.931281\n",
      "Train Epoch: 168 [40960/50000 (82%)]\tLoss: 1.023140\n",
      "Train Epoch: 168 [42240/50000 (84%)]\tLoss: 1.149516\n",
      "Train Epoch: 168 [43520/50000 (87%)]\tLoss: 0.922090\n",
      "Train Epoch: 168 [44800/50000 (90%)]\tLoss: 0.845194\n",
      "Train Epoch: 168 [46080/50000 (92%)]\tLoss: 0.908881\n",
      "Train Epoch: 168 [47360/50000 (95%)]\tLoss: 1.131681\n",
      "Train Epoch: 168 [48640/50000 (97%)]\tLoss: 0.963461\n",
      "Train Epoch: 168 [31200/50000 (100%)]\tLoss: 1.096101\n",
      "\n",
      "Test set: Avg. loss: 0.000352, Accuracy: 8518/9250 (92.09%)\n",
      "\n",
      "Train Epoch: 169 [0/50000 (0%)]\tLoss: 0.135264\n",
      "Train Epoch: 169 [1280/50000 (3%)]\tLoss: 0.993501\n",
      "Train Epoch: 169 [2560/50000 (5%)]\tLoss: 1.045171\n",
      "Train Epoch: 169 [3840/50000 (8%)]\tLoss: 0.770670\n",
      "Train Epoch: 169 [5120/50000 (10%)]\tLoss: 1.033033\n",
      "Train Epoch: 169 [6400/50000 (13%)]\tLoss: 1.088737\n",
      "Train Epoch: 169 [7680/50000 (15%)]\tLoss: 1.049035\n",
      "Train Epoch: 169 [8960/50000 (18%)]\tLoss: 0.962251\n",
      "Train Epoch: 169 [10240/50000 (20%)]\tLoss: 1.023761\n",
      "Train Epoch: 169 [11520/50000 (23%)]\tLoss: 0.758970\n",
      "Train Epoch: 169 [12800/50000 (26%)]\tLoss: 1.057014\n",
      "Train Epoch: 169 [14080/50000 (28%)]\tLoss: 0.952999\n",
      "Train Epoch: 169 [15360/50000 (31%)]\tLoss: 1.008836\n",
      "Train Epoch: 169 [16640/50000 (33%)]\tLoss: 1.088325\n",
      "Train Epoch: 169 [17920/50000 (36%)]\tLoss: 0.928078\n",
      "Train Epoch: 169 [19200/50000 (38%)]\tLoss: 1.105530\n",
      "Train Epoch: 169 [20480/50000 (41%)]\tLoss: 0.774809\n",
      "Train Epoch: 169 [21760/50000 (43%)]\tLoss: 0.959128\n",
      "Train Epoch: 169 [23040/50000 (46%)]\tLoss: 0.939269\n",
      "Train Epoch: 169 [24320/50000 (49%)]\tLoss: 1.106282\n",
      "Train Epoch: 169 [25600/50000 (51%)]\tLoss: 1.066117\n",
      "Train Epoch: 169 [26880/50000 (54%)]\tLoss: 1.108136\n",
      "Train Epoch: 169 [28160/50000 (56%)]\tLoss: 0.743342\n",
      "Train Epoch: 169 [29440/50000 (59%)]\tLoss: 0.930005\n",
      "Train Epoch: 169 [30720/50000 (61%)]\tLoss: 0.954593\n",
      "Train Epoch: 169 [32000/50000 (64%)]\tLoss: 0.833639\n",
      "Train Epoch: 169 [33280/50000 (66%)]\tLoss: 1.009145\n",
      "Train Epoch: 169 [34560/50000 (69%)]\tLoss: 0.862151\n",
      "Train Epoch: 169 [35840/50000 (72%)]\tLoss: 0.831511\n",
      "Train Epoch: 169 [37120/50000 (74%)]\tLoss: 0.928725\n",
      "Train Epoch: 169 [38400/50000 (77%)]\tLoss: 1.023907\n",
      "Train Epoch: 169 [39680/50000 (79%)]\tLoss: 1.021148\n",
      "Train Epoch: 169 [40960/50000 (82%)]\tLoss: 0.939678\n",
      "Train Epoch: 169 [42240/50000 (84%)]\tLoss: 0.938532\n",
      "Train Epoch: 169 [43520/50000 (87%)]\tLoss: 0.895670\n",
      "Train Epoch: 169 [44800/50000 (90%)]\tLoss: 0.958213\n",
      "Train Epoch: 169 [46080/50000 (92%)]\tLoss: 1.106782\n",
      "Train Epoch: 169 [47360/50000 (95%)]\tLoss: 1.026655\n",
      "Train Epoch: 169 [48640/50000 (97%)]\tLoss: 1.007495\n",
      "Train Epoch: 169 [31200/50000 (100%)]\tLoss: 0.890298\n",
      "\n",
      "Test set: Avg. loss: 0.000344, Accuracy: 8493/9250 (91.82%)\n",
      "\n",
      "Train Epoch: 170 [0/50000 (0%)]\tLoss: 0.045567\n",
      "Train Epoch: 170 [1280/50000 (3%)]\tLoss: 0.790050\n",
      "Train Epoch: 170 [2560/50000 (5%)]\tLoss: 0.783511\n",
      "Train Epoch: 170 [3840/50000 (8%)]\tLoss: 1.032045\n",
      "Train Epoch: 170 [5120/50000 (10%)]\tLoss: 1.118090\n",
      "Train Epoch: 170 [6400/50000 (13%)]\tLoss: 0.972732\n",
      "Train Epoch: 170 [7680/50000 (15%)]\tLoss: 1.031163\n",
      "Train Epoch: 170 [8960/50000 (18%)]\tLoss: 0.936200\n",
      "Train Epoch: 170 [10240/50000 (20%)]\tLoss: 0.979924\n",
      "Train Epoch: 170 [11520/50000 (23%)]\tLoss: 0.907240\n",
      "Train Epoch: 170 [12800/50000 (26%)]\tLoss: 0.949994\n",
      "Train Epoch: 170 [14080/50000 (28%)]\tLoss: 0.910692\n",
      "Train Epoch: 170 [15360/50000 (31%)]\tLoss: 0.995892\n",
      "Train Epoch: 170 [16640/50000 (33%)]\tLoss: 1.002377\n",
      "Train Epoch: 170 [17920/50000 (36%)]\tLoss: 0.833576\n",
      "Train Epoch: 170 [19200/50000 (38%)]\tLoss: 1.088400\n",
      "Train Epoch: 170 [20480/50000 (41%)]\tLoss: 0.883644\n",
      "Train Epoch: 170 [21760/50000 (43%)]\tLoss: 1.034724\n",
      "Train Epoch: 170 [23040/50000 (46%)]\tLoss: 0.900503\n",
      "Train Epoch: 170 [24320/50000 (49%)]\tLoss: 1.000025\n",
      "Train Epoch: 170 [25600/50000 (51%)]\tLoss: 0.754066\n",
      "Train Epoch: 170 [26880/50000 (54%)]\tLoss: 1.027884\n",
      "Train Epoch: 170 [28160/50000 (56%)]\tLoss: 0.972275\n",
      "Train Epoch: 170 [29440/50000 (59%)]\tLoss: 0.953694\n",
      "Train Epoch: 170 [30720/50000 (61%)]\tLoss: 1.180095\n",
      "Train Epoch: 170 [32000/50000 (64%)]\tLoss: 0.970363\n",
      "Train Epoch: 170 [33280/50000 (66%)]\tLoss: 0.911249\n",
      "Train Epoch: 170 [34560/50000 (69%)]\tLoss: 0.831161\n",
      "Train Epoch: 170 [35840/50000 (72%)]\tLoss: 0.966139\n",
      "Train Epoch: 170 [37120/50000 (74%)]\tLoss: 1.120098\n",
      "Train Epoch: 170 [38400/50000 (77%)]\tLoss: 1.030197\n",
      "Train Epoch: 170 [39680/50000 (79%)]\tLoss: 1.062043\n",
      "Train Epoch: 170 [40960/50000 (82%)]\tLoss: 1.098484\n",
      "Train Epoch: 170 [42240/50000 (84%)]\tLoss: 0.831212\n",
      "Train Epoch: 170 [43520/50000 (87%)]\tLoss: 0.880783\n",
      "Train Epoch: 170 [44800/50000 (90%)]\tLoss: 0.920137\n",
      "Train Epoch: 170 [46080/50000 (92%)]\tLoss: 0.978030\n",
      "Train Epoch: 170 [47360/50000 (95%)]\tLoss: 0.883384\n",
      "Train Epoch: 170 [48640/50000 (97%)]\tLoss: 1.023257\n",
      "Train Epoch: 170 [31200/50000 (100%)]\tLoss: 0.890893\n",
      "\n",
      "Test set: Avg. loss: 0.000336, Accuracy: 8515/9250 (92.05%)\n",
      "\n",
      "Train Epoch: 171 [0/50000 (0%)]\tLoss: 0.086683\n",
      "Train Epoch: 171 [1280/50000 (3%)]\tLoss: 0.721688\n",
      "Train Epoch: 171 [2560/50000 (5%)]\tLoss: 0.843248\n",
      "Train Epoch: 171 [3840/50000 (8%)]\tLoss: 1.075665\n",
      "Train Epoch: 171 [5120/50000 (10%)]\tLoss: 0.954732\n",
      "Train Epoch: 171 [6400/50000 (13%)]\tLoss: 1.151753\n",
      "Train Epoch: 171 [7680/50000 (15%)]\tLoss: 0.912211\n",
      "Train Epoch: 171 [8960/50000 (18%)]\tLoss: 0.898476\n",
      "Train Epoch: 171 [10240/50000 (20%)]\tLoss: 0.987039\n",
      "Train Epoch: 171 [11520/50000 (23%)]\tLoss: 0.871417\n",
      "Train Epoch: 171 [12800/50000 (26%)]\tLoss: 0.983649\n",
      "Train Epoch: 171 [14080/50000 (28%)]\tLoss: 0.983186\n",
      "Train Epoch: 171 [15360/50000 (31%)]\tLoss: 1.105324\n",
      "Train Epoch: 171 [16640/50000 (33%)]\tLoss: 1.052567\n",
      "Train Epoch: 171 [17920/50000 (36%)]\tLoss: 0.934185\n",
      "Train Epoch: 171 [19200/50000 (38%)]\tLoss: 0.834268\n",
      "Train Epoch: 171 [20480/50000 (41%)]\tLoss: 0.990927\n",
      "Train Epoch: 171 [21760/50000 (43%)]\tLoss: 1.051128\n",
      "Train Epoch: 171 [23040/50000 (46%)]\tLoss: 0.740626\n",
      "Train Epoch: 171 [24320/50000 (49%)]\tLoss: 1.085811\n",
      "Train Epoch: 171 [25600/50000 (51%)]\tLoss: 0.932264\n",
      "Train Epoch: 171 [26880/50000 (54%)]\tLoss: 0.947806\n",
      "Train Epoch: 171 [28160/50000 (56%)]\tLoss: 1.141248\n",
      "Train Epoch: 171 [29440/50000 (59%)]\tLoss: 1.016351\n",
      "Train Epoch: 171 [30720/50000 (61%)]\tLoss: 0.955713\n",
      "Train Epoch: 171 [32000/50000 (64%)]\tLoss: 0.977294\n",
      "Train Epoch: 171 [33280/50000 (66%)]\tLoss: 0.997792\n",
      "Train Epoch: 171 [34560/50000 (69%)]\tLoss: 0.878431\n",
      "Train Epoch: 171 [35840/50000 (72%)]\tLoss: 0.869495\n",
      "Train Epoch: 171 [37120/50000 (74%)]\tLoss: 1.113497\n",
      "Train Epoch: 171 [38400/50000 (77%)]\tLoss: 1.076384\n",
      "Train Epoch: 171 [39680/50000 (79%)]\tLoss: 1.170077\n",
      "Train Epoch: 171 [40960/50000 (82%)]\tLoss: 1.037424\n",
      "Train Epoch: 171 [42240/50000 (84%)]\tLoss: 1.118949\n",
      "Train Epoch: 171 [43520/50000 (87%)]\tLoss: 0.921109\n",
      "Train Epoch: 171 [44800/50000 (90%)]\tLoss: 0.963730\n",
      "Train Epoch: 171 [46080/50000 (92%)]\tLoss: 1.125119\n",
      "Train Epoch: 171 [47360/50000 (95%)]\tLoss: 1.160615\n",
      "Train Epoch: 171 [48640/50000 (97%)]\tLoss: 0.906644\n",
      "Train Epoch: 171 [31200/50000 (100%)]\tLoss: 0.851268\n",
      "\n",
      "Test set: Avg. loss: 0.000332, Accuracy: 8509/9250 (91.99%)\n",
      "\n",
      "Train Epoch: 172 [0/50000 (0%)]\tLoss: 0.111228\n",
      "Train Epoch: 172 [1280/50000 (3%)]\tLoss: 0.991008\n",
      "Train Epoch: 172 [2560/50000 (5%)]\tLoss: 0.887159\n",
      "Train Epoch: 172 [3840/50000 (8%)]\tLoss: 0.773531\n",
      "Train Epoch: 172 [5120/50000 (10%)]\tLoss: 1.007734\n",
      "Train Epoch: 172 [6400/50000 (13%)]\tLoss: 1.136113\n",
      "Train Epoch: 172 [7680/50000 (15%)]\tLoss: 1.004440\n",
      "Train Epoch: 172 [8960/50000 (18%)]\tLoss: 0.889762\n",
      "Train Epoch: 172 [10240/50000 (20%)]\tLoss: 0.918648\n",
      "Train Epoch: 172 [11520/50000 (23%)]\tLoss: 0.975172\n",
      "Train Epoch: 172 [12800/50000 (26%)]\tLoss: 0.943811\n",
      "Train Epoch: 172 [14080/50000 (28%)]\tLoss: 0.930721\n",
      "Train Epoch: 172 [15360/50000 (31%)]\tLoss: 0.912997\n",
      "Train Epoch: 172 [16640/50000 (33%)]\tLoss: 0.868268\n",
      "Train Epoch: 172 [17920/50000 (36%)]\tLoss: 1.012249\n",
      "Train Epoch: 172 [19200/50000 (38%)]\tLoss: 1.113113\n",
      "Train Epoch: 172 [20480/50000 (41%)]\tLoss: 0.879676\n",
      "Train Epoch: 172 [21760/50000 (43%)]\tLoss: 1.016131\n",
      "Train Epoch: 172 [23040/50000 (46%)]\tLoss: 0.972834\n",
      "Train Epoch: 172 [24320/50000 (49%)]\tLoss: 0.781147\n",
      "Train Epoch: 172 [25600/50000 (51%)]\tLoss: 1.073363\n",
      "Train Epoch: 172 [26880/50000 (54%)]\tLoss: 0.939972\n",
      "Train Epoch: 172 [28160/50000 (56%)]\tLoss: 0.910820\n",
      "Train Epoch: 172 [29440/50000 (59%)]\tLoss: 0.961770\n",
      "Train Epoch: 172 [30720/50000 (61%)]\tLoss: 1.095547\n",
      "Train Epoch: 172 [32000/50000 (64%)]\tLoss: 1.045337\n",
      "Train Epoch: 172 [33280/50000 (66%)]\tLoss: 0.957209\n",
      "Train Epoch: 172 [34560/50000 (69%)]\tLoss: 0.940220\n",
      "Train Epoch: 172 [35840/50000 (72%)]\tLoss: 1.019637\n",
      "Train Epoch: 172 [37120/50000 (74%)]\tLoss: 0.999685\n",
      "Train Epoch: 172 [38400/50000 (77%)]\tLoss: 0.939934\n",
      "Train Epoch: 172 [39680/50000 (79%)]\tLoss: 0.730893\n",
      "Train Epoch: 172 [40960/50000 (82%)]\tLoss: 1.024858\n",
      "Train Epoch: 172 [42240/50000 (84%)]\tLoss: 1.257989\n",
      "Train Epoch: 172 [43520/50000 (87%)]\tLoss: 0.893733\n",
      "Train Epoch: 172 [44800/50000 (90%)]\tLoss: 0.833880\n",
      "Train Epoch: 172 [46080/50000 (92%)]\tLoss: 0.956609\n",
      "Train Epoch: 172 [47360/50000 (95%)]\tLoss: 0.884474\n",
      "Train Epoch: 172 [48640/50000 (97%)]\tLoss: 1.018140\n",
      "Train Epoch: 172 [31200/50000 (100%)]\tLoss: 0.911895\n",
      "\n",
      "Test set: Avg. loss: 0.000332, Accuracy: 8506/9250 (91.96%)\n",
      "\n",
      "Train Epoch: 173 [0/50000 (0%)]\tLoss: 0.121676\n",
      "Train Epoch: 173 [1280/50000 (3%)]\tLoss: 0.829028\n",
      "Train Epoch: 173 [2560/50000 (5%)]\tLoss: 0.894929\n",
      "Train Epoch: 173 [3840/50000 (8%)]\tLoss: 1.012608\n",
      "Train Epoch: 173 [5120/50000 (10%)]\tLoss: 0.867031\n",
      "Train Epoch: 173 [6400/50000 (13%)]\tLoss: 1.151274\n",
      "Train Epoch: 173 [7680/50000 (15%)]\tLoss: 0.987320\n",
      "Train Epoch: 173 [8960/50000 (18%)]\tLoss: 1.120437\n",
      "Train Epoch: 173 [10240/50000 (20%)]\tLoss: 1.004118\n",
      "Train Epoch: 173 [11520/50000 (23%)]\tLoss: 1.040336\n",
      "Train Epoch: 173 [12800/50000 (26%)]\tLoss: 0.863842\n",
      "Train Epoch: 173 [14080/50000 (28%)]\tLoss: 1.009984\n",
      "Train Epoch: 173 [15360/50000 (31%)]\tLoss: 1.043943\n",
      "Train Epoch: 173 [16640/50000 (33%)]\tLoss: 1.062435\n",
      "Train Epoch: 173 [17920/50000 (36%)]\tLoss: 0.759472\n",
      "Train Epoch: 173 [19200/50000 (38%)]\tLoss: 0.907186\n",
      "Train Epoch: 173 [20480/50000 (41%)]\tLoss: 1.033731\n",
      "Train Epoch: 173 [21760/50000 (43%)]\tLoss: 0.813258\n",
      "Train Epoch: 173 [23040/50000 (46%)]\tLoss: 0.999751\n",
      "Train Epoch: 173 [24320/50000 (49%)]\tLoss: 0.999355\n",
      "Train Epoch: 173 [25600/50000 (51%)]\tLoss: 0.970850\n",
      "Train Epoch: 173 [26880/50000 (54%)]\tLoss: 0.999864\n",
      "Train Epoch: 173 [28160/50000 (56%)]\tLoss: 0.917028\n",
      "Train Epoch: 173 [29440/50000 (59%)]\tLoss: 1.068628\n",
      "Train Epoch: 173 [30720/50000 (61%)]\tLoss: 0.904252\n",
      "Train Epoch: 173 [32000/50000 (64%)]\tLoss: 1.041539\n",
      "Train Epoch: 173 [33280/50000 (66%)]\tLoss: 0.968547\n",
      "Train Epoch: 173 [34560/50000 (69%)]\tLoss: 0.976424\n",
      "Train Epoch: 173 [35840/50000 (72%)]\tLoss: 0.953261\n",
      "Train Epoch: 173 [37120/50000 (74%)]\tLoss: 0.905650\n",
      "Train Epoch: 173 [38400/50000 (77%)]\tLoss: 1.115701\n",
      "Train Epoch: 173 [39680/50000 (79%)]\tLoss: 0.951554\n",
      "Train Epoch: 173 [40960/50000 (82%)]\tLoss: 1.016109\n",
      "Train Epoch: 173 [42240/50000 (84%)]\tLoss: 1.065058\n",
      "Train Epoch: 173 [43520/50000 (87%)]\tLoss: 1.068241\n",
      "Train Epoch: 173 [44800/50000 (90%)]\tLoss: 0.893038\n",
      "Train Epoch: 173 [46080/50000 (92%)]\tLoss: 0.964809\n",
      "Train Epoch: 173 [47360/50000 (95%)]\tLoss: 0.960003\n",
      "Train Epoch: 173 [48640/50000 (97%)]\tLoss: 0.917958\n",
      "Train Epoch: 173 [31200/50000 (100%)]\tLoss: 1.071569\n",
      "\n",
      "Test set: Avg. loss: 0.000344, Accuracy: 8513/9250 (92.03%)\n",
      "\n",
      "Train Epoch: 174 [0/50000 (0%)]\tLoss: 0.025986\n",
      "Train Epoch: 174 [1280/50000 (3%)]\tLoss: 1.029177\n",
      "Train Epoch: 174 [2560/50000 (5%)]\tLoss: 0.809301\n",
      "Train Epoch: 174 [3840/50000 (8%)]\tLoss: 0.893208\n",
      "Train Epoch: 174 [5120/50000 (10%)]\tLoss: 1.033922\n",
      "Train Epoch: 174 [6400/50000 (13%)]\tLoss: 0.774155\n",
      "Train Epoch: 174 [7680/50000 (15%)]\tLoss: 0.958890\n",
      "Train Epoch: 174 [8960/50000 (18%)]\tLoss: 1.158131\n",
      "Train Epoch: 174 [10240/50000 (20%)]\tLoss: 0.779601\n",
      "Train Epoch: 174 [11520/50000 (23%)]\tLoss: 0.905414\n",
      "Train Epoch: 174 [12800/50000 (26%)]\tLoss: 1.013786\n",
      "Train Epoch: 174 [14080/50000 (28%)]\tLoss: 0.878824\n",
      "Train Epoch: 174 [15360/50000 (31%)]\tLoss: 0.907208\n",
      "Train Epoch: 174 [16640/50000 (33%)]\tLoss: 1.100618\n",
      "Train Epoch: 174 [17920/50000 (36%)]\tLoss: 0.743564\n",
      "Train Epoch: 174 [19200/50000 (38%)]\tLoss: 1.075251\n",
      "Train Epoch: 174 [20480/50000 (41%)]\tLoss: 0.986829\n",
      "Train Epoch: 174 [21760/50000 (43%)]\tLoss: 1.008811\n",
      "Train Epoch: 174 [23040/50000 (46%)]\tLoss: 1.058274\n",
      "Train Epoch: 174 [24320/50000 (49%)]\tLoss: 1.014990\n",
      "Train Epoch: 174 [25600/50000 (51%)]\tLoss: 0.891641\n",
      "Train Epoch: 174 [26880/50000 (54%)]\tLoss: 0.798667\n",
      "Train Epoch: 174 [28160/50000 (56%)]\tLoss: 1.114894\n",
      "Train Epoch: 174 [29440/50000 (59%)]\tLoss: 1.067346\n",
      "Train Epoch: 174 [30720/50000 (61%)]\tLoss: 1.219251\n",
      "Train Epoch: 174 [32000/50000 (64%)]\tLoss: 1.023440\n",
      "Train Epoch: 174 [33280/50000 (66%)]\tLoss: 1.156000\n",
      "Train Epoch: 174 [34560/50000 (69%)]\tLoss: 0.956167\n",
      "Train Epoch: 174 [35840/50000 (72%)]\tLoss: 0.888427\n",
      "Train Epoch: 174 [37120/50000 (74%)]\tLoss: 1.034754\n",
      "Train Epoch: 174 [38400/50000 (77%)]\tLoss: 1.053419\n",
      "Train Epoch: 174 [39680/50000 (79%)]\tLoss: 1.018730\n",
      "Train Epoch: 174 [40960/50000 (82%)]\tLoss: 0.917726\n",
      "Train Epoch: 174 [42240/50000 (84%)]\tLoss: 1.000794\n",
      "Train Epoch: 174 [43520/50000 (87%)]\tLoss: 0.864876\n",
      "Train Epoch: 174 [44800/50000 (90%)]\tLoss: 1.100657\n",
      "Train Epoch: 174 [46080/50000 (92%)]\tLoss: 0.826002\n",
      "Train Epoch: 174 [47360/50000 (95%)]\tLoss: 0.994238\n",
      "Train Epoch: 174 [48640/50000 (97%)]\tLoss: 0.802283\n",
      "Train Epoch: 174 [31200/50000 (100%)]\tLoss: 1.020659\n",
      "\n",
      "Test set: Avg. loss: 0.000343, Accuracy: 8524/9250 (92.15%)\n",
      "\n",
      "Train Epoch: 175 [0/50000 (0%)]\tLoss: 0.137377\n",
      "Train Epoch: 175 [1280/50000 (3%)]\tLoss: 1.149513\n",
      "Train Epoch: 175 [2560/50000 (5%)]\tLoss: 0.835421\n",
      "Train Epoch: 175 [3840/50000 (8%)]\tLoss: 0.784477\n",
      "Train Epoch: 175 [5120/50000 (10%)]\tLoss: 1.119700\n",
      "Train Epoch: 175 [6400/50000 (13%)]\tLoss: 0.869501\n",
      "Train Epoch: 175 [7680/50000 (15%)]\tLoss: 1.023510\n",
      "Train Epoch: 175 [8960/50000 (18%)]\tLoss: 1.073145\n",
      "Train Epoch: 175 [10240/50000 (20%)]\tLoss: 1.142200\n",
      "Train Epoch: 175 [11520/50000 (23%)]\tLoss: 1.147862\n",
      "Train Epoch: 175 [12800/50000 (26%)]\tLoss: 0.920807\n",
      "Train Epoch: 175 [14080/50000 (28%)]\tLoss: 0.739423\n",
      "Train Epoch: 175 [15360/50000 (31%)]\tLoss: 0.948063\n",
      "Train Epoch: 175 [16640/50000 (33%)]\tLoss: 0.959332\n",
      "Train Epoch: 175 [17920/50000 (36%)]\tLoss: 0.992934\n",
      "Train Epoch: 175 [19200/50000 (38%)]\tLoss: 1.102568\n",
      "Train Epoch: 175 [20480/50000 (41%)]\tLoss: 1.196487\n",
      "Train Epoch: 175 [21760/50000 (43%)]\tLoss: 0.842925\n",
      "Train Epoch: 175 [23040/50000 (46%)]\tLoss: 0.965538\n",
      "Train Epoch: 175 [24320/50000 (49%)]\tLoss: 1.013321\n",
      "Train Epoch: 175 [25600/50000 (51%)]\tLoss: 0.911316\n",
      "Train Epoch: 175 [26880/50000 (54%)]\tLoss: 0.767943\n",
      "Train Epoch: 175 [28160/50000 (56%)]\tLoss: 1.154932\n",
      "Train Epoch: 175 [29440/50000 (59%)]\tLoss: 1.096430\n",
      "Train Epoch: 175 [30720/50000 (61%)]\tLoss: 1.076720\n",
      "Train Epoch: 175 [32000/50000 (64%)]\tLoss: 1.039291\n",
      "Train Epoch: 175 [33280/50000 (66%)]\tLoss: 1.043253\n",
      "Train Epoch: 175 [34560/50000 (69%)]\tLoss: 1.029826\n",
      "Train Epoch: 175 [35840/50000 (72%)]\tLoss: 1.100613\n",
      "Train Epoch: 175 [37120/50000 (74%)]\tLoss: 1.030958\n",
      "Train Epoch: 175 [38400/50000 (77%)]\tLoss: 0.972344\n",
      "Train Epoch: 175 [39680/50000 (79%)]\tLoss: 0.841101\n",
      "Train Epoch: 175 [40960/50000 (82%)]\tLoss: 1.008428\n",
      "Train Epoch: 175 [42240/50000 (84%)]\tLoss: 0.967723\n",
      "Train Epoch: 175 [43520/50000 (87%)]\tLoss: 1.121490\n",
      "Train Epoch: 175 [44800/50000 (90%)]\tLoss: 0.821510\n",
      "Train Epoch: 175 [46080/50000 (92%)]\tLoss: 1.109671\n",
      "Train Epoch: 175 [47360/50000 (95%)]\tLoss: 1.117683\n",
      "Train Epoch: 175 [48640/50000 (97%)]\tLoss: 1.158134\n",
      "Train Epoch: 175 [31200/50000 (100%)]\tLoss: 0.913988\n",
      "\n",
      "Test set: Avg. loss: 0.000346, Accuracy: 8514/9250 (92.04%)\n",
      "\n",
      "Train Epoch: 176 [0/50000 (0%)]\tLoss: 0.110622\n",
      "Train Epoch: 176 [1280/50000 (3%)]\tLoss: 1.141394\n",
      "Train Epoch: 176 [2560/50000 (5%)]\tLoss: 0.886875\n",
      "Train Epoch: 176 [3840/50000 (8%)]\tLoss: 0.958072\n",
      "Train Epoch: 176 [5120/50000 (10%)]\tLoss: 0.893970\n",
      "Train Epoch: 176 [6400/50000 (13%)]\tLoss: 0.985681\n",
      "Train Epoch: 176 [7680/50000 (15%)]\tLoss: 0.854896\n",
      "Train Epoch: 176 [8960/50000 (18%)]\tLoss: 0.996500\n",
      "Train Epoch: 176 [10240/50000 (20%)]\tLoss: 1.011374\n",
      "Train Epoch: 176 [11520/50000 (23%)]\tLoss: 1.070307\n",
      "Train Epoch: 176 [12800/50000 (26%)]\tLoss: 1.011688\n",
      "Train Epoch: 176 [14080/50000 (28%)]\tLoss: 0.866253\n",
      "Train Epoch: 176 [15360/50000 (31%)]\tLoss: 0.874670\n",
      "Train Epoch: 176 [16640/50000 (33%)]\tLoss: 0.879342\n",
      "Train Epoch: 176 [17920/50000 (36%)]\tLoss: 0.950118\n",
      "Train Epoch: 176 [19200/50000 (38%)]\tLoss: 0.750419\n",
      "Train Epoch: 176 [20480/50000 (41%)]\tLoss: 1.009829\n",
      "Train Epoch: 176 [21760/50000 (43%)]\tLoss: 0.916206\n",
      "Train Epoch: 176 [23040/50000 (46%)]\tLoss: 0.841497\n",
      "Train Epoch: 176 [24320/50000 (49%)]\tLoss: 1.024370\n",
      "Train Epoch: 176 [25600/50000 (51%)]\tLoss: 0.999200\n",
      "Train Epoch: 176 [26880/50000 (54%)]\tLoss: 1.048393\n",
      "Train Epoch: 176 [28160/50000 (56%)]\tLoss: 0.777860\n",
      "Train Epoch: 176 [29440/50000 (59%)]\tLoss: 0.894011\n",
      "Train Epoch: 176 [30720/50000 (61%)]\tLoss: 1.054467\n",
      "Train Epoch: 176 [32000/50000 (64%)]\tLoss: 1.129595\n",
      "Train Epoch: 176 [33280/50000 (66%)]\tLoss: 0.861604\n",
      "Train Epoch: 176 [34560/50000 (69%)]\tLoss: 1.036704\n",
      "Train Epoch: 176 [35840/50000 (72%)]\tLoss: 1.020749\n",
      "Train Epoch: 176 [37120/50000 (74%)]\tLoss: 1.109617\n",
      "Train Epoch: 176 [38400/50000 (77%)]\tLoss: 0.918069\n",
      "Train Epoch: 176 [39680/50000 (79%)]\tLoss: 0.934499\n",
      "Train Epoch: 176 [40960/50000 (82%)]\tLoss: 0.912780\n",
      "Train Epoch: 176 [42240/50000 (84%)]\tLoss: 1.073739\n",
      "Train Epoch: 176 [43520/50000 (87%)]\tLoss: 1.046966\n",
      "Train Epoch: 176 [44800/50000 (90%)]\tLoss: 0.879094\n",
      "Train Epoch: 176 [46080/50000 (92%)]\tLoss: 0.964817\n",
      "Train Epoch: 176 [47360/50000 (95%)]\tLoss: 1.096712\n",
      "Train Epoch: 176 [48640/50000 (97%)]\tLoss: 0.971674\n",
      "Train Epoch: 176 [31200/50000 (100%)]\tLoss: 0.917063\n",
      "\n",
      "Test set: Avg. loss: 0.000339, Accuracy: 8536/9250 (92.28%)\n",
      "\n",
      "Train Epoch: 177 [0/50000 (0%)]\tLoss: 0.050424\n",
      "Train Epoch: 177 [1280/50000 (3%)]\tLoss: 0.758810\n",
      "Train Epoch: 177 [2560/50000 (5%)]\tLoss: 0.944866\n",
      "Train Epoch: 177 [3840/50000 (8%)]\tLoss: 0.919272\n",
      "Train Epoch: 177 [5120/50000 (10%)]\tLoss: 0.945497\n",
      "Train Epoch: 177 [6400/50000 (13%)]\tLoss: 1.143818\n",
      "Train Epoch: 177 [7680/50000 (15%)]\tLoss: 0.785040\n",
      "Train Epoch: 177 [8960/50000 (18%)]\tLoss: 0.914266\n",
      "Train Epoch: 177 [10240/50000 (20%)]\tLoss: 1.162638\n",
      "Train Epoch: 177 [11520/50000 (23%)]\tLoss: 1.017908\n",
      "Train Epoch: 177 [12800/50000 (26%)]\tLoss: 0.909749\n",
      "Train Epoch: 177 [14080/50000 (28%)]\tLoss: 0.898721\n",
      "Train Epoch: 177 [15360/50000 (31%)]\tLoss: 0.899325\n",
      "Train Epoch: 177 [16640/50000 (33%)]\tLoss: 0.804397\n",
      "Train Epoch: 177 [17920/50000 (36%)]\tLoss: 1.020982\n",
      "Train Epoch: 177 [19200/50000 (38%)]\tLoss: 0.971067\n",
      "Train Epoch: 177 [20480/50000 (41%)]\tLoss: 0.930095\n",
      "Train Epoch: 177 [21760/50000 (43%)]\tLoss: 0.940237\n",
      "Train Epoch: 177 [23040/50000 (46%)]\tLoss: 1.123738\n",
      "Train Epoch: 177 [24320/50000 (49%)]\tLoss: 1.020213\n",
      "Train Epoch: 177 [25600/50000 (51%)]\tLoss: 1.105030\n",
      "Train Epoch: 177 [26880/50000 (54%)]\tLoss: 1.004213\n",
      "Train Epoch: 177 [28160/50000 (56%)]\tLoss: 0.856276\n",
      "Train Epoch: 177 [29440/50000 (59%)]\tLoss: 1.120032\n",
      "Train Epoch: 177 [30720/50000 (61%)]\tLoss: 1.106716\n",
      "Train Epoch: 177 [32000/50000 (64%)]\tLoss: 0.936477\n",
      "Train Epoch: 177 [33280/50000 (66%)]\tLoss: 1.048604\n",
      "Train Epoch: 177 [34560/50000 (69%)]\tLoss: 0.888358\n",
      "Train Epoch: 177 [35840/50000 (72%)]\tLoss: 1.004805\n",
      "Train Epoch: 177 [37120/50000 (74%)]\tLoss: 0.804188\n",
      "Train Epoch: 177 [38400/50000 (77%)]\tLoss: 0.859754\n",
      "Train Epoch: 177 [39680/50000 (79%)]\tLoss: 0.764481\n",
      "Train Epoch: 177 [40960/50000 (82%)]\tLoss: 0.884313\n",
      "Train Epoch: 177 [42240/50000 (84%)]\tLoss: 1.125472\n",
      "Train Epoch: 177 [43520/50000 (87%)]\tLoss: 0.791412\n",
      "Train Epoch: 177 [44800/50000 (90%)]\tLoss: 1.108370\n",
      "Train Epoch: 177 [46080/50000 (92%)]\tLoss: 1.020988\n",
      "Train Epoch: 177 [47360/50000 (95%)]\tLoss: 1.044317\n",
      "Train Epoch: 177 [48640/50000 (97%)]\tLoss: 1.083244\n",
      "Train Epoch: 177 [31200/50000 (100%)]\tLoss: 1.012496\n",
      "\n",
      "Test set: Avg. loss: 0.000348, Accuracy: 8533/9250 (92.25%)\n",
      "\n",
      "Train Epoch: 178 [0/50000 (0%)]\tLoss: 0.089425\n",
      "Train Epoch: 178 [1280/50000 (3%)]\tLoss: 1.203637\n",
      "Train Epoch: 178 [2560/50000 (5%)]\tLoss: 1.151830\n",
      "Train Epoch: 178 [3840/50000 (8%)]\tLoss: 0.931730\n",
      "Train Epoch: 178 [5120/50000 (10%)]\tLoss: 0.801117\n",
      "Train Epoch: 178 [6400/50000 (13%)]\tLoss: 0.754515\n",
      "Train Epoch: 178 [7680/50000 (15%)]\tLoss: 1.013866\n",
      "Train Epoch: 178 [8960/50000 (18%)]\tLoss: 1.003344\n",
      "Train Epoch: 178 [10240/50000 (20%)]\tLoss: 1.159497\n",
      "Train Epoch: 178 [11520/50000 (23%)]\tLoss: 1.039129\n",
      "Train Epoch: 178 [12800/50000 (26%)]\tLoss: 1.138831\n",
      "Train Epoch: 178 [14080/50000 (28%)]\tLoss: 0.964245\n",
      "Train Epoch: 178 [15360/50000 (31%)]\tLoss: 0.777480\n",
      "Train Epoch: 178 [16640/50000 (33%)]\tLoss: 0.986685\n",
      "Train Epoch: 178 [17920/50000 (36%)]\tLoss: 1.081298\n",
      "Train Epoch: 178 [19200/50000 (38%)]\tLoss: 0.973953\n",
      "Train Epoch: 178 [20480/50000 (41%)]\tLoss: 0.986109\n",
      "Train Epoch: 178 [21760/50000 (43%)]\tLoss: 0.785916\n",
      "Train Epoch: 178 [23040/50000 (46%)]\tLoss: 1.044366\n",
      "Train Epoch: 178 [24320/50000 (49%)]\tLoss: 0.879525\n",
      "Train Epoch: 178 [25600/50000 (51%)]\tLoss: 0.939615\n",
      "Train Epoch: 178 [26880/50000 (54%)]\tLoss: 0.887225\n",
      "Train Epoch: 178 [28160/50000 (56%)]\tLoss: 0.978407\n",
      "Train Epoch: 178 [29440/50000 (59%)]\tLoss: 0.971991\n",
      "Train Epoch: 178 [30720/50000 (61%)]\tLoss: 0.965004\n",
      "Train Epoch: 178 [32000/50000 (64%)]\tLoss: 0.924725\n",
      "Train Epoch: 178 [33280/50000 (66%)]\tLoss: 0.698142\n",
      "Train Epoch: 178 [34560/50000 (69%)]\tLoss: 1.202911\n",
      "Train Epoch: 178 [35840/50000 (72%)]\tLoss: 0.917371\n",
      "Train Epoch: 178 [37120/50000 (74%)]\tLoss: 0.828002\n",
      "Train Epoch: 178 [38400/50000 (77%)]\tLoss: 0.954578\n",
      "Train Epoch: 178 [39680/50000 (79%)]\tLoss: 0.985759\n",
      "Train Epoch: 178 [40960/50000 (82%)]\tLoss: 1.013081\n",
      "Train Epoch: 178 [42240/50000 (84%)]\tLoss: 0.945333\n",
      "Train Epoch: 178 [43520/50000 (87%)]\tLoss: 0.897629\n",
      "Train Epoch: 178 [44800/50000 (90%)]\tLoss: 0.991848\n",
      "Train Epoch: 178 [46080/50000 (92%)]\tLoss: 0.914585\n",
      "Train Epoch: 178 [47360/50000 (95%)]\tLoss: 0.859547\n",
      "Train Epoch: 178 [48640/50000 (97%)]\tLoss: 1.028376\n",
      "Train Epoch: 178 [31200/50000 (100%)]\tLoss: 0.997551\n",
      "\n",
      "Test set: Avg. loss: 0.000339, Accuracy: 8541/9250 (92.34%)\n",
      "\n",
      "Train Epoch: 179 [0/50000 (0%)]\tLoss: 0.109848\n",
      "Train Epoch: 179 [1280/50000 (3%)]\tLoss: 1.043425\n",
      "Train Epoch: 179 [2560/50000 (5%)]\tLoss: 0.847254\n",
      "Train Epoch: 179 [3840/50000 (8%)]\tLoss: 0.914014\n",
      "Train Epoch: 179 [5120/50000 (10%)]\tLoss: 1.048589\n",
      "Train Epoch: 179 [6400/50000 (13%)]\tLoss: 0.970255\n",
      "Train Epoch: 179 [7680/50000 (15%)]\tLoss: 1.119936\n",
      "Train Epoch: 179 [8960/50000 (18%)]\tLoss: 1.104690\n",
      "Train Epoch: 179 [10240/50000 (20%)]\tLoss: 1.036605\n",
      "Train Epoch: 179 [11520/50000 (23%)]\tLoss: 1.111957\n",
      "Train Epoch: 179 [12800/50000 (26%)]\tLoss: 0.820773\n",
      "Train Epoch: 179 [14080/50000 (28%)]\tLoss: 1.044001\n",
      "Train Epoch: 179 [15360/50000 (31%)]\tLoss: 1.006310\n",
      "Train Epoch: 179 [16640/50000 (33%)]\tLoss: 0.810136\n",
      "Train Epoch: 179 [17920/50000 (36%)]\tLoss: 0.852850\n",
      "Train Epoch: 179 [19200/50000 (38%)]\tLoss: 0.939481\n",
      "Train Epoch: 179 [20480/50000 (41%)]\tLoss: 0.968766\n",
      "Train Epoch: 179 [21760/50000 (43%)]\tLoss: 0.933611\n",
      "Train Epoch: 179 [23040/50000 (46%)]\tLoss: 0.998920\n",
      "Train Epoch: 179 [24320/50000 (49%)]\tLoss: 1.118686\n",
      "Train Epoch: 179 [25600/50000 (51%)]\tLoss: 0.965476\n",
      "Train Epoch: 179 [26880/50000 (54%)]\tLoss: 0.903904\n",
      "Train Epoch: 179 [28160/50000 (56%)]\tLoss: 1.040971\n",
      "Train Epoch: 179 [29440/50000 (59%)]\tLoss: 1.031349\n",
      "Train Epoch: 179 [30720/50000 (61%)]\tLoss: 0.837385\n",
      "Train Epoch: 179 [32000/50000 (64%)]\tLoss: 1.063055\n",
      "Train Epoch: 179 [33280/50000 (66%)]\tLoss: 0.993856\n",
      "Train Epoch: 179 [34560/50000 (69%)]\tLoss: 1.085635\n",
      "Train Epoch: 179 [35840/50000 (72%)]\tLoss: 0.997432\n",
      "Train Epoch: 179 [37120/50000 (74%)]\tLoss: 0.992406\n",
      "Train Epoch: 179 [38400/50000 (77%)]\tLoss: 1.015038\n",
      "Train Epoch: 179 [39680/50000 (79%)]\tLoss: 1.055047\n",
      "Train Epoch: 179 [40960/50000 (82%)]\tLoss: 0.937028\n",
      "Train Epoch: 179 [42240/50000 (84%)]\tLoss: 0.925565\n",
      "Train Epoch: 179 [43520/50000 (87%)]\tLoss: 1.022726\n",
      "Train Epoch: 179 [44800/50000 (90%)]\tLoss: 0.851264\n",
      "Train Epoch: 179 [46080/50000 (92%)]\tLoss: 1.026974\n",
      "Train Epoch: 179 [47360/50000 (95%)]\tLoss: 0.848577\n",
      "Train Epoch: 179 [48640/50000 (97%)]\tLoss: 0.983597\n",
      "Train Epoch: 179 [31200/50000 (100%)]\tLoss: 0.860067\n",
      "\n",
      "Test set: Avg. loss: 0.000332, Accuracy: 8529/9250 (92.21%)\n",
      "\n",
      "Train Epoch: 180 [0/50000 (0%)]\tLoss: 0.110989\n",
      "Train Epoch: 180 [1280/50000 (3%)]\tLoss: 0.847188\n",
      "Train Epoch: 180 [2560/50000 (5%)]\tLoss: 0.908097\n",
      "Train Epoch: 180 [3840/50000 (8%)]\tLoss: 0.899504\n",
      "Train Epoch: 180 [5120/50000 (10%)]\tLoss: 1.045942\n",
      "Train Epoch: 180 [6400/50000 (13%)]\tLoss: 0.818667\n",
      "Train Epoch: 180 [7680/50000 (15%)]\tLoss: 1.054272\n",
      "Train Epoch: 180 [8960/50000 (18%)]\tLoss: 1.026190\n",
      "Train Epoch: 180 [10240/50000 (20%)]\tLoss: 0.946833\n",
      "Train Epoch: 180 [11520/50000 (23%)]\tLoss: 0.821458\n",
      "Train Epoch: 180 [12800/50000 (26%)]\tLoss: 1.094967\n",
      "Train Epoch: 180 [14080/50000 (28%)]\tLoss: 0.853030\n",
      "Train Epoch: 180 [15360/50000 (31%)]\tLoss: 0.857393\n",
      "Train Epoch: 180 [16640/50000 (33%)]\tLoss: 1.196479\n",
      "Train Epoch: 180 [17920/50000 (36%)]\tLoss: 1.004653\n",
      "Train Epoch: 180 [19200/50000 (38%)]\tLoss: 0.834459\n",
      "Train Epoch: 180 [20480/50000 (41%)]\tLoss: 1.059975\n",
      "Train Epoch: 180 [21760/50000 (43%)]\tLoss: 1.031130\n",
      "Train Epoch: 180 [23040/50000 (46%)]\tLoss: 0.791877\n",
      "Train Epoch: 180 [24320/50000 (49%)]\tLoss: 0.981236\n",
      "Train Epoch: 180 [25600/50000 (51%)]\tLoss: 1.058744\n",
      "Train Epoch: 180 [26880/50000 (54%)]\tLoss: 0.897007\n",
      "Train Epoch: 180 [28160/50000 (56%)]\tLoss: 0.837989\n",
      "Train Epoch: 180 [29440/50000 (59%)]\tLoss: 0.969365\n",
      "Train Epoch: 180 [30720/50000 (61%)]\tLoss: 0.722313\n",
      "Train Epoch: 180 [32000/50000 (64%)]\tLoss: 0.989487\n",
      "Train Epoch: 180 [33280/50000 (66%)]\tLoss: 0.862811\n",
      "Train Epoch: 180 [34560/50000 (69%)]\tLoss: 0.843211\n",
      "Train Epoch: 180 [35840/50000 (72%)]\tLoss: 1.047183\n",
      "Train Epoch: 180 [37120/50000 (74%)]\tLoss: 0.943941\n",
      "Train Epoch: 180 [38400/50000 (77%)]\tLoss: 1.018898\n",
      "Train Epoch: 180 [39680/50000 (79%)]\tLoss: 0.831749\n",
      "Train Epoch: 180 [40960/50000 (82%)]\tLoss: 1.196525\n",
      "Train Epoch: 180 [42240/50000 (84%)]\tLoss: 0.990342\n",
      "Train Epoch: 180 [43520/50000 (87%)]\tLoss: 0.982973\n",
      "Train Epoch: 180 [44800/50000 (90%)]\tLoss: 1.050023\n",
      "Train Epoch: 180 [46080/50000 (92%)]\tLoss: 0.988876\n",
      "Train Epoch: 180 [47360/50000 (95%)]\tLoss: 1.014893\n",
      "Train Epoch: 180 [48640/50000 (97%)]\tLoss: 1.016872\n",
      "Train Epoch: 180 [31200/50000 (100%)]\tLoss: 0.942851\n",
      "\n",
      "Test set: Avg. loss: 0.000333, Accuracy: 8554/9250 (92.48%)\n",
      "\n",
      "Train Epoch: 181 [0/50000 (0%)]\tLoss: 0.132540\n",
      "Train Epoch: 181 [1280/50000 (3%)]\tLoss: 1.059517\n",
      "Train Epoch: 181 [2560/50000 (5%)]\tLoss: 0.903830\n",
      "Train Epoch: 181 [3840/50000 (8%)]\tLoss: 0.847353\n",
      "Train Epoch: 181 [5120/50000 (10%)]\tLoss: 0.788530\n",
      "Train Epoch: 181 [6400/50000 (13%)]\tLoss: 1.000801\n",
      "Train Epoch: 181 [7680/50000 (15%)]\tLoss: 1.109955\n",
      "Train Epoch: 181 [8960/50000 (18%)]\tLoss: 1.125022\n",
      "Train Epoch: 181 [10240/50000 (20%)]\tLoss: 0.946327\n",
      "Train Epoch: 181 [11520/50000 (23%)]\tLoss: 0.966980\n",
      "Train Epoch: 181 [12800/50000 (26%)]\tLoss: 0.939315\n",
      "Train Epoch: 181 [14080/50000 (28%)]\tLoss: 0.837823\n",
      "Train Epoch: 181 [15360/50000 (31%)]\tLoss: 1.042324\n",
      "Train Epoch: 181 [16640/50000 (33%)]\tLoss: 0.975381\n",
      "Train Epoch: 181 [17920/50000 (36%)]\tLoss: 1.075579\n",
      "Train Epoch: 181 [19200/50000 (38%)]\tLoss: 1.064212\n",
      "Train Epoch: 181 [20480/50000 (41%)]\tLoss: 1.009192\n",
      "Train Epoch: 181 [21760/50000 (43%)]\tLoss: 1.024085\n",
      "Train Epoch: 181 [23040/50000 (46%)]\tLoss: 0.957727\n",
      "Train Epoch: 181 [24320/50000 (49%)]\tLoss: 0.981896\n",
      "Train Epoch: 181 [25600/50000 (51%)]\tLoss: 1.114497\n",
      "Train Epoch: 181 [26880/50000 (54%)]\tLoss: 0.822055\n",
      "Train Epoch: 181 [28160/50000 (56%)]\tLoss: 1.106511\n",
      "Train Epoch: 181 [29440/50000 (59%)]\tLoss: 1.117482\n",
      "Train Epoch: 181 [30720/50000 (61%)]\tLoss: 1.000910\n",
      "Train Epoch: 181 [32000/50000 (64%)]\tLoss: 1.106905\n",
      "Train Epoch: 181 [33280/50000 (66%)]\tLoss: 0.889487\n",
      "Train Epoch: 181 [34560/50000 (69%)]\tLoss: 0.905322\n",
      "Train Epoch: 181 [35840/50000 (72%)]\tLoss: 0.934431\n",
      "Train Epoch: 181 [37120/50000 (74%)]\tLoss: 0.837399\n",
      "Train Epoch: 181 [38400/50000 (77%)]\tLoss: 0.943582\n",
      "Train Epoch: 181 [39680/50000 (79%)]\tLoss: 0.938719\n",
      "Train Epoch: 181 [40960/50000 (82%)]\tLoss: 0.915946\n",
      "Train Epoch: 181 [42240/50000 (84%)]\tLoss: 0.991787\n",
      "Train Epoch: 181 [43520/50000 (87%)]\tLoss: 1.108298\n",
      "Train Epoch: 181 [44800/50000 (90%)]\tLoss: 0.933987\n",
      "Train Epoch: 181 [46080/50000 (92%)]\tLoss: 0.974765\n",
      "Train Epoch: 181 [47360/50000 (95%)]\tLoss: 0.775180\n",
      "Train Epoch: 181 [48640/50000 (97%)]\tLoss: 0.932590\n",
      "Train Epoch: 181 [31200/50000 (100%)]\tLoss: 1.089818\n",
      "\n",
      "Test set: Avg. loss: 0.000330, Accuracy: 8539/9250 (92.31%)\n",
      "\n",
      "Train Epoch: 182 [0/50000 (0%)]\tLoss: 0.052694\n",
      "Train Epoch: 182 [1280/50000 (3%)]\tLoss: 1.131617\n",
      "Train Epoch: 182 [2560/50000 (5%)]\tLoss: 1.060835\n",
      "Train Epoch: 182 [3840/50000 (8%)]\tLoss: 0.926079\n",
      "Train Epoch: 182 [5120/50000 (10%)]\tLoss: 0.776133\n",
      "Train Epoch: 182 [6400/50000 (13%)]\tLoss: 0.958111\n",
      "Train Epoch: 182 [7680/50000 (15%)]\tLoss: 0.847054\n",
      "Train Epoch: 182 [8960/50000 (18%)]\tLoss: 1.007272\n",
      "Train Epoch: 182 [10240/50000 (20%)]\tLoss: 0.854140\n",
      "Train Epoch: 182 [11520/50000 (23%)]\tLoss: 1.171190\n",
      "Train Epoch: 182 [12800/50000 (26%)]\tLoss: 0.772003\n",
      "Train Epoch: 182 [14080/50000 (28%)]\tLoss: 0.719022\n",
      "Train Epoch: 182 [15360/50000 (31%)]\tLoss: 1.045249\n",
      "Train Epoch: 182 [16640/50000 (33%)]\tLoss: 0.966776\n",
      "Train Epoch: 182 [17920/50000 (36%)]\tLoss: 1.051828\n",
      "Train Epoch: 182 [19200/50000 (38%)]\tLoss: 1.091598\n",
      "Train Epoch: 182 [20480/50000 (41%)]\tLoss: 1.022434\n",
      "Train Epoch: 182 [21760/50000 (43%)]\tLoss: 0.896587\n",
      "Train Epoch: 182 [23040/50000 (46%)]\tLoss: 0.862204\n",
      "Train Epoch: 182 [24320/50000 (49%)]\tLoss: 0.763738\n",
      "Train Epoch: 182 [25600/50000 (51%)]\tLoss: 0.950302\n",
      "Train Epoch: 182 [26880/50000 (54%)]\tLoss: 0.907599\n",
      "Train Epoch: 182 [28160/50000 (56%)]\tLoss: 0.989412\n",
      "Train Epoch: 182 [29440/50000 (59%)]\tLoss: 0.911684\n",
      "Train Epoch: 182 [30720/50000 (61%)]\tLoss: 1.080905\n",
      "Train Epoch: 182 [32000/50000 (64%)]\tLoss: 1.015489\n",
      "Train Epoch: 182 [33280/50000 (66%)]\tLoss: 0.983309\n",
      "Train Epoch: 182 [34560/50000 (69%)]\tLoss: 1.030287\n",
      "Train Epoch: 182 [35840/50000 (72%)]\tLoss: 1.191671\n",
      "Train Epoch: 182 [37120/50000 (74%)]\tLoss: 0.998237\n",
      "Train Epoch: 182 [38400/50000 (77%)]\tLoss: 0.813848\n",
      "Train Epoch: 182 [39680/50000 (79%)]\tLoss: 1.047351\n",
      "Train Epoch: 182 [40960/50000 (82%)]\tLoss: 0.863066\n",
      "Train Epoch: 182 [42240/50000 (84%)]\tLoss: 0.974639\n",
      "Train Epoch: 182 [43520/50000 (87%)]\tLoss: 0.994628\n",
      "Train Epoch: 182 [44800/50000 (90%)]\tLoss: 1.006186\n",
      "Train Epoch: 182 [46080/50000 (92%)]\tLoss: 1.166057\n",
      "Train Epoch: 182 [47360/50000 (95%)]\tLoss: 1.031421\n",
      "Train Epoch: 182 [48640/50000 (97%)]\tLoss: 0.849840\n",
      "Train Epoch: 182 [31200/50000 (100%)]\tLoss: 1.207834\n",
      "\n",
      "Test set: Avg. loss: 0.000337, Accuracy: 8545/9250 (92.38%)\n",
      "\n",
      "Train Epoch: 183 [0/50000 (0%)]\tLoss: 0.111112\n",
      "Train Epoch: 183 [1280/50000 (3%)]\tLoss: 1.110801\n",
      "Train Epoch: 183 [2560/50000 (5%)]\tLoss: 0.667300\n",
      "Train Epoch: 183 [3840/50000 (8%)]\tLoss: 1.058971\n",
      "Train Epoch: 183 [5120/50000 (10%)]\tLoss: 1.054531\n",
      "Train Epoch: 183 [6400/50000 (13%)]\tLoss: 1.055947\n",
      "Train Epoch: 183 [7680/50000 (15%)]\tLoss: 0.904008\n",
      "Train Epoch: 183 [8960/50000 (18%)]\tLoss: 0.924692\n",
      "Train Epoch: 183 [10240/50000 (20%)]\tLoss: 0.936936\n",
      "Train Epoch: 183 [11520/50000 (23%)]\tLoss: 0.925500\n",
      "Train Epoch: 183 [12800/50000 (26%)]\tLoss: 0.995508\n",
      "Train Epoch: 183 [14080/50000 (28%)]\tLoss: 0.907245\n",
      "Train Epoch: 183 [15360/50000 (31%)]\tLoss: 1.002631\n",
      "Train Epoch: 183 [16640/50000 (33%)]\tLoss: 1.039630\n",
      "Train Epoch: 183 [17920/50000 (36%)]\tLoss: 1.188790\n",
      "Train Epoch: 183 [19200/50000 (38%)]\tLoss: 0.956438\n",
      "Train Epoch: 183 [20480/50000 (41%)]\tLoss: 1.172962\n",
      "Train Epoch: 183 [21760/50000 (43%)]\tLoss: 0.836023\n",
      "Train Epoch: 183 [23040/50000 (46%)]\tLoss: 0.699859\n",
      "Train Epoch: 183 [24320/50000 (49%)]\tLoss: 0.921244\n",
      "Train Epoch: 183 [25600/50000 (51%)]\tLoss: 1.013053\n",
      "Train Epoch: 183 [26880/50000 (54%)]\tLoss: 0.849130\n",
      "Train Epoch: 183 [28160/50000 (56%)]\tLoss: 0.934780\n",
      "Train Epoch: 183 [29440/50000 (59%)]\tLoss: 0.977653\n",
      "Train Epoch: 183 [30720/50000 (61%)]\tLoss: 0.959869\n",
      "Train Epoch: 183 [32000/50000 (64%)]\tLoss: 0.973372\n",
      "Train Epoch: 183 [33280/50000 (66%)]\tLoss: 0.956670\n",
      "Train Epoch: 183 [34560/50000 (69%)]\tLoss: 1.164105\n",
      "Train Epoch: 183 [35840/50000 (72%)]\tLoss: 0.972967\n",
      "Train Epoch: 183 [37120/50000 (74%)]\tLoss: 1.079377\n",
      "Train Epoch: 183 [38400/50000 (77%)]\tLoss: 0.920952\n",
      "Train Epoch: 183 [39680/50000 (79%)]\tLoss: 0.890856\n",
      "Train Epoch: 183 [40960/50000 (82%)]\tLoss: 0.988459\n",
      "Train Epoch: 183 [42240/50000 (84%)]\tLoss: 0.869360\n",
      "Train Epoch: 183 [43520/50000 (87%)]\tLoss: 0.912759\n",
      "Train Epoch: 183 [44800/50000 (90%)]\tLoss: 1.044525\n",
      "Train Epoch: 183 [46080/50000 (92%)]\tLoss: 0.874366\n",
      "Train Epoch: 183 [47360/50000 (95%)]\tLoss: 1.263410\n",
      "Train Epoch: 183 [48640/50000 (97%)]\tLoss: 0.953904\n",
      "Train Epoch: 183 [31200/50000 (100%)]\tLoss: 0.956345\n",
      "\n",
      "Test set: Avg. loss: 0.000334, Accuracy: 8550/9250 (92.43%)\n",
      "\n",
      "Train Epoch: 184 [0/50000 (0%)]\tLoss: 0.131517\n",
      "Train Epoch: 184 [1280/50000 (3%)]\tLoss: 1.105083\n",
      "Train Epoch: 184 [2560/50000 (5%)]\tLoss: 0.942960\n",
      "Train Epoch: 184 [3840/50000 (8%)]\tLoss: 0.930797\n",
      "Train Epoch: 184 [5120/50000 (10%)]\tLoss: 0.930490\n",
      "Train Epoch: 184 [6400/50000 (13%)]\tLoss: 1.012193\n",
      "Train Epoch: 184 [7680/50000 (15%)]\tLoss: 0.945212\n",
      "Train Epoch: 184 [8960/50000 (18%)]\tLoss: 0.894168\n",
      "Train Epoch: 184 [10240/50000 (20%)]\tLoss: 0.963870\n",
      "Train Epoch: 184 [11520/50000 (23%)]\tLoss: 1.049633\n",
      "Train Epoch: 184 [12800/50000 (26%)]\tLoss: 0.938950\n",
      "Train Epoch: 184 [14080/50000 (28%)]\tLoss: 1.163721\n",
      "Train Epoch: 184 [15360/50000 (31%)]\tLoss: 0.731900\n",
      "Train Epoch: 184 [16640/50000 (33%)]\tLoss: 0.918128\n",
      "Train Epoch: 184 [17920/50000 (36%)]\tLoss: 0.804137\n",
      "Train Epoch: 184 [19200/50000 (38%)]\tLoss: 0.940383\n",
      "Train Epoch: 184 [20480/50000 (41%)]\tLoss: 0.870070\n",
      "Train Epoch: 184 [21760/50000 (43%)]\tLoss: 0.944549\n",
      "Train Epoch: 184 [23040/50000 (46%)]\tLoss: 0.888690\n",
      "Train Epoch: 184 [24320/50000 (49%)]\tLoss: 0.756964\n",
      "Train Epoch: 184 [25600/50000 (51%)]\tLoss: 1.109041\n",
      "Train Epoch: 184 [26880/50000 (54%)]\tLoss: 1.034845\n",
      "Train Epoch: 184 [28160/50000 (56%)]\tLoss: 0.904163\n",
      "Train Epoch: 184 [29440/50000 (59%)]\tLoss: 0.846910\n",
      "Train Epoch: 184 [30720/50000 (61%)]\tLoss: 0.765284\n",
      "Train Epoch: 184 [32000/50000 (64%)]\tLoss: 1.085864\n",
      "Train Epoch: 184 [33280/50000 (66%)]\tLoss: 0.981633\n",
      "Train Epoch: 184 [34560/50000 (69%)]\tLoss: 1.194223\n",
      "Train Epoch: 184 [35840/50000 (72%)]\tLoss: 0.953395\n",
      "Train Epoch: 184 [37120/50000 (74%)]\tLoss: 1.122864\n",
      "Train Epoch: 184 [38400/50000 (77%)]\tLoss: 0.893419\n",
      "Train Epoch: 184 [39680/50000 (79%)]\tLoss: 0.994444\n",
      "Train Epoch: 184 [40960/50000 (82%)]\tLoss: 0.900856\n",
      "Train Epoch: 184 [42240/50000 (84%)]\tLoss: 0.883578\n",
      "Train Epoch: 184 [43520/50000 (87%)]\tLoss: 1.022216\n",
      "Train Epoch: 184 [44800/50000 (90%)]\tLoss: 0.692776\n",
      "Train Epoch: 184 [46080/50000 (92%)]\tLoss: 1.060852\n",
      "Train Epoch: 184 [47360/50000 (95%)]\tLoss: 0.958790\n",
      "Train Epoch: 184 [48640/50000 (97%)]\tLoss: 0.837407\n",
      "Train Epoch: 184 [31200/50000 (100%)]\tLoss: 0.872862\n",
      "\n",
      "Test set: Avg. loss: 0.000328, Accuracy: 8538/9250 (92.30%)\n",
      "\n",
      "Train Epoch: 185 [0/50000 (0%)]\tLoss: 0.083759\n",
      "Train Epoch: 185 [1280/50000 (3%)]\tLoss: 1.086399\n",
      "Train Epoch: 185 [2560/50000 (5%)]\tLoss: 0.925911\n",
      "Train Epoch: 185 [3840/50000 (8%)]\tLoss: 1.036364\n",
      "Train Epoch: 185 [5120/50000 (10%)]\tLoss: 0.875513\n",
      "Train Epoch: 185 [6400/50000 (13%)]\tLoss: 1.077161\n",
      "Train Epoch: 185 [7680/50000 (15%)]\tLoss: 1.005145\n",
      "Train Epoch: 185 [8960/50000 (18%)]\tLoss: 0.847654\n",
      "Train Epoch: 185 [10240/50000 (20%)]\tLoss: 0.719597\n",
      "Train Epoch: 185 [11520/50000 (23%)]\tLoss: 0.974309\n",
      "Train Epoch: 185 [12800/50000 (26%)]\tLoss: 0.958886\n",
      "Train Epoch: 185 [14080/50000 (28%)]\tLoss: 0.879442\n",
      "Train Epoch: 185 [15360/50000 (31%)]\tLoss: 1.040226\n",
      "Train Epoch: 185 [16640/50000 (33%)]\tLoss: 0.975188\n",
      "Train Epoch: 185 [17920/50000 (36%)]\tLoss: 0.892873\n",
      "Train Epoch: 185 [19200/50000 (38%)]\tLoss: 0.997997\n",
      "Train Epoch: 185 [20480/50000 (41%)]\tLoss: 0.935362\n",
      "Train Epoch: 185 [21760/50000 (43%)]\tLoss: 1.015671\n",
      "Train Epoch: 185 [23040/50000 (46%)]\tLoss: 0.873939\n",
      "Train Epoch: 185 [24320/50000 (49%)]\tLoss: 0.834184\n",
      "Train Epoch: 185 [25600/50000 (51%)]\tLoss: 0.850212\n",
      "Train Epoch: 185 [26880/50000 (54%)]\tLoss: 1.130315\n",
      "Train Epoch: 185 [28160/50000 (56%)]\tLoss: 1.038410\n",
      "Train Epoch: 185 [29440/50000 (59%)]\tLoss: 0.804598\n",
      "Train Epoch: 185 [30720/50000 (61%)]\tLoss: 1.036960\n",
      "Train Epoch: 185 [32000/50000 (64%)]\tLoss: 1.042859\n",
      "Train Epoch: 185 [33280/50000 (66%)]\tLoss: 0.794377\n",
      "Train Epoch: 185 [34560/50000 (69%)]\tLoss: 0.891684\n",
      "Train Epoch: 185 [35840/50000 (72%)]\tLoss: 0.971781\n",
      "Train Epoch: 185 [37120/50000 (74%)]\tLoss: 1.088134\n",
      "Train Epoch: 185 [38400/50000 (77%)]\tLoss: 0.924976\n",
      "Train Epoch: 185 [39680/50000 (79%)]\tLoss: 0.876629\n",
      "Train Epoch: 185 [40960/50000 (82%)]\tLoss: 0.841284\n",
      "Train Epoch: 185 [42240/50000 (84%)]\tLoss: 1.064230\n",
      "Train Epoch: 185 [43520/50000 (87%)]\tLoss: 0.932782\n",
      "Train Epoch: 185 [44800/50000 (90%)]\tLoss: 0.791954\n",
      "Train Epoch: 185 [46080/50000 (92%)]\tLoss: 1.004884\n",
      "Train Epoch: 185 [47360/50000 (95%)]\tLoss: 0.926090\n",
      "Train Epoch: 185 [48640/50000 (97%)]\tLoss: 0.942251\n",
      "Train Epoch: 185 [31200/50000 (100%)]\tLoss: 1.094092\n",
      "\n",
      "Test set: Avg. loss: 0.000335, Accuracy: 8518/9250 (92.09%)\n",
      "\n",
      "Train Epoch: 186 [0/50000 (0%)]\tLoss: 0.130255\n",
      "Train Epoch: 186 [1280/50000 (3%)]\tLoss: 1.054995\n",
      "Train Epoch: 186 [2560/50000 (5%)]\tLoss: 0.969263\n",
      "Train Epoch: 186 [3840/50000 (8%)]\tLoss: 1.110461\n",
      "Train Epoch: 186 [5120/50000 (10%)]\tLoss: 0.828465\n",
      "Train Epoch: 186 [6400/50000 (13%)]\tLoss: 0.947256\n",
      "Train Epoch: 186 [7680/50000 (15%)]\tLoss: 0.708934\n",
      "Train Epoch: 186 [8960/50000 (18%)]\tLoss: 0.981887\n",
      "Train Epoch: 186 [10240/50000 (20%)]\tLoss: 0.922038\n",
      "Train Epoch: 186 [11520/50000 (23%)]\tLoss: 0.844124\n",
      "Train Epoch: 186 [12800/50000 (26%)]\tLoss: 1.042843\n",
      "Train Epoch: 186 [14080/50000 (28%)]\tLoss: 0.980897\n",
      "Train Epoch: 186 [15360/50000 (31%)]\tLoss: 1.000630\n",
      "Train Epoch: 186 [16640/50000 (33%)]\tLoss: 0.962486\n",
      "Train Epoch: 186 [17920/50000 (36%)]\tLoss: 0.778816\n",
      "Train Epoch: 186 [19200/50000 (38%)]\tLoss: 0.836209\n",
      "Train Epoch: 186 [20480/50000 (41%)]\tLoss: 0.878507\n",
      "Train Epoch: 186 [21760/50000 (43%)]\tLoss: 0.917462\n",
      "Train Epoch: 186 [23040/50000 (46%)]\tLoss: 0.850297\n",
      "Train Epoch: 186 [24320/50000 (49%)]\tLoss: 0.988337\n",
      "Train Epoch: 186 [25600/50000 (51%)]\tLoss: 0.852549\n",
      "Train Epoch: 186 [26880/50000 (54%)]\tLoss: 0.964493\n",
      "Train Epoch: 186 [28160/50000 (56%)]\tLoss: 0.836024\n",
      "Train Epoch: 186 [29440/50000 (59%)]\tLoss: 0.817244\n",
      "Train Epoch: 186 [30720/50000 (61%)]\tLoss: 1.145566\n",
      "Train Epoch: 186 [32000/50000 (64%)]\tLoss: 0.860807\n",
      "Train Epoch: 186 [33280/50000 (66%)]\tLoss: 0.753447\n",
      "Train Epoch: 186 [34560/50000 (69%)]\tLoss: 1.007298\n",
      "Train Epoch: 186 [35840/50000 (72%)]\tLoss: 1.013928\n",
      "Train Epoch: 186 [37120/50000 (74%)]\tLoss: 1.037807\n",
      "Train Epoch: 186 [38400/50000 (77%)]\tLoss: 1.012953\n",
      "Train Epoch: 186 [39680/50000 (79%)]\tLoss: 1.016430\n",
      "Train Epoch: 186 [40960/50000 (82%)]\tLoss: 0.891559\n",
      "Train Epoch: 186 [42240/50000 (84%)]\tLoss: 0.932037\n",
      "Train Epoch: 186 [43520/50000 (87%)]\tLoss: 0.853188\n",
      "Train Epoch: 186 [44800/50000 (90%)]\tLoss: 0.942563\n",
      "Train Epoch: 186 [46080/50000 (92%)]\tLoss: 1.028265\n",
      "Train Epoch: 186 [47360/50000 (95%)]\tLoss: 0.897979\n",
      "Train Epoch: 186 [48640/50000 (97%)]\tLoss: 0.976855\n",
      "Train Epoch: 186 [31200/50000 (100%)]\tLoss: 1.023888\n",
      "\n",
      "Test set: Avg. loss: 0.000335, Accuracy: 8541/9250 (92.34%)\n",
      "\n",
      "Train Epoch: 187 [0/50000 (0%)]\tLoss: 0.125110\n",
      "Train Epoch: 187 [1280/50000 (3%)]\tLoss: 0.955068\n",
      "Train Epoch: 187 [2560/50000 (5%)]\tLoss: 0.933985\n",
      "Train Epoch: 187 [3840/50000 (8%)]\tLoss: 0.942928\n",
      "Train Epoch: 187 [5120/50000 (10%)]\tLoss: 1.060728\n",
      "Train Epoch: 187 [6400/50000 (13%)]\tLoss: 1.175973\n",
      "Train Epoch: 187 [7680/50000 (15%)]\tLoss: 0.926346\n",
      "Train Epoch: 187 [8960/50000 (18%)]\tLoss: 0.832736\n",
      "Train Epoch: 187 [10240/50000 (20%)]\tLoss: 0.987871\n",
      "Train Epoch: 187 [11520/50000 (23%)]\tLoss: 0.810573\n",
      "Train Epoch: 187 [12800/50000 (26%)]\tLoss: 0.907130\n",
      "Train Epoch: 187 [14080/50000 (28%)]\tLoss: 1.080045\n",
      "Train Epoch: 187 [15360/50000 (31%)]\tLoss: 0.949815\n",
      "Train Epoch: 187 [16640/50000 (33%)]\tLoss: 0.833874\n",
      "Train Epoch: 187 [17920/50000 (36%)]\tLoss: 0.981740\n",
      "Train Epoch: 187 [19200/50000 (38%)]\tLoss: 0.825062\n",
      "Train Epoch: 187 [20480/50000 (41%)]\tLoss: 0.858081\n",
      "Train Epoch: 187 [21760/50000 (43%)]\tLoss: 1.038153\n",
      "Train Epoch: 187 [23040/50000 (46%)]\tLoss: 1.068753\n",
      "Train Epoch: 187 [24320/50000 (49%)]\tLoss: 1.001838\n",
      "Train Epoch: 187 [25600/50000 (51%)]\tLoss: 1.186507\n",
      "Train Epoch: 187 [26880/50000 (54%)]\tLoss: 0.966935\n",
      "Train Epoch: 187 [28160/50000 (56%)]\tLoss: 0.954400\n",
      "Train Epoch: 187 [29440/50000 (59%)]\tLoss: 0.990234\n",
      "Train Epoch: 187 [30720/50000 (61%)]\tLoss: 0.812744\n",
      "Train Epoch: 187 [32000/50000 (64%)]\tLoss: 0.959699\n",
      "Train Epoch: 187 [33280/50000 (66%)]\tLoss: 1.062918\n",
      "Train Epoch: 187 [34560/50000 (69%)]\tLoss: 0.955410\n",
      "Train Epoch: 187 [35840/50000 (72%)]\tLoss: 1.022144\n",
      "Train Epoch: 187 [37120/50000 (74%)]\tLoss: 0.921581\n",
      "Train Epoch: 187 [38400/50000 (77%)]\tLoss: 0.648800\n",
      "Train Epoch: 187 [39680/50000 (79%)]\tLoss: 0.868168\n",
      "Train Epoch: 187 [40960/50000 (82%)]\tLoss: 0.861342\n",
      "Train Epoch: 187 [42240/50000 (84%)]\tLoss: 0.970804\n",
      "Train Epoch: 187 [43520/50000 (87%)]\tLoss: 0.967901\n",
      "Train Epoch: 187 [44800/50000 (90%)]\tLoss: 1.034835\n",
      "Train Epoch: 187 [46080/50000 (92%)]\tLoss: 1.069011\n",
      "Train Epoch: 187 [47360/50000 (95%)]\tLoss: 0.909774\n",
      "Train Epoch: 187 [48640/50000 (97%)]\tLoss: 0.840535\n",
      "Train Epoch: 187 [31200/50000 (100%)]\tLoss: 0.978137\n",
      "\n",
      "Test set: Avg. loss: 0.000325, Accuracy: 8538/9250 (92.30%)\n",
      "\n",
      "Train Epoch: 188 [0/50000 (0%)]\tLoss: 0.123374\n",
      "Train Epoch: 188 [1280/50000 (3%)]\tLoss: 0.967046\n",
      "Train Epoch: 188 [2560/50000 (5%)]\tLoss: 0.985223\n",
      "Train Epoch: 188 [3840/50000 (8%)]\tLoss: 0.907552\n",
      "Train Epoch: 188 [5120/50000 (10%)]\tLoss: 0.970219\n",
      "Train Epoch: 188 [6400/50000 (13%)]\tLoss: 0.898360\n",
      "Train Epoch: 188 [7680/50000 (15%)]\tLoss: 0.968113\n",
      "Train Epoch: 188 [8960/50000 (18%)]\tLoss: 0.837710\n",
      "Train Epoch: 188 [10240/50000 (20%)]\tLoss: 0.834796\n",
      "Train Epoch: 188 [11520/50000 (23%)]\tLoss: 0.975013\n",
      "Train Epoch: 188 [12800/50000 (26%)]\tLoss: 0.892118\n",
      "Train Epoch: 188 [14080/50000 (28%)]\tLoss: 0.934288\n",
      "Train Epoch: 188 [15360/50000 (31%)]\tLoss: 1.060185\n",
      "Train Epoch: 188 [16640/50000 (33%)]\tLoss: 0.949842\n",
      "Train Epoch: 188 [17920/50000 (36%)]\tLoss: 1.111738\n",
      "Train Epoch: 188 [19200/50000 (38%)]\tLoss: 0.985044\n",
      "Train Epoch: 188 [20480/50000 (41%)]\tLoss: 0.848285\n",
      "Train Epoch: 188 [21760/50000 (43%)]\tLoss: 0.927706\n",
      "Train Epoch: 188 [23040/50000 (46%)]\tLoss: 0.923751\n",
      "Train Epoch: 188 [24320/50000 (49%)]\tLoss: 1.004322\n",
      "Train Epoch: 188 [25600/50000 (51%)]\tLoss: 0.935197\n",
      "Train Epoch: 188 [26880/50000 (54%)]\tLoss: 0.979671\n",
      "Train Epoch: 188 [28160/50000 (56%)]\tLoss: 0.932110\n",
      "Train Epoch: 188 [29440/50000 (59%)]\tLoss: 1.025009\n",
      "Train Epoch: 188 [30720/50000 (61%)]\tLoss: 0.985322\n",
      "Train Epoch: 188 [32000/50000 (64%)]\tLoss: 0.985775\n",
      "Train Epoch: 188 [33280/50000 (66%)]\tLoss: 1.121729\n",
      "Train Epoch: 188 [34560/50000 (69%)]\tLoss: 0.989129\n",
      "Train Epoch: 188 [35840/50000 (72%)]\tLoss: 1.028699\n",
      "Train Epoch: 188 [37120/50000 (74%)]\tLoss: 0.937226\n",
      "Train Epoch: 188 [38400/50000 (77%)]\tLoss: 1.098127\n",
      "Train Epoch: 188 [39680/50000 (79%)]\tLoss: 0.772114\n",
      "Train Epoch: 188 [40960/50000 (82%)]\tLoss: 0.991541\n",
      "Train Epoch: 188 [42240/50000 (84%)]\tLoss: 0.840483\n",
      "Train Epoch: 188 [43520/50000 (87%)]\tLoss: 1.050231\n",
      "Train Epoch: 188 [44800/50000 (90%)]\tLoss: 1.056843\n",
      "Train Epoch: 188 [46080/50000 (92%)]\tLoss: 0.983132\n",
      "Train Epoch: 188 [47360/50000 (95%)]\tLoss: 0.907537\n",
      "Train Epoch: 188 [48640/50000 (97%)]\tLoss: 1.025230\n",
      "Train Epoch: 188 [31200/50000 (100%)]\tLoss: 0.873779\n",
      "\n",
      "Test set: Avg. loss: 0.000331, Accuracy: 8549/9250 (92.42%)\n",
      "\n",
      "Train Epoch: 189 [0/50000 (0%)]\tLoss: 0.081135\n",
      "Train Epoch: 189 [1280/50000 (3%)]\tLoss: 0.927348\n",
      "Train Epoch: 189 [2560/50000 (5%)]\tLoss: 1.030687\n",
      "Train Epoch: 189 [3840/50000 (8%)]\tLoss: 0.864165\n",
      "Train Epoch: 189 [5120/50000 (10%)]\tLoss: 1.094842\n",
      "Train Epoch: 189 [6400/50000 (13%)]\tLoss: 0.970709\n",
      "Train Epoch: 189 [7680/50000 (15%)]\tLoss: 0.931043\n",
      "Train Epoch: 189 [8960/50000 (18%)]\tLoss: 0.999320\n",
      "Train Epoch: 189 [10240/50000 (20%)]\tLoss: 0.913838\n",
      "Train Epoch: 189 [11520/50000 (23%)]\tLoss: 0.876362\n",
      "Train Epoch: 189 [12800/50000 (26%)]\tLoss: 1.115312\n",
      "Train Epoch: 189 [14080/50000 (28%)]\tLoss: 0.934635\n",
      "Train Epoch: 189 [15360/50000 (31%)]\tLoss: 0.760687\n",
      "Train Epoch: 189 [16640/50000 (33%)]\tLoss: 1.108427\n",
      "Train Epoch: 189 [17920/50000 (36%)]\tLoss: 0.759702\n",
      "Train Epoch: 189 [19200/50000 (38%)]\tLoss: 0.978808\n",
      "Train Epoch: 189 [20480/50000 (41%)]\tLoss: 0.936363\n",
      "Train Epoch: 189 [21760/50000 (43%)]\tLoss: 0.998676\n",
      "Train Epoch: 189 [23040/50000 (46%)]\tLoss: 1.086380\n",
      "Train Epoch: 189 [24320/50000 (49%)]\tLoss: 1.004559\n",
      "Train Epoch: 189 [25600/50000 (51%)]\tLoss: 0.814284\n",
      "Train Epoch: 189 [26880/50000 (54%)]\tLoss: 1.078668\n",
      "Train Epoch: 189 [28160/50000 (56%)]\tLoss: 0.734155\n",
      "Train Epoch: 189 [29440/50000 (59%)]\tLoss: 0.879792\n",
      "Train Epoch: 189 [30720/50000 (61%)]\tLoss: 0.917009\n",
      "Train Epoch: 189 [32000/50000 (64%)]\tLoss: 0.884297\n",
      "Train Epoch: 189 [33280/50000 (66%)]\tLoss: 0.940132\n",
      "Train Epoch: 189 [34560/50000 (69%)]\tLoss: 0.911545\n",
      "Train Epoch: 189 [35840/50000 (72%)]\tLoss: 1.003138\n",
      "Train Epoch: 189 [37120/50000 (74%)]\tLoss: 0.966303\n",
      "Train Epoch: 189 [38400/50000 (77%)]\tLoss: 0.946892\n",
      "Train Epoch: 189 [39680/50000 (79%)]\tLoss: 0.978462\n",
      "Train Epoch: 189 [40960/50000 (82%)]\tLoss: 0.974041\n",
      "Train Epoch: 189 [42240/50000 (84%)]\tLoss: 1.068611\n",
      "Train Epoch: 189 [43520/50000 (87%)]\tLoss: 0.769057\n",
      "Train Epoch: 189 [44800/50000 (90%)]\tLoss: 1.056038\n",
      "Train Epoch: 189 [46080/50000 (92%)]\tLoss: 0.976101\n",
      "Train Epoch: 189 [47360/50000 (95%)]\tLoss: 0.891235\n",
      "Train Epoch: 189 [48640/50000 (97%)]\tLoss: 1.283574\n",
      "Train Epoch: 189 [31200/50000 (100%)]\tLoss: 1.094189\n",
      "\n",
      "Test set: Avg. loss: 0.000331, Accuracy: 8552/9250 (92.45%)\n",
      "\n",
      "Train Epoch: 190 [0/50000 (0%)]\tLoss: 0.088577\n",
      "Train Epoch: 190 [1280/50000 (3%)]\tLoss: 1.170301\n",
      "Train Epoch: 190 [2560/50000 (5%)]\tLoss: 1.122052\n",
      "Train Epoch: 190 [3840/50000 (8%)]\tLoss: 0.991178\n",
      "Train Epoch: 190 [5120/50000 (10%)]\tLoss: 0.881080\n",
      "Train Epoch: 190 [6400/50000 (13%)]\tLoss: 1.157637\n",
      "Train Epoch: 190 [7680/50000 (15%)]\tLoss: 1.176999\n",
      "Train Epoch: 190 [8960/50000 (18%)]\tLoss: 0.938016\n",
      "Train Epoch: 190 [10240/50000 (20%)]\tLoss: 0.954853\n",
      "Train Epoch: 190 [11520/50000 (23%)]\tLoss: 0.994532\n",
      "Train Epoch: 190 [12800/50000 (26%)]\tLoss: 1.009108\n",
      "Train Epoch: 190 [14080/50000 (28%)]\tLoss: 0.882386\n",
      "Train Epoch: 190 [15360/50000 (31%)]\tLoss: 1.059108\n",
      "Train Epoch: 190 [16640/50000 (33%)]\tLoss: 0.863240\n",
      "Train Epoch: 190 [17920/50000 (36%)]\tLoss: 0.929557\n",
      "Train Epoch: 190 [19200/50000 (38%)]\tLoss: 0.916304\n",
      "Train Epoch: 190 [20480/50000 (41%)]\tLoss: 0.896875\n",
      "Train Epoch: 190 [21760/50000 (43%)]\tLoss: 1.117743\n",
      "Train Epoch: 190 [23040/50000 (46%)]\tLoss: 1.057857\n",
      "Train Epoch: 190 [24320/50000 (49%)]\tLoss: 0.961426\n",
      "Train Epoch: 190 [25600/50000 (51%)]\tLoss: 0.919995\n",
      "Train Epoch: 190 [26880/50000 (54%)]\tLoss: 0.997363\n",
      "Train Epoch: 190 [28160/50000 (56%)]\tLoss: 0.911043\n",
      "Train Epoch: 190 [29440/50000 (59%)]\tLoss: 0.976273\n",
      "Train Epoch: 190 [30720/50000 (61%)]\tLoss: 0.989532\n",
      "Train Epoch: 190 [32000/50000 (64%)]\tLoss: 0.869007\n",
      "Train Epoch: 190 [33280/50000 (66%)]\tLoss: 1.090815\n",
      "Train Epoch: 190 [34560/50000 (69%)]\tLoss: 0.767318\n",
      "Train Epoch: 190 [35840/50000 (72%)]\tLoss: 0.979931\n",
      "Train Epoch: 190 [37120/50000 (74%)]\tLoss: 1.032159\n",
      "Train Epoch: 190 [38400/50000 (77%)]\tLoss: 1.104317\n",
      "Train Epoch: 190 [39680/50000 (79%)]\tLoss: 1.007617\n",
      "Train Epoch: 190 [40960/50000 (82%)]\tLoss: 0.813609\n",
      "Train Epoch: 190 [42240/50000 (84%)]\tLoss: 0.981735\n",
      "Train Epoch: 190 [43520/50000 (87%)]\tLoss: 1.010326\n",
      "Train Epoch: 190 [44800/50000 (90%)]\tLoss: 1.109228\n",
      "Train Epoch: 190 [46080/50000 (92%)]\tLoss: 0.967120\n",
      "Train Epoch: 190 [47360/50000 (95%)]\tLoss: 0.847297\n",
      "Train Epoch: 190 [48640/50000 (97%)]\tLoss: 1.084170\n",
      "Train Epoch: 190 [31200/50000 (100%)]\tLoss: 1.028857\n",
      "\n",
      "Test set: Avg. loss: 0.000331, Accuracy: 8525/9250 (92.16%)\n",
      "\n",
      "Train Epoch: 191 [0/50000 (0%)]\tLoss: 0.136181\n",
      "Train Epoch: 191 [1280/50000 (3%)]\tLoss: 0.993005\n",
      "Train Epoch: 191 [2560/50000 (5%)]\tLoss: 0.917263\n",
      "Train Epoch: 191 [3840/50000 (8%)]\tLoss: 0.944798\n",
      "Train Epoch: 191 [5120/50000 (10%)]\tLoss: 0.878815\n",
      "Train Epoch: 191 [6400/50000 (13%)]\tLoss: 1.006118\n",
      "Train Epoch: 191 [7680/50000 (15%)]\tLoss: 0.953682\n",
      "Train Epoch: 191 [8960/50000 (18%)]\tLoss: 1.115799\n",
      "Train Epoch: 191 [10240/50000 (20%)]\tLoss: 0.839804\n",
      "Train Epoch: 191 [11520/50000 (23%)]\tLoss: 0.723423\n",
      "Train Epoch: 191 [12800/50000 (26%)]\tLoss: 0.783811\n",
      "Train Epoch: 191 [14080/50000 (28%)]\tLoss: 0.922264\n",
      "Train Epoch: 191 [15360/50000 (31%)]\tLoss: 0.741828\n",
      "Train Epoch: 191 [16640/50000 (33%)]\tLoss: 0.811030\n",
      "Train Epoch: 191 [17920/50000 (36%)]\tLoss: 1.043900\n",
      "Train Epoch: 191 [19200/50000 (38%)]\tLoss: 1.032599\n",
      "Train Epoch: 191 [20480/50000 (41%)]\tLoss: 0.894493\n",
      "Train Epoch: 191 [21760/50000 (43%)]\tLoss: 0.885113\n",
      "Train Epoch: 191 [23040/50000 (46%)]\tLoss: 0.836345\n",
      "Train Epoch: 191 [24320/50000 (49%)]\tLoss: 1.065601\n",
      "Train Epoch: 191 [25600/50000 (51%)]\tLoss: 1.112801\n",
      "Train Epoch: 191 [26880/50000 (54%)]\tLoss: 0.940887\n",
      "Train Epoch: 191 [28160/50000 (56%)]\tLoss: 0.791577\n",
      "Train Epoch: 191 [29440/50000 (59%)]\tLoss: 0.891941\n",
      "Train Epoch: 191 [30720/50000 (61%)]\tLoss: 0.887740\n",
      "Train Epoch: 191 [32000/50000 (64%)]\tLoss: 1.042113\n",
      "Train Epoch: 191 [33280/50000 (66%)]\tLoss: 0.868121\n",
      "Train Epoch: 191 [34560/50000 (69%)]\tLoss: 0.906671\n",
      "Train Epoch: 191 [35840/50000 (72%)]\tLoss: 0.946261\n",
      "Train Epoch: 191 [37120/50000 (74%)]\tLoss: 0.948866\n",
      "Train Epoch: 191 [38400/50000 (77%)]\tLoss: 0.763594\n",
      "Train Epoch: 191 [39680/50000 (79%)]\tLoss: 0.861695\n",
      "Train Epoch: 191 [40960/50000 (82%)]\tLoss: 1.002889\n",
      "Train Epoch: 191 [42240/50000 (84%)]\tLoss: 0.888444\n",
      "Train Epoch: 191 [43520/50000 (87%)]\tLoss: 0.984683\n",
      "Train Epoch: 191 [44800/50000 (90%)]\tLoss: 0.962498\n",
      "Train Epoch: 191 [46080/50000 (92%)]\tLoss: 1.002530\n",
      "Train Epoch: 191 [47360/50000 (95%)]\tLoss: 1.091878\n",
      "Train Epoch: 191 [48640/50000 (97%)]\tLoss: 0.920691\n",
      "Train Epoch: 191 [31200/50000 (100%)]\tLoss: 0.930390\n",
      "\n",
      "Test set: Avg. loss: 0.000326, Accuracy: 8534/9250 (92.26%)\n",
      "\n",
      "Train Epoch: 192 [0/50000 (0%)]\tLoss: 0.130777\n",
      "Train Epoch: 192 [1280/50000 (3%)]\tLoss: 1.088902\n",
      "Train Epoch: 192 [2560/50000 (5%)]\tLoss: 0.891253\n",
      "Train Epoch: 192 [3840/50000 (8%)]\tLoss: 1.049140\n",
      "Train Epoch: 192 [5120/50000 (10%)]\tLoss: 1.119558\n",
      "Train Epoch: 192 [6400/50000 (13%)]\tLoss: 1.012209\n",
      "Train Epoch: 192 [7680/50000 (15%)]\tLoss: 1.063951\n",
      "Train Epoch: 192 [8960/50000 (18%)]\tLoss: 0.992202\n",
      "Train Epoch: 192 [10240/50000 (20%)]\tLoss: 1.055491\n",
      "Train Epoch: 192 [11520/50000 (23%)]\tLoss: 0.828643\n",
      "Train Epoch: 192 [12800/50000 (26%)]\tLoss: 0.864090\n",
      "Train Epoch: 192 [14080/50000 (28%)]\tLoss: 1.131107\n",
      "Train Epoch: 192 [15360/50000 (31%)]\tLoss: 1.137464\n",
      "Train Epoch: 192 [16640/50000 (33%)]\tLoss: 0.862874\n",
      "Train Epoch: 192 [17920/50000 (36%)]\tLoss: 0.779479\n",
      "Train Epoch: 192 [19200/50000 (38%)]\tLoss: 0.983776\n",
      "Train Epoch: 192 [20480/50000 (41%)]\tLoss: 0.853427\n",
      "Train Epoch: 192 [21760/50000 (43%)]\tLoss: 0.965657\n",
      "Train Epoch: 192 [23040/50000 (46%)]\tLoss: 0.741643\n",
      "Train Epoch: 192 [24320/50000 (49%)]\tLoss: 0.745735\n",
      "Train Epoch: 192 [25600/50000 (51%)]\tLoss: 1.066242\n",
      "Train Epoch: 192 [26880/50000 (54%)]\tLoss: 0.826659\n",
      "Train Epoch: 192 [28160/50000 (56%)]\tLoss: 1.114798\n",
      "Train Epoch: 192 [29440/50000 (59%)]\tLoss: 0.767801\n",
      "Train Epoch: 192 [30720/50000 (61%)]\tLoss: 0.971596\n",
      "Train Epoch: 192 [32000/50000 (64%)]\tLoss: 0.909567\n",
      "Train Epoch: 192 [33280/50000 (66%)]\tLoss: 1.009463\n",
      "Train Epoch: 192 [34560/50000 (69%)]\tLoss: 1.050889\n",
      "Train Epoch: 192 [35840/50000 (72%)]\tLoss: 0.829719\n",
      "Train Epoch: 192 [37120/50000 (74%)]\tLoss: 1.043748\n",
      "Train Epoch: 192 [38400/50000 (77%)]\tLoss: 0.698776\n",
      "Train Epoch: 192 [39680/50000 (79%)]\tLoss: 0.954121\n",
      "Train Epoch: 192 [40960/50000 (82%)]\tLoss: 0.982504\n",
      "Train Epoch: 192 [42240/50000 (84%)]\tLoss: 0.991014\n",
      "Train Epoch: 192 [43520/50000 (87%)]\tLoss: 0.802458\n",
      "Train Epoch: 192 [44800/50000 (90%)]\tLoss: 1.155039\n",
      "Train Epoch: 192 [46080/50000 (92%)]\tLoss: 1.017953\n",
      "Train Epoch: 192 [47360/50000 (95%)]\tLoss: 1.092757\n",
      "Train Epoch: 192 [48640/50000 (97%)]\tLoss: 0.980722\n",
      "Train Epoch: 192 [31200/50000 (100%)]\tLoss: 0.753880\n",
      "\n",
      "Test set: Avg. loss: 0.000329, Accuracy: 8535/9250 (92.27%)\n",
      "\n",
      "Train Epoch: 193 [0/50000 (0%)]\tLoss: 0.034121\n",
      "Train Epoch: 193 [1280/50000 (3%)]\tLoss: 0.953527\n",
      "Train Epoch: 193 [2560/50000 (5%)]\tLoss: 0.943024\n",
      "Train Epoch: 193 [3840/50000 (8%)]\tLoss: 0.963547\n",
      "Train Epoch: 193 [5120/50000 (10%)]\tLoss: 1.001695\n",
      "Train Epoch: 193 [6400/50000 (13%)]\tLoss: 1.013407\n",
      "Train Epoch: 193 [7680/50000 (15%)]\tLoss: 1.000122\n",
      "Train Epoch: 193 [8960/50000 (18%)]\tLoss: 0.851393\n",
      "Train Epoch: 193 [10240/50000 (20%)]\tLoss: 0.876055\n",
      "Train Epoch: 193 [11520/50000 (23%)]\tLoss: 1.098176\n",
      "Train Epoch: 193 [12800/50000 (26%)]\tLoss: 0.875769\n",
      "Train Epoch: 193 [14080/50000 (28%)]\tLoss: 0.854189\n",
      "Train Epoch: 193 [15360/50000 (31%)]\tLoss: 0.937337\n",
      "Train Epoch: 193 [16640/50000 (33%)]\tLoss: 1.083998\n",
      "Train Epoch: 193 [17920/50000 (36%)]\tLoss: 0.949843\n",
      "Train Epoch: 193 [19200/50000 (38%)]\tLoss: 0.963680\n",
      "Train Epoch: 193 [20480/50000 (41%)]\tLoss: 1.002673\n",
      "Train Epoch: 193 [21760/50000 (43%)]\tLoss: 0.990070\n",
      "Train Epoch: 193 [23040/50000 (46%)]\tLoss: 1.076639\n",
      "Train Epoch: 193 [24320/50000 (49%)]\tLoss: 0.977677\n",
      "Train Epoch: 193 [25600/50000 (51%)]\tLoss: 0.988933\n",
      "Train Epoch: 193 [26880/50000 (54%)]\tLoss: 1.122100\n",
      "Train Epoch: 193 [28160/50000 (56%)]\tLoss: 0.996690\n",
      "Train Epoch: 193 [29440/50000 (59%)]\tLoss: 0.965486\n",
      "Train Epoch: 193 [30720/50000 (61%)]\tLoss: 0.962824\n",
      "Train Epoch: 193 [32000/50000 (64%)]\tLoss: 1.034275\n",
      "Train Epoch: 193 [33280/50000 (66%)]\tLoss: 1.089724\n",
      "Train Epoch: 193 [34560/50000 (69%)]\tLoss: 1.065219\n",
      "Train Epoch: 193 [35840/50000 (72%)]\tLoss: 0.908586\n",
      "Train Epoch: 193 [37120/50000 (74%)]\tLoss: 1.027569\n",
      "Train Epoch: 193 [38400/50000 (77%)]\tLoss: 0.801133\n",
      "Train Epoch: 193 [39680/50000 (79%)]\tLoss: 0.974716\n",
      "Train Epoch: 193 [40960/50000 (82%)]\tLoss: 0.979354\n",
      "Train Epoch: 193 [42240/50000 (84%)]\tLoss: 0.998424\n",
      "Train Epoch: 193 [43520/50000 (87%)]\tLoss: 1.036774\n",
      "Train Epoch: 193 [44800/50000 (90%)]\tLoss: 1.100063\n",
      "Train Epoch: 193 [46080/50000 (92%)]\tLoss: 1.076049\n",
      "Train Epoch: 193 [47360/50000 (95%)]\tLoss: 0.896031\n",
      "Train Epoch: 193 [48640/50000 (97%)]\tLoss: 0.813065\n",
      "Train Epoch: 193 [31200/50000 (100%)]\tLoss: 0.868431\n",
      "\n",
      "Test set: Avg. loss: 0.000329, Accuracy: 8551/9250 (92.44%)\n",
      "\n",
      "Train Epoch: 194 [0/50000 (0%)]\tLoss: 0.055515\n",
      "Train Epoch: 194 [1280/50000 (3%)]\tLoss: 0.860502\n",
      "Train Epoch: 194 [2560/50000 (5%)]\tLoss: 0.764067\n",
      "Train Epoch: 194 [3840/50000 (8%)]\tLoss: 0.904899\n",
      "Train Epoch: 194 [5120/50000 (10%)]\tLoss: 0.812410\n",
      "Train Epoch: 194 [6400/50000 (13%)]\tLoss: 0.977067\n",
      "Train Epoch: 194 [7680/50000 (15%)]\tLoss: 0.926099\n",
      "Train Epoch: 194 [8960/50000 (18%)]\tLoss: 0.899597\n",
      "Train Epoch: 194 [10240/50000 (20%)]\tLoss: 1.117091\n",
      "Train Epoch: 194 [11520/50000 (23%)]\tLoss: 0.832840\n",
      "Train Epoch: 194 [12800/50000 (26%)]\tLoss: 0.874371\n",
      "Train Epoch: 194 [14080/50000 (28%)]\tLoss: 1.046100\n",
      "Train Epoch: 194 [15360/50000 (31%)]\tLoss: 0.960802\n",
      "Train Epoch: 194 [16640/50000 (33%)]\tLoss: 1.136546\n",
      "Train Epoch: 194 [17920/50000 (36%)]\tLoss: 0.990193\n",
      "Train Epoch: 194 [19200/50000 (38%)]\tLoss: 0.795016\n",
      "Train Epoch: 194 [20480/50000 (41%)]\tLoss: 0.743821\n",
      "Train Epoch: 194 [21760/50000 (43%)]\tLoss: 0.990581\n",
      "Train Epoch: 194 [23040/50000 (46%)]\tLoss: 0.944498\n",
      "Train Epoch: 194 [24320/50000 (49%)]\tLoss: 0.908831\n",
      "Train Epoch: 194 [25600/50000 (51%)]\tLoss: 1.141809\n",
      "Train Epoch: 194 [26880/50000 (54%)]\tLoss: 0.905010\n",
      "Train Epoch: 194 [28160/50000 (56%)]\tLoss: 1.036361\n",
      "Train Epoch: 194 [29440/50000 (59%)]\tLoss: 0.893096\n",
      "Train Epoch: 194 [30720/50000 (61%)]\tLoss: 0.782373\n",
      "Train Epoch: 194 [32000/50000 (64%)]\tLoss: 1.062244\n",
      "Train Epoch: 194 [33280/50000 (66%)]\tLoss: 0.770338\n",
      "Train Epoch: 194 [34560/50000 (69%)]\tLoss: 0.965204\n",
      "Train Epoch: 194 [35840/50000 (72%)]\tLoss: 0.891603\n",
      "Train Epoch: 194 [37120/50000 (74%)]\tLoss: 0.807591\n",
      "Train Epoch: 194 [38400/50000 (77%)]\tLoss: 0.809580\n",
      "Train Epoch: 194 [39680/50000 (79%)]\tLoss: 0.935365\n",
      "Train Epoch: 194 [40960/50000 (82%)]\tLoss: 1.031164\n",
      "Train Epoch: 194 [42240/50000 (84%)]\tLoss: 0.878008\n",
      "Train Epoch: 194 [43520/50000 (87%)]\tLoss: 0.891760\n",
      "Train Epoch: 194 [44800/50000 (90%)]\tLoss: 0.968761\n",
      "Train Epoch: 194 [46080/50000 (92%)]\tLoss: 1.040857\n",
      "Train Epoch: 194 [47360/50000 (95%)]\tLoss: 1.096200\n",
      "Train Epoch: 194 [48640/50000 (97%)]\tLoss: 0.857663\n",
      "Train Epoch: 194 [31200/50000 (100%)]\tLoss: 0.915000\n",
      "\n",
      "Test set: Avg. loss: 0.000327, Accuracy: 8551/9250 (92.44%)\n",
      "\n",
      "Train Epoch: 195 [0/50000 (0%)]\tLoss: 0.122164\n",
      "Train Epoch: 195 [1280/50000 (3%)]\tLoss: 0.831031\n",
      "Train Epoch: 195 [2560/50000 (5%)]\tLoss: 0.741860\n",
      "Train Epoch: 195 [3840/50000 (8%)]\tLoss: 0.972510\n",
      "Train Epoch: 195 [5120/50000 (10%)]\tLoss: 0.821004\n",
      "Train Epoch: 195 [6400/50000 (13%)]\tLoss: 0.755008\n",
      "Train Epoch: 195 [7680/50000 (15%)]\tLoss: 0.915114\n",
      "Train Epoch: 195 [8960/50000 (18%)]\tLoss: 1.157891\n",
      "Train Epoch: 195 [10240/50000 (20%)]\tLoss: 1.012291\n",
      "Train Epoch: 195 [11520/50000 (23%)]\tLoss: 1.061693\n",
      "Train Epoch: 195 [12800/50000 (26%)]\tLoss: 0.933592\n",
      "Train Epoch: 195 [14080/50000 (28%)]\tLoss: 1.006546\n",
      "Train Epoch: 195 [15360/50000 (31%)]\tLoss: 0.868130\n",
      "Train Epoch: 195 [16640/50000 (33%)]\tLoss: 0.998989\n",
      "Train Epoch: 195 [17920/50000 (36%)]\tLoss: 1.052295\n",
      "Train Epoch: 195 [19200/50000 (38%)]\tLoss: 0.909029\n",
      "Train Epoch: 195 [20480/50000 (41%)]\tLoss: 0.961636\n",
      "Train Epoch: 195 [21760/50000 (43%)]\tLoss: 1.220114\n",
      "Train Epoch: 195 [23040/50000 (46%)]\tLoss: 0.889650\n",
      "Train Epoch: 195 [24320/50000 (49%)]\tLoss: 0.918370\n",
      "Train Epoch: 195 [25600/50000 (51%)]\tLoss: 0.962546\n",
      "Train Epoch: 195 [26880/50000 (54%)]\tLoss: 0.866052\n",
      "Train Epoch: 195 [28160/50000 (56%)]\tLoss: 1.122026\n",
      "Train Epoch: 195 [29440/50000 (59%)]\tLoss: 0.954226\n",
      "Train Epoch: 195 [30720/50000 (61%)]\tLoss: 0.962781\n",
      "Train Epoch: 195 [32000/50000 (64%)]\tLoss: 1.042615\n",
      "Train Epoch: 195 [33280/50000 (66%)]\tLoss: 1.080627\n",
      "Train Epoch: 195 [34560/50000 (69%)]\tLoss: 1.033385\n",
      "Train Epoch: 195 [35840/50000 (72%)]\tLoss: 1.000497\n",
      "Train Epoch: 195 [37120/50000 (74%)]\tLoss: 0.990006\n",
      "Train Epoch: 195 [38400/50000 (77%)]\tLoss: 1.160843\n",
      "Train Epoch: 195 [39680/50000 (79%)]\tLoss: 0.915370\n",
      "Train Epoch: 195 [40960/50000 (82%)]\tLoss: 0.897879\n",
      "Train Epoch: 195 [42240/50000 (84%)]\tLoss: 0.996588\n",
      "Train Epoch: 195 [43520/50000 (87%)]\tLoss: 1.035150\n",
      "Train Epoch: 195 [44800/50000 (90%)]\tLoss: 0.956440\n",
      "Train Epoch: 195 [46080/50000 (92%)]\tLoss: 0.845751\n",
      "Train Epoch: 195 [47360/50000 (95%)]\tLoss: 1.031618\n",
      "Train Epoch: 195 [48640/50000 (97%)]\tLoss: 0.975602\n",
      "Train Epoch: 195 [31200/50000 (100%)]\tLoss: 1.062349\n",
      "\n",
      "Test set: Avg. loss: 0.000328, Accuracy: 8555/9250 (92.49%)\n",
      "\n",
      "Train Epoch: 196 [0/50000 (0%)]\tLoss: 0.119872\n",
      "Train Epoch: 196 [1280/50000 (3%)]\tLoss: 1.008964\n",
      "Train Epoch: 196 [2560/50000 (5%)]\tLoss: 0.934837\n",
      "Train Epoch: 196 [3840/50000 (8%)]\tLoss: 1.006116\n",
      "Train Epoch: 196 [5120/50000 (10%)]\tLoss: 0.932746\n",
      "Train Epoch: 196 [6400/50000 (13%)]\tLoss: 1.247677\n",
      "Train Epoch: 196 [7680/50000 (15%)]\tLoss: 0.931080\n",
      "Train Epoch: 196 [8960/50000 (18%)]\tLoss: 0.810654\n",
      "Train Epoch: 196 [10240/50000 (20%)]\tLoss: 1.040236\n",
      "Train Epoch: 196 [11520/50000 (23%)]\tLoss: 0.820322\n",
      "Train Epoch: 196 [12800/50000 (26%)]\tLoss: 1.053630\n",
      "Train Epoch: 196 [14080/50000 (28%)]\tLoss: 0.957529\n",
      "Train Epoch: 196 [15360/50000 (31%)]\tLoss: 0.906508\n",
      "Train Epoch: 196 [16640/50000 (33%)]\tLoss: 1.005306\n",
      "Train Epoch: 196 [17920/50000 (36%)]\tLoss: 1.026206\n",
      "Train Epoch: 196 [19200/50000 (38%)]\tLoss: 1.029906\n",
      "Train Epoch: 196 [20480/50000 (41%)]\tLoss: 0.826698\n",
      "Train Epoch: 196 [21760/50000 (43%)]\tLoss: 0.907359\n",
      "Train Epoch: 196 [23040/50000 (46%)]\tLoss: 0.987412\n",
      "Train Epoch: 196 [24320/50000 (49%)]\tLoss: 1.005072\n",
      "Train Epoch: 196 [25600/50000 (51%)]\tLoss: 0.967627\n",
      "Train Epoch: 196 [26880/50000 (54%)]\tLoss: 0.988748\n",
      "Train Epoch: 196 [28160/50000 (56%)]\tLoss: 1.026771\n",
      "Train Epoch: 196 [29440/50000 (59%)]\tLoss: 0.921779\n",
      "Train Epoch: 196 [30720/50000 (61%)]\tLoss: 0.993604\n",
      "Train Epoch: 196 [32000/50000 (64%)]\tLoss: 1.051277\n",
      "Train Epoch: 196 [33280/50000 (66%)]\tLoss: 0.881396\n",
      "Train Epoch: 196 [34560/50000 (69%)]\tLoss: 0.684618\n",
      "Train Epoch: 196 [35840/50000 (72%)]\tLoss: 0.763219\n",
      "Train Epoch: 196 [37120/50000 (74%)]\tLoss: 0.979650\n",
      "Train Epoch: 196 [38400/50000 (77%)]\tLoss: 0.887633\n",
      "Train Epoch: 196 [39680/50000 (79%)]\tLoss: 0.907316\n",
      "Train Epoch: 196 [40960/50000 (82%)]\tLoss: 0.968516\n",
      "Train Epoch: 196 [42240/50000 (84%)]\tLoss: 1.024888\n",
      "Train Epoch: 196 [43520/50000 (87%)]\tLoss: 1.042327\n",
      "Train Epoch: 196 [44800/50000 (90%)]\tLoss: 1.130179\n",
      "Train Epoch: 196 [46080/50000 (92%)]\tLoss: 0.944636\n",
      "Train Epoch: 196 [47360/50000 (95%)]\tLoss: 1.054937\n",
      "Train Epoch: 196 [48640/50000 (97%)]\tLoss: 1.113387\n",
      "Train Epoch: 196 [31200/50000 (100%)]\tLoss: 1.081462\n",
      "\n",
      "Test set: Avg. loss: 0.000328, Accuracy: 8547/9250 (92.40%)\n",
      "\n",
      "Train Epoch: 197 [0/50000 (0%)]\tLoss: 0.104360\n",
      "Train Epoch: 197 [1280/50000 (3%)]\tLoss: 0.922338\n",
      "Train Epoch: 197 [2560/50000 (5%)]\tLoss: 0.873057\n",
      "Train Epoch: 197 [3840/50000 (8%)]\tLoss: 0.930449\n",
      "Train Epoch: 197 [5120/50000 (10%)]\tLoss: 0.932145\n",
      "Train Epoch: 197 [6400/50000 (13%)]\tLoss: 0.811694\n",
      "Train Epoch: 197 [7680/50000 (15%)]\tLoss: 1.121249\n",
      "Train Epoch: 197 [8960/50000 (18%)]\tLoss: 0.919595\n",
      "Train Epoch: 197 [10240/50000 (20%)]\tLoss: 1.044229\n",
      "Train Epoch: 197 [11520/50000 (23%)]\tLoss: 1.006216\n",
      "Train Epoch: 197 [12800/50000 (26%)]\tLoss: 1.065964\n",
      "Train Epoch: 197 [14080/50000 (28%)]\tLoss: 1.036387\n",
      "Train Epoch: 197 [15360/50000 (31%)]\tLoss: 0.945592\n",
      "Train Epoch: 197 [16640/50000 (33%)]\tLoss: 0.835651\n",
      "Train Epoch: 197 [17920/50000 (36%)]\tLoss: 1.093460\n",
      "Train Epoch: 197 [19200/50000 (38%)]\tLoss: 0.945762\n",
      "Train Epoch: 197 [20480/50000 (41%)]\tLoss: 0.792978\n",
      "Train Epoch: 197 [21760/50000 (43%)]\tLoss: 0.877951\n",
      "Train Epoch: 197 [23040/50000 (46%)]\tLoss: 0.768707\n",
      "Train Epoch: 197 [24320/50000 (49%)]\tLoss: 0.991372\n",
      "Train Epoch: 197 [25600/50000 (51%)]\tLoss: 0.953148\n",
      "Train Epoch: 197 [26880/50000 (54%)]\tLoss: 1.000734\n",
      "Train Epoch: 197 [28160/50000 (56%)]\tLoss: 0.956811\n",
      "Train Epoch: 197 [29440/50000 (59%)]\tLoss: 0.693586\n",
      "Train Epoch: 197 [30720/50000 (61%)]\tLoss: 1.010484\n",
      "Train Epoch: 197 [32000/50000 (64%)]\tLoss: 0.967540\n",
      "Train Epoch: 197 [33280/50000 (66%)]\tLoss: 0.951247\n",
      "Train Epoch: 197 [34560/50000 (69%)]\tLoss: 0.947497\n",
      "Train Epoch: 197 [35840/50000 (72%)]\tLoss: 0.872854\n",
      "Train Epoch: 197 [37120/50000 (74%)]\tLoss: 1.086766\n",
      "Train Epoch: 197 [38400/50000 (77%)]\tLoss: 0.921263\n",
      "Train Epoch: 197 [39680/50000 (79%)]\tLoss: 1.010162\n",
      "Train Epoch: 197 [40960/50000 (82%)]\tLoss: 0.948705\n",
      "Train Epoch: 197 [42240/50000 (84%)]\tLoss: 0.928199\n",
      "Train Epoch: 197 [43520/50000 (87%)]\tLoss: 0.886821\n",
      "Train Epoch: 197 [44800/50000 (90%)]\tLoss: 0.988142\n",
      "Train Epoch: 197 [46080/50000 (92%)]\tLoss: 0.936950\n",
      "Train Epoch: 197 [47360/50000 (95%)]\tLoss: 1.082205\n",
      "Train Epoch: 197 [48640/50000 (97%)]\tLoss: 0.890640\n",
      "Train Epoch: 197 [31200/50000 (100%)]\tLoss: 0.980449\n",
      "\n",
      "Test set: Avg. loss: 0.000328, Accuracy: 8549/9250 (92.42%)\n",
      "\n",
      "Train Epoch: 198 [0/50000 (0%)]\tLoss: 0.122647\n",
      "Train Epoch: 198 [1280/50000 (3%)]\tLoss: 0.996740\n",
      "Train Epoch: 198 [2560/50000 (5%)]\tLoss: 0.824555\n",
      "Train Epoch: 198 [3840/50000 (8%)]\tLoss: 1.038245\n",
      "Train Epoch: 198 [5120/50000 (10%)]\tLoss: 0.942474\n",
      "Train Epoch: 198 [6400/50000 (13%)]\tLoss: 0.944365\n",
      "Train Epoch: 198 [7680/50000 (15%)]\tLoss: 0.982668\n",
      "Train Epoch: 198 [8960/50000 (18%)]\tLoss: 0.806624\n",
      "Train Epoch: 198 [10240/50000 (20%)]\tLoss: 0.949553\n",
      "Train Epoch: 198 [11520/50000 (23%)]\tLoss: 0.938251\n",
      "Train Epoch: 198 [12800/50000 (26%)]\tLoss: 0.921262\n",
      "Train Epoch: 198 [14080/50000 (28%)]\tLoss: 0.922577\n",
      "Train Epoch: 198 [15360/50000 (31%)]\tLoss: 1.033823\n",
      "Train Epoch: 198 [16640/50000 (33%)]\tLoss: 1.022047\n",
      "Train Epoch: 198 [17920/50000 (36%)]\tLoss: 0.774705\n",
      "Train Epoch: 198 [19200/50000 (38%)]\tLoss: 1.051537\n",
      "Train Epoch: 198 [20480/50000 (41%)]\tLoss: 0.873172\n",
      "Train Epoch: 198 [21760/50000 (43%)]\tLoss: 0.980252\n",
      "Train Epoch: 198 [23040/50000 (46%)]\tLoss: 1.073219\n",
      "Train Epoch: 198 [24320/50000 (49%)]\tLoss: 1.045872\n",
      "Train Epoch: 198 [25600/50000 (51%)]\tLoss: 0.899173\n",
      "Train Epoch: 198 [26880/50000 (54%)]\tLoss: 1.031198\n",
      "Train Epoch: 198 [28160/50000 (56%)]\tLoss: 1.003665\n",
      "Train Epoch: 198 [29440/50000 (59%)]\tLoss: 1.246512\n",
      "Train Epoch: 198 [30720/50000 (61%)]\tLoss: 1.025938\n",
      "Train Epoch: 198 [32000/50000 (64%)]\tLoss: 1.022307\n",
      "Train Epoch: 198 [33280/50000 (66%)]\tLoss: 0.931480\n",
      "Train Epoch: 198 [34560/50000 (69%)]\tLoss: 0.877251\n",
      "Train Epoch: 198 [35840/50000 (72%)]\tLoss: 1.044022\n",
      "Train Epoch: 198 [37120/50000 (74%)]\tLoss: 0.920532\n",
      "Train Epoch: 198 [38400/50000 (77%)]\tLoss: 0.903053\n",
      "Train Epoch: 198 [39680/50000 (79%)]\tLoss: 0.896212\n",
      "Train Epoch: 198 [40960/50000 (82%)]\tLoss: 1.068777\n",
      "Train Epoch: 198 [42240/50000 (84%)]\tLoss: 0.916719\n",
      "Train Epoch: 198 [43520/50000 (87%)]\tLoss: 0.938684\n",
      "Train Epoch: 198 [44800/50000 (90%)]\tLoss: 0.970222\n",
      "Train Epoch: 198 [46080/50000 (92%)]\tLoss: 0.934468\n",
      "Train Epoch: 198 [47360/50000 (95%)]\tLoss: 0.961795\n",
      "Train Epoch: 198 [48640/50000 (97%)]\tLoss: 0.712338\n",
      "Train Epoch: 198 [31200/50000 (100%)]\tLoss: 0.795731\n",
      "\n",
      "Test set: Avg. loss: 0.000327, Accuracy: 8548/9250 (92.41%)\n",
      "\n",
      "Train Epoch: 199 [0/50000 (0%)]\tLoss: 0.113955\n",
      "Train Epoch: 199 [1280/50000 (3%)]\tLoss: 0.974253\n",
      "Train Epoch: 199 [2560/50000 (5%)]\tLoss: 0.950649\n",
      "Train Epoch: 199 [3840/50000 (8%)]\tLoss: 0.944355\n",
      "Train Epoch: 199 [5120/50000 (10%)]\tLoss: 0.860351\n",
      "Train Epoch: 199 [6400/50000 (13%)]\tLoss: 0.968507\n",
      "Train Epoch: 199 [7680/50000 (15%)]\tLoss: 1.000072\n",
      "Train Epoch: 199 [8960/50000 (18%)]\tLoss: 1.101266\n",
      "Train Epoch: 199 [10240/50000 (20%)]\tLoss: 0.849256\n",
      "Train Epoch: 199 [11520/50000 (23%)]\tLoss: 0.932716\n",
      "Train Epoch: 199 [12800/50000 (26%)]\tLoss: 0.972917\n",
      "Train Epoch: 199 [14080/50000 (28%)]\tLoss: 0.860895\n",
      "Train Epoch: 199 [15360/50000 (31%)]\tLoss: 0.887936\n",
      "Train Epoch: 199 [16640/50000 (33%)]\tLoss: 0.756714\n",
      "Train Epoch: 199 [17920/50000 (36%)]\tLoss: 0.863522\n",
      "Train Epoch: 199 [19200/50000 (38%)]\tLoss: 0.740095\n",
      "Train Epoch: 199 [20480/50000 (41%)]\tLoss: 1.161943\n",
      "Train Epoch: 199 [21760/50000 (43%)]\tLoss: 0.973788\n",
      "Train Epoch: 199 [23040/50000 (46%)]\tLoss: 0.864115\n",
      "Train Epoch: 199 [24320/50000 (49%)]\tLoss: 0.837755\n",
      "Train Epoch: 199 [25600/50000 (51%)]\tLoss: 0.770089\n",
      "Train Epoch: 199 [26880/50000 (54%)]\tLoss: 0.980328\n",
      "Train Epoch: 199 [28160/50000 (56%)]\tLoss: 1.164577\n",
      "Train Epoch: 199 [29440/50000 (59%)]\tLoss: 0.680861\n",
      "Train Epoch: 199 [30720/50000 (61%)]\tLoss: 1.051253\n",
      "Train Epoch: 199 [32000/50000 (64%)]\tLoss: 0.666386\n",
      "Train Epoch: 199 [33280/50000 (66%)]\tLoss: 0.951942\n",
      "Train Epoch: 199 [34560/50000 (69%)]\tLoss: 0.792401\n",
      "Train Epoch: 199 [35840/50000 (72%)]\tLoss: 1.093169\n",
      "Train Epoch: 199 [37120/50000 (74%)]\tLoss: 1.030227\n",
      "Train Epoch: 199 [38400/50000 (77%)]\tLoss: 0.969243\n",
      "Train Epoch: 199 [39680/50000 (79%)]\tLoss: 1.086267\n",
      "Train Epoch: 199 [40960/50000 (82%)]\tLoss: 1.067383\n",
      "Train Epoch: 199 [42240/50000 (84%)]\tLoss: 1.021674\n",
      "Train Epoch: 199 [43520/50000 (87%)]\tLoss: 1.022894\n",
      "Train Epoch: 199 [44800/50000 (90%)]\tLoss: 0.947907\n",
      "Train Epoch: 199 [46080/50000 (92%)]\tLoss: 1.044602\n",
      "Train Epoch: 199 [47360/50000 (95%)]\tLoss: 0.942754\n",
      "Train Epoch: 199 [48640/50000 (97%)]\tLoss: 0.863261\n",
      "Train Epoch: 199 [31200/50000 (100%)]\tLoss: 0.664168\n",
      "\n",
      "Test set: Avg. loss: 0.000327, Accuracy: 8548/9250 (92.41%)\n",
      "\n",
      "Train Epoch: 200 [0/50000 (0%)]\tLoss: 0.112401\n",
      "Train Epoch: 200 [1280/50000 (3%)]\tLoss: 0.993885\n",
      "Train Epoch: 200 [2560/50000 (5%)]\tLoss: 0.940285\n",
      "Train Epoch: 200 [3840/50000 (8%)]\tLoss: 0.901054\n",
      "Train Epoch: 200 [5120/50000 (10%)]\tLoss: 0.794839\n",
      "Train Epoch: 200 [6400/50000 (13%)]\tLoss: 0.961300\n",
      "Train Epoch: 200 [7680/50000 (15%)]\tLoss: 1.239098\n",
      "Train Epoch: 200 [8960/50000 (18%)]\tLoss: 0.982340\n",
      "Train Epoch: 200 [10240/50000 (20%)]\tLoss: 0.891474\n",
      "Train Epoch: 200 [11520/50000 (23%)]\tLoss: 0.879094\n",
      "Train Epoch: 200 [12800/50000 (26%)]\tLoss: 0.936012\n",
      "Train Epoch: 200 [14080/50000 (28%)]\tLoss: 1.021465\n",
      "Train Epoch: 200 [15360/50000 (31%)]\tLoss: 0.851288\n",
      "Train Epoch: 200 [16640/50000 (33%)]\tLoss: 0.804021\n",
      "Train Epoch: 200 [17920/50000 (36%)]\tLoss: 0.999709\n",
      "Train Epoch: 200 [19200/50000 (38%)]\tLoss: 1.027484\n",
      "Train Epoch: 200 [20480/50000 (41%)]\tLoss: 1.009241\n",
      "Train Epoch: 200 [21760/50000 (43%)]\tLoss: 1.136278\n",
      "Train Epoch: 200 [23040/50000 (46%)]\tLoss: 1.116006\n",
      "Train Epoch: 200 [24320/50000 (49%)]\tLoss: 0.766900\n",
      "Train Epoch: 200 [25600/50000 (51%)]\tLoss: 0.952325\n",
      "Train Epoch: 200 [26880/50000 (54%)]\tLoss: 1.113847\n",
      "Train Epoch: 200 [28160/50000 (56%)]\tLoss: 1.056973\n",
      "Train Epoch: 200 [29440/50000 (59%)]\tLoss: 0.854761\n",
      "Train Epoch: 200 [30720/50000 (61%)]\tLoss: 1.202057\n",
      "Train Epoch: 200 [32000/50000 (64%)]\tLoss: 0.940120\n",
      "Train Epoch: 200 [33280/50000 (66%)]\tLoss: 1.075805\n",
      "Train Epoch: 200 [34560/50000 (69%)]\tLoss: 0.761442\n",
      "Train Epoch: 200 [35840/50000 (72%)]\tLoss: 1.014645\n",
      "Train Epoch: 200 [37120/50000 (74%)]\tLoss: 0.896559\n",
      "Train Epoch: 200 [38400/50000 (77%)]\tLoss: 1.005266\n",
      "Train Epoch: 200 [39680/50000 (79%)]\tLoss: 1.161338\n",
      "Train Epoch: 200 [40960/50000 (82%)]\tLoss: 1.069106\n",
      "Train Epoch: 200 [42240/50000 (84%)]\tLoss: 0.843239\n",
      "Train Epoch: 200 [43520/50000 (87%)]\tLoss: 0.916057\n",
      "Train Epoch: 200 [44800/50000 (90%)]\tLoss: 0.840996\n",
      "Train Epoch: 200 [46080/50000 (92%)]\tLoss: 1.014511\n",
      "Train Epoch: 200 [47360/50000 (95%)]\tLoss: 0.977414\n",
      "Train Epoch: 200 [48640/50000 (97%)]\tLoss: 1.108965\n",
      "Train Epoch: 200 [31200/50000 (100%)]\tLoss: 0.995404\n",
      "\n",
      "Test set: Avg. loss: 0.000327, Accuracy: 8549/9250 (92.42%)\n",
      "\n",
      "Finished Training\n",
      "\n",
      "Accuracies: [36.3027027027027, 47.15675675675676, 57.41621621621621, 63.61081081081081, 70.6054054054054, 72.15135135135135, 75.26486486486486, 77.13513513513513, 76.90810810810811, 77.81621621621622, 80.83243243243243, 80.03243243243243, 81.74054054054054, 80.24864864864865, 82.57297297297298, 81.93513513513514, 83.47027027027028, 82.99459459459459, 84.54054054054055, 83.81621621621622, 84.21621621621621, 84.32432432432432, 85.37297297297297, 85.34054054054054, 83.64324324324325, 85.91351351351351, 84.28108108108108, 84.72432432432433, 86.0972972972973, 85.08108108108108, 86.3027027027027, 87.24324324324324, 85.92432432432433, 86.05405405405405, 85.62162162162163, 86.98378378378378, 86.33513513513513, 85.01621621621622, 86.46486486486486, 86.69189189189188, 86.4, 86.70270270270271, 86.42162162162163, 86.92972972972973, 87.62162162162163, 86.6054054054054, 88.08648648648649, 86.65945945945946, 86.23783783783784, 87.29729729729729, 87.53513513513514, 86.68108108108108, 88.54054054054055, 87.13513513513513, 88.3027027027027, 87.6972972972973, 87.65405405405406, 86.86486486486487, 87.55675675675676, 87.87027027027027, 87.64324324324325, 87.09189189189189, 87.71891891891892, 87.7081081081081, 87.76216216216216, 87.91351351351351, 87.72972972972973, 88.67027027027027, 87.22162162162162, 88.2054054054054, 88.35675675675675, 88.06486486486486, 87.4918918918919, 88.48648648648648, 89.01621621621622, 88.57297297297298, 88.18378378378378, 88.2054054054054, 88.77837837837838, 88.43243243243244, 88.14054054054054, 88.8, 89.2, 89.09189189189189, 88.21621621621621, 88.75675675675676, 89.35135135135135, 88.96216216216216, 88.99459459459459, 88.57297297297298, 89.28648648648648, 88.58378378378379, 89.15675675675676, 89.01621621621622, 88.96216216216216, 88.8108108108108, 89.26486486486486, 89.56756756756756, 89.4918918918919, 89.32972972972973, 88.54054054054055, 89.37297297297297, 89.47027027027028, 89.58918918918918, 89.47027027027028, 89.51351351351352, 89.64324324324325, 89.3945945945946, 89.68648648648649, 89.47027027027028, 89.43783783783783, 90.0972972972973, 90.34594594594594, 89.5027027027027, 89.92432432432433, 89.89189189189189, 89.89189189189189, 89.3945945945946, 90.5945945945946, 90.67027027027027, 90.22702702702702, 90.43243243243244, 90.08648648648649, 90.71351351351352, 90.47567567567567, 90.34594594594594, 90.51891891891891, 90.0972972972973, 90.42162162162163, 90.51891891891891, 90.46486486486486, 90.36756756756756, 90.07567567567567, 91.00540540540541, 91.09189189189189, 90.82162162162162, 91.03783783783784, 91.12432432432432, 90.64864864864865, 90.84324324324324, 90.87567567567568, 91.36216216216216, 91.09189189189189, 91.36216216216216, 91.36216216216216, 91.47027027027028, 91.45945945945945, 90.85405405405406, 91.48108108108109, 91.28648648648648, 91.6, 91.81621621621622, 91.36216216216216, 91.76216216216216, 91.65405405405406, 91.64324324324325, 91.72972972972973, 91.93513513513514, 91.7081081081081, 91.37297297297297, 91.64324324324325, 91.80540540540541, 91.64324324324325, 91.89189189189189, 91.96756756756757, 91.77297297297298, 91.92432432432433, 92.08648648648649, 91.81621621621622, 92.05405405405405, 91.98918918918919, 91.95675675675676, 92.03243243243243, 92.15135135135135, 92.04324324324324, 92.28108108108108, 92.24864864864865, 92.33513513513513, 92.2054054054054, 92.47567567567567, 92.31351351351351, 92.37837837837837, 92.43243243243244, 92.3027027027027, 92.08648648648649, 92.33513513513513, 92.3027027027027, 92.42162162162163, 92.45405405405405, 92.16216216216216, 92.25945945945946, 92.27027027027027, 92.44324324324324, 92.44324324324324, 92.48648648648648, 92.4, 92.42162162162163, 92.41081081081082, 92.41081081081082, 92.42162162162163]\n"
     ]
    }
   ],
   "source": [
    "# Create Model\n",
    "model = fixup_resnet20()\n",
    "\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "    print('Using ', torch.cuda.device_count(), ' GPU(s)')\n",
    "\n",
    "# Define Optimizer\n",
    "cel = nn.CrossEntropyLoss()\n",
    "criterion = lambda pred, target, lam: (-F.log_softmax(pred, dim=1) * torch.zeros(pred.size()).cuda().scatter_(1, target.data.view(-1, 1), lam.view(-1, 1))).sum(dim=1).mean()\n",
    "parameters_bias = [p[1] for p in model.named_parameters() if 'bias' in p[0]]\n",
    "parameters_scale = [p[1] for p in model.named_parameters() if 'scale' in p[0]]\n",
    "parameters_others = [p[1] for p in model.named_parameters() if not ('bias' in p[0] or 'scale' in p[0])]\n",
    "optimizer = optim.SGD(\n",
    "    [\n",
    "        {'params': parameters_bias, 'lr': base_lr/10.}, \n",
    "        {'params': parameters_scale, 'lr': base_lr/10.}, \n",
    "        {'params': parameters_others}\n",
    "    ], \n",
    "    lr=base_learning_rate, \n",
    "    momentum=mom, \n",
    "    weight_decay=decay\n",
    ")\n",
    "\n",
    "sgdr = CosineAnnealingLR(optimizer, num_epochs, eta_min=0, last_epoch=-1)\n",
    "\n",
    "# Start Training\n",
    "_, _, accs = train(num_epochs, model, optimizer, sgdr, cel, criterion, trainloader, testloader)\n",
    "\n",
    "print()\n",
    "print('Accuracies: {}'.format(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qOX5Iwrde9f5"
   },
   "source": [
    "Put model in evaluation mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g10p0O_9fAOe",
    "outputId": "e3339441-3c0d-4771-bcca-5030bce598c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using  1  GPU(s)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "    print('Using ', torch.cuda.device_count(), ' GPU(s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FRreifcIgVNz"
   },
   "source": [
    "Let's test our model again to see again which accuracy we have finally reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GblopwOcg1HF"
   },
   "outputs": [],
   "source": [
    "def test_final(model, data_loader):\n",
    "    _, accs = test(model, cel, data_loader, [], [])\n",
    "    return accs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ruV5BFPJgYJY",
    "outputId": "b305c3e0-2483-4e8a-ccf8-3bea57686297"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.000327, Accuracy: 8549/9250 (92.42%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "92.42162162162163"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc = test_final(model, testloader); test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndn0ckY3XNFk"
   },
   "source": [
    "Let's save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mn16mBzdEnfk"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./cifar10_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9E2mBMz-XVyH",
    "outputId": "e6e9f8d4-39f0-4b10-bb11-ce9e44f5c097"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar10_model.pth  data  sample_data\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "d7HV1Mfvp21K",
    "outputId": "8fa6223d-31ba-4935-e2a0-8a21ddc5a1ca"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_21146bcb-6248-480f-988b-1929adfc7969\", \"cifar10_model.pth\", 1097107)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.download('./cifar10_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vSGM5aFLqExM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_cifar10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
