{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize Activations\n",
    "\n",
    "<br/>\n",
    "\n",
    "<pre>\n",
    "model name:            imagenette_128_resnet18_model.pth\n",
    "network architecture:  resnet18\n",
    "dataset:               imagenette training and calibration set\n",
    "image size:            128x128 (resized beforehand)\n",
    "</pre>\n",
    "\n",
    "<br/>\n",
    "\n",
    "We want to test our Out-of-Distribution (OoD) detection method __Layer-wise Activation Cluster Analysis (LACA)__ on a dataset that is more complex than the MNIST, SVHN or the CIFAR-10 dataset which have been used so far. We chose the [Imagenette dataset](https://github.com/fastai/imagenette) as it contains images showing more complex scenes. The [Imagenette dataset](https://github.com/fastai/imagenette) is a subset of 10 classes of the [ImageNet dataset](https://www.image-net.org/). \n",
    "\n",
    "The first step of our OoD detection method is executed before inference. Here we measure in-distribution statistics from the training data and OoD statistics from the calibration data. Both kind of statistics are necessary to calculate the credibility of a test sample at inference. \n",
    "\n",
    "After fetching the activations from the data samples (see __01_fetch_activations_imagenette_128_resnet18.ipynb__) we vectorize the activations. Activations from convolutional layers are cube-shaped. To vectorize these activations we simply flatten them. Activations from linear layers are vectors already. Here we do not need to do anything. [Papernot and McDaniel](https://github.com/cleverhans-lab/cleverhans/blob/master/cleverhans_v3.1.0/cleverhans/model_zoo/deep_k_nearest_neighbors/dknn.py#L544) vectorized the activations in the same way.\n",
    "\n",
    "<br/>\n",
    "\n",
    "_Sources:_\n",
    "* [Imagenette dataset](https://github.com/fastai/imagenette)\n",
    "* [Deep kNN paper](https://arxiv.org/abs/1803.04765)\n",
    "* [Deep kNN sample code](https://github.com/cleverhans-lab/cleverhans/blob/master/cleverhans_v3.1.0/cleverhans/model_zoo/deep_k_nearest_neighbors/dknn.py)\n",
    "* [Deep kNN sample code (PyTorch)](https://github.com/bam098/deep_knn/blob/master/dknn_mnist.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version:      3.6.9\n",
      "torch version:       1.7.0\n",
      "torchvision version: 0.8.1\n",
      "sklearn version:     0.23.2\n",
      "skimage version:     0.17.2\n",
      "numpy version:       1.19.5\n",
      "matplotlib version:  3.2.2\n",
      "seaborn version:     0.11.0\n",
      "pandas version:      1.1.4\n",
      "pickle version:      4.0\n",
      "CUDA available:      False\n",
      "cuDNN enabled:       True\n",
      "num gpus:            0\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import adaptive_avg_pool2d\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, models, datasets\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "import skimage\n",
    "from skimage.measure import block_reduce\n",
    "from umap import UMAP\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import platform\n",
    "from pathlib import Path\n",
    "import random\n",
    "import warnings\n",
    "import pprint\n",
    "from collections import Counter\n",
    "\n",
    "sns.set()\n",
    "sns.set_context(\"notebook\", font_scale=1.1)\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "print('python version:      {}'.format(platform.python_version()))\n",
    "print('torch version:       {}'.format(torch.__version__))\n",
    "print('torchvision version: {}'.format(torchvision.__version__))\n",
    "print('sklearn version:     {}'.format(sklearn.__version__))\n",
    "print('skimage version:     {}'.format(skimage.__version__))\n",
    "print('numpy version:       {}'.format(np.__version__))\n",
    "print('matplotlib version:  {}'.format(matplotlib.__version__))\n",
    "print('seaborn version:     {}'.format(sns.__version__))\n",
    "print('pandas version:      {}'.format(pd.__version__))\n",
    "print('pickle version:      {}'.format(pickle.format_version))\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print('CUDA available:      {}'.format(use_cuda))\n",
    "print('cuDNN enabled:       {}'.format(torch.backends.cudnn.enabled))\n",
    "print('num gpus:            {}'.format(torch.cuda.device_count()))\n",
    "\n",
    "if use_cuda:\n",
    "    print('gpu:                 {}'.format(torch.cuda.get_device_name(0)))\n",
    "\n",
    "    print()\n",
    "    print('------------------------- CUDA -------------------------')\n",
    "    ! nvcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the seed values to obtain reproducible results. For more information how to set seed values in Python and Pytorch see the [Pytorch documentation](https://pytorch.org/docs/1.7.0/notes/randomness.html?highlight=repro)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.set_deterministic(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-26T12:01:04.424348Z",
     "iopub.status.busy": "2022-09-26T12:01:04.423665Z",
     "iopub.status.idle": "2022-09-26T12:01:04.646403Z",
     "shell.execute_reply": "2022-09-26T12:01:04.645378Z",
     "shell.execute_reply.started": "2022-09-26T12:01:04.424311Z"
    }
   },
   "outputs": [],
   "source": [
    "# Activations\n",
    "img_size          = 128                                                             # Image size\n",
    "base_act_folder   = Path('/Users/lehmann/research/laca3/activations/imagenette')    # Base activations folder\n",
    "afname_string     = 'imagenette_{}_resnet18_acts'.format(img_size)                  # Activations file name\n",
    "acts_path         = base_act_folder/afname_string                                   # Activations path\n",
    "layer_names       = [                                                               # List of layer names \n",
    "    'relu',\n",
    "    'maxpool',\n",
    "    'layer1-0',\n",
    "    'layer1-1',\n",
    "    'layer2-0',\n",
    "    'layer2-1',\n",
    "    'layer3-0',\n",
    "    'layer3-1',\n",
    "    'layer4-0',\n",
    "    'layer4-1',\n",
    "    'avgpool'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Function for Vectorizing Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_acts2vec(dataset_name, pool=None):\n",
    "    \n",
    "    for layer_name in layer_names:\n",
    "        print('## Transforming Activations to Vector Form for Layer {}'.format(layer_name))\n",
    "        \n",
    "        # Load activations\n",
    "        fname = str(acts_path) + '_{}_{}.pkl'.format(dataset_name, layer_name)\n",
    "        with open(fname, 'rb') as pickle_file:\n",
    "            loaded_activations = pickle.load(pickle_file)\n",
    "        \n",
    "        # Transform activations\n",
    "        layer_activations = loaded_activations['activations']\n",
    "        layer_targets = loaded_activations['targets']\n",
    "        \n",
    "        layer_activation_vectors = []\n",
    "        \n",
    "        for i in range(layer_activations.shape[0]):\n",
    "            sample_activation_vector = transform_acts2vec_from_sample(layer_activations[i], pool)            \n",
    "            layer_activation_vectors.append(sample_activation_vector)\n",
    "        \n",
    "        layer_activation_vectors = np.array(layer_activation_vectors) \n",
    "        print('- activations transformed: {}'.format(layer_activation_vectors.shape))\n",
    "        \n",
    "        # Save activations vectors\n",
    "        activation_vectors = {}\n",
    "        activation_vectors['activations'] = layer_activation_vectors\n",
    "        activation_vectors['targets'] = layer_targets\n",
    "        \n",
    "        fname = str(acts_path) + '_{}_{}_vectors.pkl'.format(dataset_name, layer_name)\n",
    "        with open(fname, 'wb') as pickle_file:\n",
    "            pickle.dump(activation_vectors, pickle_file, protocol=4)\n",
    "\n",
    "        print(\"done!\")        \n",
    "        print()\n",
    "    \n",
    "def transform_acts2vec_from_sample(sample_activations, pool=(2,2)):\n",
    "    if len(sample_activations.shape) == 3:\n",
    "        if pool is None:\n",
    "            sample_activations = sample_activations.flatten()\n",
    "        else:\n",
    "            sample_activations = np.array([\n",
    "                block_reduce(act_map, pool, np.mean) for act_map in sample_activations\n",
    "            ]).flatten()\n",
    "                        \n",
    "    return sample_activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize Activations from Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Transforming Activations to Vector Form for Layer relu\n",
      "- activations transformed: (9469, 262144)\n",
      "done!\n",
      "\n",
      "## Transforming Activations to Vector Form for Layer maxpool\n",
      "- activations transformed: (9469, 65536)\n",
      "done!\n",
      "\n",
      "## Transforming Activations to Vector Form for Layer layer1-0\n",
      "- activations transformed: (9469, 65536)\n",
      "done!\n",
      "\n",
      "## Transforming Activations to Vector Form for Layer layer1-1\n",
      "- activations transformed: (9469, 65536)\n",
      "done!\n",
      "\n",
      "## Transforming Activations to Vector Form for Layer layer2-0\n",
      "- activations transformed: (9469, 32768)\n",
      "done!\n",
      "\n",
      "## Transforming Activations to Vector Form for Layer layer2-1\n",
      "- activations transformed: (9469, 32768)\n",
      "done!\n",
      "\n",
      "## Transforming Activations to Vector Form for Layer layer3-0\n",
      "- activations transformed: (9469, 16384)\n",
      "done!\n",
      "\n",
      "## Transforming Activations to Vector Form for Layer layer3-1\n",
      "- activations transformed: (9469, 16384)\n",
      "done!\n",
      "\n",
      "## Transforming Activations to Vector Form for Layer layer4-0\n",
      "- activations transformed: (9469, 8192)\n",
      "done!\n",
      "\n",
      "## Transforming Activations to Vector Form for Layer layer4-1\n",
      "- activations transformed: (9469, 8192)\n",
      "done!\n",
      "\n",
      "## Transforming Activations to Vector Form for Layer avgpool\n",
      "- activations transformed: (9469, 512)\n",
      "done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainset_name = 'trainset'\n",
    "transform_acts2vec(trainset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## layer relu\n",
      "activations: (9469, 262144), targets: (9469,)\n",
      "\n",
      "## layer maxpool\n",
      "activations: (9469, 65536), targets: (9469,)\n",
      "\n",
      "## layer layer1-0\n",
      "activations: (9469, 65536), targets: (9469,)\n",
      "\n",
      "## layer layer1-1\n",
      "activations: (9469, 65536), targets: (9469,)\n",
      "\n",
      "## layer layer2-0\n",
      "activations: (9469, 32768), targets: (9469,)\n",
      "\n",
      "## layer layer2-1\n",
      "activations: (9469, 32768), targets: (9469,)\n",
      "\n",
      "## layer layer3-0\n",
      "activations: (9469, 16384), targets: (9469,)\n",
      "\n",
      "## layer layer3-1\n",
      "activations: (9469, 16384), targets: (9469,)\n",
      "\n",
      "## layer layer4-0\n",
      "activations: (9469, 8192), targets: (9469,)\n",
      "\n",
      "## layer layer4-1\n",
      "activations: (9469, 8192), targets: (9469,)\n",
      "\n",
      "## layer avgpool\n",
      "activations: (9469, 512), targets: (9469,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for layer_name in layer_names:\n",
    "    fname = str(acts_path) + '_{}_{}_vectors.pkl'.format(trainset_name, layer_name)\n",
    "    with open(fname, 'rb') as pickle_file:\n",
    "        loaded_activations = pickle.load(pickle_file)\n",
    "    \n",
    "    print('## layer {}'.format(layer_name))\n",
    "    print('activations: {}, targets: {}'.format(\n",
    "        loaded_activations['activations'].shape, loaded_activations['targets'].shape\n",
    "    ))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize Activations from Calibration Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Transforming Activations to Vector Form for Layer relu\n",
      "- activations transformed: (750, 262144)\n",
      "done!\n",
      "\n",
      "## Transforming Activations to Vector Form for Layer maxpool\n",
      "- activations transformed: (750, 65536)\n",
      "done!\n",
      "\n",
      "## Transforming Activations to Vector Form for Layer layer1-0\n",
      "- activations transformed: (750, 65536)\n",
      "done!\n",
      "\n",
      "## Transforming Activations to Vector Form for Layer layer1-1\n",
      "- activations transformed: (750, 65536)\n",
      "done!\n",
      "\n",
      "## Transforming Activations to Vector Form for Layer layer2-0\n",
      "- activations transformed: (750, 32768)\n",
      "done!\n",
      "\n",
      "## Transforming Activations to Vector Form for Layer layer2-1\n",
      "- activations transformed: (750, 32768)\n",
      "done!\n",
      "\n",
      "## Transforming Activations to Vector Form for Layer layer3-0\n",
      "- activations transformed: (750, 16384)\n",
      "done!\n",
      "\n",
      "## Transforming Activations to Vector Form for Layer layer3-1\n",
      "- activations transformed: (750, 16384)\n",
      "done!\n",
      "\n",
      "## Transforming Activations to Vector Form for Layer layer4-0\n",
      "- activations transformed: (750, 8192)\n",
      "done!\n",
      "\n",
      "## Transforming Activations to Vector Form for Layer layer4-1\n",
      "- activations transformed: (750, 8192)\n",
      "done!\n",
      "\n",
      "## Transforming Activations to Vector Form for Layer avgpool\n",
      "- activations transformed: (750, 512)\n",
      "done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calibset_name = 'calibset'\n",
    "transform_acts2vec(calibset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## layer relu\n",
      "activations: (750, 262144), targets: (750,)\n",
      "\n",
      "## layer maxpool\n",
      "activations: (750, 65536), targets: (750,)\n",
      "\n",
      "## layer layer1-0\n",
      "activations: (750, 65536), targets: (750,)\n",
      "\n",
      "## layer layer1-1\n",
      "activations: (750, 65536), targets: (750,)\n",
      "\n",
      "## layer layer2-0\n",
      "activations: (750, 32768), targets: (750,)\n",
      "\n",
      "## layer layer2-1\n",
      "activations: (750, 32768), targets: (750,)\n",
      "\n",
      "## layer layer3-0\n",
      "activations: (750, 16384), targets: (750,)\n",
      "\n",
      "## layer layer3-1\n",
      "activations: (750, 16384), targets: (750,)\n",
      "\n",
      "## layer layer4-0\n",
      "activations: (750, 8192), targets: (750,)\n",
      "\n",
      "## layer layer4-1\n",
      "activations: (750, 8192), targets: (750,)\n",
      "\n",
      "## layer avgpool\n",
      "activations: (750, 512), targets: (750,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for layer_name in layer_names:\n",
    "    fname = str(acts_path) + '_{}_{}_vectors.pkl'.format(calibset_name, layer_name)\n",
    "    with open(fname, 'rb') as pickle_file:\n",
    "        loaded_activations = pickle.load(pickle_file)\n",
    "    \n",
    "    print('## layer {}'.format(layer_name))\n",
    "    print('activations: {}, targets: {}'.format(\n",
    "        loaded_activations['activations'].shape, loaded_activations['targets'].shape\n",
    "    ))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
